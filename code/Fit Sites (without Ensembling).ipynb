{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af59f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from glob import glob\n",
    "\n",
    "import utils\n",
    "# from utils import load_data, get_train_val_split, get_stratified_splitter\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedGroupKFold, train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import kstest, kruskal, mannwhitneyu\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import re\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "\n",
    "import optuna\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f663bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/sharaddargan/Documents/Course Content/Spring 2023/Probability and Statistics 2/Project/EnergyPrediction-ASHRAE/code/utils.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c2569b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.88%\n",
      "Memory usage of dataframe is 9.60 MB\n",
      "Memory usage after optimization is: 3.07 MB\n",
      "Decreased by 68.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharaddargan/Documents/Course Content/Spring 2023/Probability and Statistics 2/Project/EnergyPrediction-ASHRAE/code/utils.py:143: FutureWarning: Using .astype to convert from timezone-aware dtype to timezone-naive dtype is deprecated and will raise in a future version.  Use obj.tz_localize(None) or obj.tz_convert('UTC').tz_localize(None) instead\n",
      "  weather_train['timestamp'] = pd.to_datetime(weather_train['timestamp'], infer_datetime_format = True, utc = True).astype('datetime64[ns]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 19.04 MB\n",
      "Memory usage after optimization is: 5.13 MB\n",
      "Decreased by 73.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharaddargan/Documents/Course Content/Spring 2023/Probability and Statistics 2/Project/EnergyPrediction-ASHRAE/code/utils.py:151: FutureWarning: Using .astype to convert from timezone-aware dtype to timezone-naive dtype is deprecated and will raise in a future version.  Use obj.tz_localize(None) or obj.tz_convert('UTC').tz_localize(None) instead\n",
      "  train['timestamp'] = pd.to_datetime(train['timestamp'], infer_datetime_format = True, utc = True).astype('datetime64[ns]')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 616.95 MB\n",
      "Memory usage after optimization is: 289.19 MB\n",
      "Decreased by 53.12%\n",
      "Memory usage of dataframe is 1272.51 MB\n",
      "Memory usage after optimization is: 358.53 MB\n",
      "Decreased by 71.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sharaddargan/Documents/Course Content/Spring 2023/Probability and Statistics 2/Project/EnergyPrediction-ASHRAE/code/utils.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[(train['site_id'] == 0) & (train['meter'] == 0)]['meter_reading'] = 0.2931 * train[(train['site_id'] == 0) & (train['meter'] == 0)]['meter_reading']\n"
     ]
    }
   ],
   "source": [
    "data_dict = utils.load_data('ashrae-energy-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aea63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weather features \n",
    "weather_features = ['cloud_coverage', 'dew_temperature', 'air_temperature', \n",
    "                    'sea_level_pressure', 'wind_direction', 'wind_speed', 'precip_depth_1_hr',]\n",
    "\n",
    "hourly_by_site = data_dict[\"X_train\"].groupby(['hour', 'month', 'site_id'])[weather_features].mean().reset_index()\n",
    "\n",
    "data_dict[\"X_train\"] = data_dict[\"X_train\"].merge(\n",
    "    hourly_by_site, \n",
    "    on=['hour', 'month', 'site_id'], \n",
    "    how='left', \n",
    "    suffixes=(None, '_hourly_by_site')\n",
    ")\n",
    "\n",
    "del hourly_by_site\n",
    "\n",
    "for feature in weather_features:\n",
    "    # Fill in NA values from weather with hourly by site columns \n",
    "    data_dict[\"X_train\"][feature].fillna(\n",
    "        data_dict[\"X_train\"][feature + \"_hourly_by_site\"],\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    # Fill in the rest with the median \n",
    "    data_dict[\"X_train\"][feature].fillna(\n",
    "        data_dict[\"X_train\"][feature].median(),\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    data_dict[\"X_train\"][feature + \"_diff_hourly_from_mean\"] = data_dict[\"X_train\"][feature] - \\\n",
    "        data_dict[\"X_train\"][feature + \"_hourly_by_site\"]\n",
    "    \n",
    "data_dict[\"X_train\"] = data_dict[\"X_train\"].drop(columns = [feat + \"_hourly_by_site\" for feat in weather_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ad44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in NA with median values for floor count and year_built\n",
    "for feature in ['year_built', 'floor_count']:\n",
    "    data_dict[\"X_train\"][feature].fillna(\n",
    "        data_dict[\"X_train\"][feature].median(), \n",
    "        inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "557c72c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weather_test', 'X_train', 'X_test', 'y_train'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a4187",
   "metadata": {},
   "source": [
    "## Examine Differences (Non-Parametric)\n",
    "Using Bonferonni's Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d409d8",
   "metadata": {},
   "source": [
    "### Milestone 2. \n",
    "- Show difference in sites across meter readings \n",
    "- get average meter reading per day per site \n",
    "- conduct a (non-parametric ANOVA) KS OR pairs (mann-whitney) to show that they are diff \n",
    "- train a model per site id (with rudimentary hyperparameter tuning) \n",
    "- John sites 0-7, Sharad sites 8-15 \n",
    "\n",
    "### Milestone 3. Determine, per site, which primary uses are similar (if they have only a few buildings), which are diff\n",
    "- for a given primary use, if diff, identify \"clusters\" of buildings that are similar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86eb2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['year_built', 'floor_count', 'air_temperature',\n",
    "       'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr',\n",
    "       'sea_level_pressure', 'wind_direction', 'wind_speed',\n",
    "       'air_temperature_mean_lag7', 'air_temperature_max_lag7',\n",
    "       'air_temperature_min_lag7', 'air_temperature_std_lag7',\n",
    "       'cloud_coverage_mean_lag7', 'cloud_coverage_max_lag7',\n",
    "       'cloud_coverage_min_lag7', 'cloud_coverage_std_lag7',\n",
    "       'dew_temperature_mean_lag7', 'dew_temperature_max_lag7',\n",
    "       'dew_temperature_min_lag7', 'dew_temperature_std_lag7',\n",
    "       'precip_depth_1_hr_mean_lag7', 'precip_depth_1_hr_max_lag7',\n",
    "       'precip_depth_1_hr_min_lag7', 'precip_depth_1_hr_std_lag7',\n",
    "       'sea_level_pressure_mean_lag7', 'sea_level_pressure_max_lag7',\n",
    "       'sea_level_pressure_min_lag7', 'sea_level_pressure_std_lag7',\n",
    "       'wind_direction_mean_lag7', 'wind_direction_max_lag7',\n",
    "       'wind_direction_min_lag7', 'wind_direction_std_lag7',\n",
    "       'wind_speed_mean_lag7', 'wind_speed_max_lag7', 'wind_speed_min_lag7',\n",
    "       'wind_speed_std_lag7', 'log_square_feet', 'weekday', 'hour', 'day',\n",
    "       'weekend', 'month', 'primary_use_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44645aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X, y = data_dict['X_train'].loc[:, features+['meter', 'site_id', 'building_id']], data_dict['y_train']\n",
    "splitter_gen = utils.get_stratified_splitter(X, y)\n",
    "train_index, test_index = next(splitter_gen)\n",
    "X_train, y_train, X_test, y_test = X.loc[train_index, :], y[train_index], X.loc[test_index, :], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aff449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_search_cv(\n",
    "    site: int,\n",
    "    meter: int,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    features: list,\n",
    "    n_trials: int = 50,\n",
    "    \n",
    "):\n",
    "    \"\"\"\n",
    "    Runs Optuna Search for LGBMRegressor\n",
    "    \"\"\"\n",
    "    SITE_FILTER = X_train[\"site_id\"] == site\n",
    "    METER_FILTER = X_train[\"meter\"] == meter\n",
    "    \n",
    "    X, y = X_train.loc[SITE_FILTER&METER_FILTER, features], y_train[SITE_FILTER&METER_FILTER]\n",
    "    if X.shape[0] == 0:\n",
    "        return None\n",
    "\n",
    "    splitter_gen = utils.get_stratified_splitter(X_train[SITE_FILTER&METER_FILTER], y_train[SITE_FILTER&METER_FILTER])\n",
    "\n",
    "    \n",
    "\n",
    "    regressor = LGBMRegressor()\n",
    "\n",
    "    param_distributions = {\n",
    "        \"max_depth\": optuna.distributions.IntDistribution(-1, len(X_train.columns)),\n",
    "        \"num_leaves\": optuna.distributions.IntDistribution(5, 50),\n",
    "        \"learning_rate\": optuna.distributions.FloatDistribution(1e-7, 1, log=True),\n",
    "        \"n_estimators\": optuna.distributions.IntDistribution(1, 500),\n",
    "        \"reg_alpha\": optuna.distributions.FloatDistribution(1e-7, 1e7, log=True),\n",
    "        \"reg_lambda\": optuna.distributions.FloatDistribution(1e-7, 1e7, log=True),            \n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters not searched over: \n",
    "    subsample_for_bin: int = 200000,\n",
    "    min_split_gain: float = 0.0,\n",
    "    min_child_weight: float = 0.001,\n",
    "    min_child_samples: int = 20,\n",
    "    subsample: float = 1.0,\n",
    "    subsample_freq: int = 0,\n",
    "    colsample_bytree: float = 1.0,\n",
    "    random_state: Union[int, numpy.random.mtrand.RandomState, NoneType] = None,\n",
    "    n_jobs: int = -1,\n",
    "    \"\"\"\n",
    "    def rmse(estimator, X_test, y_test):\n",
    "        y_pred = estimator.predict(X_test)\n",
    "        return -1 * mean_squared_error(y_test, y_pred, squared=False)\n",
    "    \n",
    "    optuna_search = optuna.integration.OptunaSearchCV(\n",
    "        regressor, \n",
    "        param_distributions,\n",
    "        n_trials=n_trials,\n",
    "        cv = splitter_gen,\n",
    "        random_state=0, # IMPORTANT,\n",
    "        refit=True,\n",
    "        n_jobs=4,\n",
    "        scoring = rmse,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    optuna_search.fit(X, y)\n",
    "    y_pred = optuna_search.predict(X)\n",
    "    \n",
    "    return optuna_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d303350d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/16 [00:00<?, ?it/s]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 17:09:36,463]\u001b[0m A new study created in memory with name: no-name-3f320d4b-1a62-4759-ba11-5b88010a3cfc\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:09:44,746]\u001b[0m Trial 1 finished with value: -1.1910817565532403 and parameters: {'max_depth': 28, 'num_leaves': 17, 'learning_rate': 0.3451915537647719, 'n_estimators': 409, 'reg_alpha': 176562.08317097957, 'reg_lambda': 4.520273143539669}. Best is trial 1 with value: -1.1910817565532403.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:09:45,942]\u001b[0m Trial 2 finished with value: -1.1910817565532403 and parameters: {'max_depth': 14, 'num_leaves': 9, 'learning_rate': 0.3097150091101042, 'n_estimators': 469, 'reg_alpha': 82763.94449483023, 'reg_lambda': 0.000409649724961753}. Best is trial 1 with value: -1.1910817565532403.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:09:48,423]\u001b[0m Trial 3 finished with value: -1.1767785055535374 and parameters: {'max_depth': 7, 'num_leaves': 22, 'learning_rate': 0.014294354606710656, 'n_estimators': 426, 'reg_alpha': 65632.14583100127, 'reg_lambda': 2.819048380106176}. Best is trial 3 with value: -1.1767785055535374.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:08,985]\u001b[0m Trial 5 finished with value: -1.1655796260046405 and parameters: {'max_depth': 13, 'num_leaves': 10, 'learning_rate': 0.00029796932217572846, 'n_estimators': 409, 'reg_alpha': 0.0020576047055155472, 'reg_lambda': 3.7431034591424744e-05}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:11,314]\u001b[0m Trial 6 finished with value: -1.1870517300582895 and parameters: {'max_depth': 46, 'num_leaves': 46, 'learning_rate': 0.00011639502729768737, 'n_estimators': 130, 'reg_alpha': 0.0017866600307077049, 'reg_lambda': 777.7499494703608}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:17,837]\u001b[0m Trial 8 finished with value: -1.1910817565532403 and parameters: {'max_depth': 21, 'num_leaves': 33, 'learning_rate': 1.0546804028814298e-07, 'n_estimators': 377, 'reg_alpha': 757445.9387383248, 'reg_lambda': 5.043172211522191e-07}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:24,479]\u001b[0m Trial 7 finished with value: -1.1856371835923902 and parameters: {'max_depth': 34, 'num_leaves': 22, 'learning_rate': 0.004765144757698621, 'n_estimators': 143, 'reg_alpha': 0.8669005630375184, 'reg_lambda': 4.9631267697799745e-05}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:31,652]\u001b[0m Trial 0 finished with value: -1.1906934730953247 and parameters: {'max_depth': 44, 'num_leaves': 35, 'learning_rate': 3.8201878191101865e-06, 'n_estimators': 387, 'reg_alpha': 4.521988639101608, 'reg_lambda': 0.1929944348819715}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:32,731]\u001b[0m Trial 9 finished with value: -1.3033221639224604 and parameters: {'max_depth': 28, 'num_leaves': 12, 'learning_rate': 0.1310718522172889, 'n_estimators': 453, 'reg_alpha': 293.5758811963088, 'reg_lambda': 27.334753836782927}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:37,444]\u001b[0m Trial 4 finished with value: -1.435013036550362 and parameters: {'max_depth': 10, 'num_leaves': 50, 'learning_rate': 0.03888763561593094, 'n_estimators': 321, 'reg_alpha': 0.040360230486190536, 'reg_lambda': 0.02318019949352364}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:37,636]\u001b[0m Trial 11 finished with value: -1.1910817565532403 and parameters: {'max_depth': 11, 'num_leaves': 40, 'learning_rate': 0.024984577666776864, 'n_estimators': 347, 'reg_alpha': 1153397.9347594923, 'reg_lambda': 0.007202278573354794}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:41,020]\u001b[0m Trial 12 finished with value: -1.166839635427925 and parameters: {'max_depth': 47, 'num_leaves': 7, 'learning_rate': 0.0005492957952686949, 'n_estimators': 150, 'reg_alpha': 2.6843084781566238, 'reg_lambda': 0.0008419214640430131}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:42,258]\u001b[0m Trial 15 finished with value: -1.1908376386985116 and parameters: {'max_depth': 1, 'num_leaves': 7, 'learning_rate': 0.0005234000806690285, 'n_estimators': 3, 'reg_alpha': 1.6248047230996024e-06, 'reg_lambda': 6.756503634640223e-07}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:49,081]\u001b[0m Trial 13 finished with value: -1.1906900157686984 and parameters: {'max_depth': -1, 'num_leaves': 6, 'learning_rate': 0.00028758574233824646, 'n_estimators': 246, 'reg_alpha': 5.322376583859649e-06, 'reg_lambda': 4390365.880135587}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:50,941]\u001b[0m Trial 16 finished with value: -1.1884561213504763 and parameters: {'max_depth': 37, 'num_leaves': 5, 'learning_rate': 0.00028884972043832124, 'n_estimators': 219, 'reg_alpha': 0.0007663181686646863, 'reg_lambda': 483898.9236030801}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:10:51,402]\u001b[0m Trial 14 finished with value: -1.188127214945046 and parameters: {'max_depth': -1, 'num_leaves': 25, 'learning_rate': 0.0010519081296296417, 'n_estimators': 245, 'reg_alpha': 1.0528946757448757e-06, 'reg_lambda': 2021770.3801377497}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:02,528]\u001b[0m Trial 18 finished with value: -1.1901355190227854 and parameters: {'max_depth': 19, 'num_leaves': 14, 'learning_rate': 2.7053756672658162e-05, 'n_estimators': 139, 'reg_alpha': 65.44032854024563, 'reg_lambda': 3.77257979038872e-05}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:05,560]\u001b[0m Trial 19 finished with value: -1.1900730586457788 and parameters: {'max_depth': 21, 'num_leaves': 18, 'learning_rate': 2.80378969872301e-05, 'n_estimators': 145, 'reg_alpha': 104.61871521109694, 'reg_lambda': 4.049197265452953e-05}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:09,861]\u001b[0m Trial 17 finished with value: -1.1890542688166756 and parameters: {'max_depth': 37, 'num_leaves': 15, 'learning_rate': 3.534583657472309e-05, 'n_estimators': 246, 'reg_alpha': 0.000674211534036509, 'reg_lambda': 9.536122308604655e-05}. Best is trial 5 with value: -1.1655796260046405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:10,249]\u001b[0m Trial 20 finished with value: -1.1625408211655348 and parameters: {'max_depth': 17, 'num_leaves': 19, 'learning_rate': 0.0020696054559377806, 'n_estimators': 72, 'reg_alpha': 0.0004135037382128046, 'reg_lambda': 1.1128468485954898e-07}. Best is trial 20 with value: -1.1625408211655348.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:11,514]\u001b[0m Trial 21 finished with value: -1.1839818202762404 and parameters: {'max_depth': 41, 'num_leaves': 30, 'learning_rate': 0.0006875360352339011, 'n_estimators': 37, 'reg_alpha': 0.00012282076471870892, 'reg_lambda': 0.0036072334252546896}. Best is trial 20 with value: -1.1625408211655348.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:12,638]\u001b[0m Trial 23 finished with value: -1.1834707983762536 and parameters: {'max_depth': 17, 'num_leaves': 30, 'learning_rate': 0.0027160747695810414, 'n_estimators': 10, 'reg_alpha': 1.8793739976850886e-05, 'reg_lambda': 1.0467159173449937e-06}. Best is trial 20 with value: -1.1625408211655348.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:16,680]\u001b[0m Trial 22 finished with value: -1.1635734515851923 and parameters: {'max_depth': 27, 'num_leaves': 30, 'learning_rate': 0.003178659435689245, 'n_estimators': 43, 'reg_alpha': 0.0343960587877498, 'reg_lambda': 1.0304123671085e-07}. Best is trial 20 with value: -1.1625408211655348.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:17,711]\u001b[0m Trial 24 finished with value: -1.1516425730397934 and parameters: {'max_depth': 16, 'num_leaves': 11, 'learning_rate': 0.003981685840677063, 'n_estimators': 74, 'reg_alpha': 0.02139766062233128, 'reg_lambda': 1.5471711984623579e-07}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 17:11:18,309]\u001b[0m Trial 25 finished with value: -1.152933282547638 and parameters: {'max_depth': 28, 'num_leaves': 11, 'learning_rate': 0.0032537985961924986, 'n_estimators': 77, 'reg_alpha': 0.0150169065006113, 'reg_lambda': 1.031204298609369e-07}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:24,590]\u001b[0m Trial 10 finished with value: -1.2748405304620383 and parameters: {'max_depth': 41, 'num_leaves': 34, 'learning_rate': 0.10804922264908694, 'n_estimators': 435, 'reg_alpha': 0.00022321383794605436, 'reg_lambda': 25649.509360594984}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:24,909]\u001b[0m Trial 28 finished with value: -1.1720080148264012 and parameters: {'max_depth': 24, 'num_leaves': 20, 'learning_rate': 0.007684418396927873, 'n_estimators': 61, 'reg_alpha': 2.2529422916562397e-07, 'reg_lambda': 2.848516704967427e-06}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:25,656]\u001b[0m Trial 26 finished with value: -1.1545400783160926 and parameters: {'max_depth': 27, 'num_leaves': 21, 'learning_rate': 0.00381405538526125, 'n_estimators': 82, 'reg_alpha': 0.02365382390162171, 'reg_lambda': 3.866850969324329e-06}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:26,232]\u001b[0m Trial 27 finished with value: -1.162792638800383 and parameters: {'max_depth': 26, 'num_leaves': 21, 'learning_rate': 0.005331156895400816, 'n_estimators': 72, 'reg_alpha': 0.0569604175214629, 'reg_lambda': 1.6660465006019781e-07}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:31,595]\u001b[0m Trial 30 finished with value: -1.1578211980362259 and parameters: {'max_depth': 32, 'num_leaves': 12, 'learning_rate': 0.0019019455692006202, 'n_estimators': 87, 'reg_alpha': 0.019496513129421713, 'reg_lambda': 3.0111582566643113e-06}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:32,201]\u001b[0m Trial 31 finished with value: -1.5751539821478207 and parameters: {'max_depth': 31, 'num_leaves': 13, 'learning_rate': 0.9138489152977463, 'n_estimators': 99, 'reg_alpha': 0.02158154837764691, 'reg_lambda': 2.707428993028399e-06}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:35,745]\u001b[0m Trial 29 finished with value: -1.1890602076223242 and parameters: {'max_depth': 24, 'num_leaves': 23, 'learning_rate': 0.006416379995750256, 'n_estimators': 95, 'reg_alpha': 1.3098954067533445e-07, 'reg_lambda': 3.654995367157398e-06}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:43,745]\u001b[0m Trial 32 finished with value: -1.5368988325649773 and parameters: {'max_depth': 31, 'num_leaves': 25, 'learning_rate': 0.9512705581609213, 'n_estimators': 191, 'reg_alpha': 0.6164848460525457, 'reg_lambda': 4.961445619214066e-06}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:45,651]\u001b[0m Trial 35 finished with value: -1.256018513728716 and parameters: {'max_depth': 31, 'num_leaves': 16, 'learning_rate': 0.015563189569971169, 'n_estimators': 113, 'reg_alpha': 0.3683622893220674, 'reg_lambda': 3.7422423051452106e-06}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:47,968]\u001b[0m Trial 34 finished with value: -1.25508598251503 and parameters: {'max_depth': 33, 'num_leaves': 16, 'learning_rate': 0.009521736554887432, 'n_estimators': 188, 'reg_alpha': 0.3634202988502515, 'reg_lambda': 4.343364380644186e-06}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:53,827]\u001b[0m Trial 33 finished with value: -1.328412936846939 and parameters: {'max_depth': 31, 'num_leaves': 25, 'learning_rate': 0.015310309198103052, 'n_estimators': 186, 'reg_alpha': 0.44109266246811196, 'reg_lambda': 5.8812213343120285e-06}. Best is trial 24 with value: -1.1516425730397934.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:56,693]\u001b[0m Trial 36 finished with value: -1.150252935639962 and parameters: {'max_depth': 31, 'num_leaves': 11, 'learning_rate': 0.0017070535899062211, 'n_estimators': 178, 'reg_alpha': 0.004394489370189636, 'reg_lambda': 9.331981998619211e-06}. Best is trial 36 with value: -1.150252935639962.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:11:56,982]\u001b[0m Trial 39 finished with value: -1.1749745323068774 and parameters: {'max_depth': 5, 'num_leaves': 10, 'learning_rate': 0.0018848093002307882, 'n_estimators': 32, 'reg_alpha': 0.016518344759097817, 'reg_lambda': 0.00032098845282802223}. Best is trial 36 with value: -1.150252935639962.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:05,982]\u001b[0m Trial 37 finished with value: -1.1444973056457535 and parameters: {'max_depth': 34, 'num_leaves': 11, 'learning_rate': 0.0017243557162918907, 'n_estimators': 296, 'reg_alpha': 0.0063403090545342995, 'reg_lambda': 4.71127774041566e-07}. Best is trial 37 with value: -1.1444973056457535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:08,890]\u001b[0m Trial 38 finished with value: -1.1474286516602317 and parameters: {'max_depth': 37, 'num_leaves': 11, 'learning_rate': 0.001316392675784111, 'n_estimators': 301, 'reg_alpha': 0.0091446493518912, 'reg_lambda': 0.06479054083596737}. Best is trial 37 with value: -1.1444973056457535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:12,633]\u001b[0m Trial 41 finished with value: -1.2391691194476544 and parameters: {'max_depth': 36, 'num_leaves': 9, 'learning_rate': 0.05570451343439714, 'n_estimators': 286, 'reg_alpha': 0.004445413469420701, 'reg_lambda': 5.201687784700959e-07}. Best is trial 37 with value: -1.1444973056457535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:13,601]\u001b[0m Trial 40 finished with value: -1.2637608517052554 and parameters: {'max_depth': 7, 'num_leaves': 10, 'learning_rate': 0.036554527540905796, 'n_estimators': 279, 'reg_alpha': 0.006823967307791698, 'reg_lambda': 0.00029753808389772543}. Best is trial 37 with value: -1.1444973056457535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:22,864]\u001b[0m Trial 42 finished with value: -1.2604369021706725 and parameters: {'max_depth': 36, 'num_leaves': 9, 'learning_rate': 0.04632170599732716, 'n_estimators': 311, 'reg_alpha': 0.003909090718836609, 'reg_lambda': 3.8315863909754123e-07}. Best is trial 37 with value: -1.1444973056457535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:26,530]\u001b[0m Trial 43 finished with value: -1.2434818849525837 and parameters: {'max_depth': 36, 'num_leaves': 9, 'learning_rate': 0.041721201491320636, 'n_estimators': 314, 'reg_alpha': 0.0030106655531114287, 'reg_lambda': 0.1636176721658393}. Best is trial 37 with value: -1.1444973056457535.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:31,889]\u001b[0m Trial 44 finished with value: -1.1365272254906067 and parameters: {'max_depth': 40, 'num_leaves': 10, 'learning_rate': 0.001639828720881107, 'n_estimators': 294, 'reg_alpha': 0.003339818734974437, 'reg_lambda': 0.10688741573140335}. Best is trial 44 with value: -1.1365272254906067.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:36,009]\u001b[0m Trial 45 finished with value: -1.143800990047902 and parameters: {'max_depth': 41, 'num_leaves': 11, 'learning_rate': 0.0014691023787413843, 'n_estimators': 322, 'reg_alpha': 0.001755218634845629, 'reg_lambda': 0.1604278467979553}. Best is trial 44 with value: -1.1365272254906067.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:43,687]\u001b[0m Trial 48 finished with value: -1.1310316506860565 and parameters: {'max_depth': 42, 'num_leaves': 5, 'learning_rate': 0.001265229084483294, 'n_estimators': 282, 'reg_alpha': 0.00010086660204140805, 'reg_lambda': 0.09375839767928858}. Best is trial 48 with value: -1.1310316506860565.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:45,639]\u001b[0m Trial 46 finished with value: -1.1477232191376179 and parameters: {'max_depth': 40, 'num_leaves': 12, 'learning_rate': 0.0013191883442802016, 'n_estimators': 321, 'reg_alpha': 8.412005366211521e-05, 'reg_lambda': 0.07645112251398938}. Best is trial 48 with value: -1.1310316506860565.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:50,467]\u001b[0m Trial 47 finished with value: -1.2734405460419809 and parameters: {'max_depth': 41, 'num_leaves': 13, 'learning_rate': 0.01137672866604407, 'n_estimators': 369, 'reg_alpha': 6.918008403862937e-05, 'reg_lambda': 1.3335278294166573e-05}. Best is trial 48 with value: -1.1310316506860565.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:55,289]\u001b[0m Trial 49 finished with value: -1.159737148605766 and parameters: {'max_depth': 41, 'num_leaves': 14, 'learning_rate': 0.001042230479566429, 'n_estimators': 363, 'reg_alpha': 9.169102213703838e-05, 'reg_lambda': 0.0641458256119402}. Best is trial 48 with value: -1.1310316506860565.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 17:12:58,275]\u001b[0m A new study created in memory with name: no-name-72ad3894-42e9-455b-9984-4166f02d896c\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:12:58,818]\u001b[0m Trial 1 finished with value: -2.212462479464853 and parameters: {'max_depth': 17, 'num_leaves': 44, 'learning_rate': 3.655561496990226e-05, 'n_estimators': 23, 'reg_alpha': 7477681.917773894, 'reg_lambda': 6108609.5475227535}. Best is trial 1 with value: -2.212462479464853.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:02,086]\u001b[0m Trial 2 finished with value: -2.2123493952620867 and parameters: {'max_depth': 2, 'num_leaves': 35, 'learning_rate': 1.0098979581804628e-06, 'n_estimators': 235, 'reg_alpha': 0.7311248926351489, 'reg_lambda': 0.0002144081646381566}. Best is trial 2 with value: -2.2123493952620867.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:02,642]\u001b[0m Trial 0 finished with value: -2.2110571540154167 and parameters: {'max_depth': 13, 'num_leaves': 27, 'learning_rate': 2.1973593714702894e-05, 'n_estimators': 472, 'reg_alpha': 95393.23754431814, 'reg_lambda': 0.17199097861177873}. Best is trial 0 with value: -2.2110571540154167.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:04,399]\u001b[0m Trial 5 finished with value: -2.212462479464853 and parameters: {'max_depth': 33, 'num_leaves': 24, 'learning_rate': 0.0017166800076207924, 'n_estimators': 336, 'reg_alpha': 2237006.836673418, 'reg_lambda': 0.06136678326576426}. Best is trial 0 with value: -2.2110571540154167.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:08,061]\u001b[0m Trial 6 finished with value: -2.212425018026169 and parameters: {'max_depth': 17, 'num_leaves': 15, 'learning_rate': 4.901577453029595e-07, 'n_estimators': 124, 'reg_alpha': 1.5305939836478936e-07, 'reg_lambda': 4.911824944726861e-06}. Best is trial 0 with value: -2.2110571540154167.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:10,497]\u001b[0m Trial 8 finished with value: -2.211550050885709 and parameters: {'max_depth': 46, 'num_leaves': 23, 'learning_rate': 1.4466356757224082e-05, 'n_estimators': 280, 'reg_alpha': 64896.36207226565, 'reg_lambda': 2.6649549360602017e-07}. Best is trial 0 with value: -2.2110571540154167.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:10,538]\u001b[0m Trial 7 finished with value: -2.2005036364615482 and parameters: {'max_depth': 29, 'num_leaves': 8, 'learning_rate': 0.004018425746044411, 'n_estimators': 248, 'reg_alpha': 4.407932921964704e-07, 'reg_lambda': 1391.8345478463154}. Best is trial 7 with value: -2.2005036364615482.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:10,683]\u001b[0m Trial 3 finished with value: -2.6715775120320444 and parameters: {'max_depth': 41, 'num_leaves': 37, 'learning_rate': 0.8728099044527212, 'n_estimators': 144, 'reg_alpha': 0.026942251670683363, 'reg_lambda': 6.128681705981775e-07}. Best is trial 7 with value: -2.2005036364615482.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:13,864]\u001b[0m Trial 4 finished with value: -2.212430125372687 and parameters: {'max_depth': 13, 'num_leaves': 25, 'learning_rate': 2.486755746604994e-07, 'n_estimators': 220, 'reg_alpha': 1.555590810043467e-07, 'reg_lambda': 0.0010657529232094432}. Best is trial 7 with value: -2.2005036364615482.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:15,572]\u001b[0m Trial 11 finished with value: -2.2117530606264264 and parameters: {'max_depth': 47, 'num_leaves': 13, 'learning_rate': 9.893911615813914e-06, 'n_estimators': 124, 'reg_alpha': 86.45037269138442, 'reg_lambda': 0.03455910274897898}. Best is trial 7 with value: -2.2005036364615482.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:17,216]\u001b[0m Trial 9 finished with value: -2.135355489783563 and parameters: {'max_depth': 4, 'num_leaves': 6, 'learning_rate': 0.0010528196723999597, 'n_estimators': 364, 'reg_alpha': 5.306436350446692, 'reg_lambda': 4.694262588844968e-07}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:22,063]\u001b[0m Trial 12 finished with value: -2.212369492281262 and parameters: {'max_depth': 14, 'num_leaves': 47, 'learning_rate': 2.066530258814744e-06, 'n_estimators': 147, 'reg_alpha': 1024.9240119225294, 'reg_lambda': 4467.9201301833145}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:23,721]\u001b[0m Trial 14 finished with value: -2.1676366789932375 and parameters: {'max_depth': 31, 'num_leaves': 5, 'learning_rate': 0.0022739403810908797, 'n_estimators': 389, 'reg_alpha': 0.0007793654699013266, 'reg_lambda': 868.5693162076725}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:24,095]\u001b[0m Trial 13 finished with value: -2.286540439670591 and parameters: {'max_depth': 29, 'num_leaves': 7, 'learning_rate': 0.0034259059441526752, 'n_estimators': 395, 'reg_alpha': 5.79196930817139e-05, 'reg_lambda': 453.6139029609689}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:29,791]\u001b[0m Trial 15 finished with value: -2.2065019388297418 and parameters: {'max_depth': 29, 'num_leaves': 6, 'learning_rate': 0.002266891430414976, 'n_estimators': 396, 'reg_alpha': 0.0010435107699601036, 'reg_lambda': 56.11298986815942}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:30,638]\u001b[0m Trial 16 finished with value: -2.1582722013448916 and parameters: {'max_depth': 4, 'num_leaves': 5, 'learning_rate': 0.0003328050898048858, 'n_estimators': 417, 'reg_alpha': 0.0022114629431797092, 'reg_lambda': 8.504795841956366}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:33,700]\u001b[0m Trial 18 finished with value: -2.2063227939011076 and parameters: {'max_depth': 1, 'num_leaves': 16, 'learning_rate': 0.00017367204694847236, 'n_estimators': 480, 'reg_alpha': 0.15719164321008786, 'reg_lambda': 12.423011010936046}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:43,223]\u001b[0m Trial 17 finished with value: -2.1482623120126485 and parameters: {'max_depth': -1, 'num_leaves': 16, 'learning_rate': 0.0003300964697960155, 'n_estimators': 437, 'reg_alpha': 0.005134882822091962, 'reg_lambda': 28.251895591135224}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:44,905]\u001b[0m Trial 10 finished with value: -2.1992549445009244 and parameters: {'max_depth': 20, 'num_leaves': 34, 'learning_rate': 0.00018061612603306707, 'n_estimators': 418, 'reg_alpha': 0.0451458522788841, 'reg_lambda': 23102.660602539534}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:50,081]\u001b[0m Trial 20 finished with value: -2.170253399042663 and parameters: {'max_depth': 8, 'num_leaves': 17, 'learning_rate': 0.0002440018957007186, 'n_estimators': 345, 'reg_alpha': 37.5765343944237, 'reg_lambda': 4.687948763016276e-05}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:51,879]\u001b[0m Trial 19 finished with value: -2.1454076744288897 and parameters: {'max_depth': -1, 'num_leaves': 16, 'learning_rate': 0.00031535436818243317, 'n_estimators': 485, 'reg_alpha': 2.1172480525264206, 'reg_lambda': 6.812649609675745}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:13:57,539]\u001b[0m Trial 21 finished with value: -2.513438772166902 and parameters: {'max_depth': 8, 'num_leaves': 17, 'learning_rate': 0.02422328579485531, 'n_estimators': 327, 'reg_alpha': 7.342314925493569, 'reg_lambda': 1.2050229196783246e-05}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:00,363]\u001b[0m Trial 22 finished with value: -2.505543749219606 and parameters: {'max_depth': 7, 'num_leaves': 17, 'learning_rate': 0.016733949321917164, 'n_estimators': 333, 'reg_alpha': 12.823917348187859, 'reg_lambda': 0.00019523817734282419}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:06,976]\u001b[0m Trial 24 finished with value: -2.51151402462714 and parameters: {'max_depth': -1, 'num_leaves': 11, 'learning_rate': 0.040419562544806505, 'n_estimators': 497, 'reg_alpha': 5.493566623537496, 'reg_lambda': 1.3857105240846317}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 17:14:13,339]\u001b[0m Trial 25 finished with value: -2.195713362885132 and parameters: {'max_depth': 0, 'num_leaves': 11, 'learning_rate': 6.19277030972353e-05, 'n_estimators': 494, 'reg_alpha': 3.0259168734632356, 'reg_lambda': 0.0025557275339493273}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:15,792]\u001b[0m Trial 23 finished with value: -2.5350676612229437 and parameters: {'max_depth': -1, 'num_leaves': 19, 'learning_rate': 0.021037838022885075, 'n_estimators': 500, 'reg_alpha': 6.483615960311362, 'reg_lambda': 1.0034418621937218e-07}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:16,474]\u001b[0m Trial 26 finished with value: -2.190577333796612 and parameters: {'max_depth': -1, 'num_leaves': 11, 'learning_rate': 8.161691492211642e-05, 'n_estimators': 500, 'reg_alpha': 1.1955389253156536, 'reg_lambda': 1.4312129303269396}. Best is trial 9 with value: -2.135355489783563.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:27,650]\u001b[0m Trial 27 finished with value: -2.1313487453039666 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 0.0006167829542905259, 'n_estimators': 455, 'reg_alpha': 0.4060509623064839, 'reg_lambda': 0.0049824607653224315}. Best is trial 27 with value: -2.1313487453039666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:28,742]\u001b[0m Trial 30 finished with value: -2.1416977412819627 and parameters: {'max_depth': 4, 'num_leaves': 30, 'learning_rate': 0.0006320284275789912, 'n_estimators': 442, 'reg_alpha': 449.61124641441654, 'reg_lambda': 0.011818895511100132}. Best is trial 27 with value: -2.1313487453039666.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:35,844]\u001b[0m Trial 28 finished with value: -2.1232033630413993 and parameters: {'max_depth': 6, 'num_leaves': 21, 'learning_rate': 0.0005804638921361969, 'n_estimators': 448, 'reg_alpha': 0.32227183465436177, 'reg_lambda': 0.5968346603160571}. Best is trial 28 with value: -2.1232033630413993.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:35,951]\u001b[0m Trial 29 finished with value: -2.128190720118452 and parameters: {'max_depth': 5, 'num_leaves': 20, 'learning_rate': 0.0006853000967095876, 'n_estimators': 447, 'reg_alpha': 0.1938637946174579, 'reg_lambda': 0.00513910817482557}. Best is trial 28 with value: -2.1232033630413993.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:46,818]\u001b[0m Trial 31 finished with value: -2.130156456026026 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 0.0007483386003175699, 'n_estimators': 448, 'reg_alpha': 430.3451149727422, 'reg_lambda': 0.00862502774505309}. Best is trial 28 with value: -2.1232033630413993.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:14:59,299]\u001b[0m Trial 32 finished with value: -2.15243711675397 and parameters: {'max_depth': 11, 'num_leaves': 29, 'learning_rate': 0.0008268231259845128, 'n_estimators': 445, 'reg_alpha': 810.671307451506, 'reg_lambda': 0.006118855811887831}. Best is trial 28 with value: -2.1232033630413993.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:01,017]\u001b[0m Trial 34 finished with value: -2.1328285676349177 and parameters: {'max_depth': 10, 'num_leaves': 21, 'learning_rate': 0.0011434041794579424, 'n_estimators': 444, 'reg_alpha': 0.28013755423556513, 'reg_lambda': 0.232620148572113}. Best is trial 28 with value: -2.1232033630413993.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:03,510]\u001b[0m Trial 33 finished with value: -2.1288709878712653 and parameters: {'max_depth': 11, 'num_leaves': 29, 'learning_rate': 0.0007621740319271262, 'n_estimators': 364, 'reg_alpha': 0.1784541786586279, 'reg_lambda': 0.33044466029921865}. Best is trial 28 with value: -2.1232033630413993.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:12,594]\u001b[0m Trial 35 finished with value: -2.1230301898009705 and parameters: {'max_depth': 12, 'num_leaves': 21, 'learning_rate': 0.0007792929652938114, 'n_estimators': 444, 'reg_alpha': 0.25571560408993005, 'reg_lambda': 0.20642814899704448}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:22,676]\u001b[0m Trial 37 finished with value: -2.2045603142535697 and parameters: {'max_depth': 16, 'num_leaves': 21, 'learning_rate': 3.574922728285744e-05, 'n_estimators': 374, 'reg_alpha': 0.15983197970204, 'reg_lambda': 0.1804596139238135}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:24,327]\u001b[0m Trial 38 finished with value: -2.2071224334701114 and parameters: {'max_depth': 16, 'num_leaves': 26, 'learning_rate': 3.0313777155560204e-05, 'n_estimators': 301, 'reg_alpha': 0.035295622557577025, 'reg_lambda': 0.31331364887848034}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:25,155]\u001b[0m Trial 36 finished with value: -2.2069315278523813 and parameters: {'max_depth': 10, 'num_leaves': 20, 'learning_rate': 2.023386488803839e-05, 'n_estimators': 459, 'reg_alpha': 0.25058635566272935, 'reg_lambda': 0.2262992285781605}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:27,723]\u001b[0m Trial 41 finished with value: -2.131286244698192 and parameters: {'max_depth': 22, 'num_leaves': 32, 'learning_rate': 0.005743482482446867, 'n_estimators': 40, 'reg_alpha': 0.020545754414328782, 'reg_lambda': 0.0005693945707967082}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:33,986]\u001b[0m Trial 39 finished with value: -2.2050501528105895 and parameters: {'max_depth': 16, 'num_leaves': 27, 'learning_rate': 4.371482704867933e-05, 'n_estimators': 293, 'reg_alpha': 0.03410069631057268, 'reg_lambda': 0.26054574974356015}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:43,771]\u001b[0m Trial 40 finished with value: -2.3585511155893575 and parameters: {'max_depth': 11, 'num_leaves': 27, 'learning_rate': 0.005305424132573951, 'n_estimators': 297, 'reg_alpha': 0.01725616169536526, 'reg_lambda': 0.4342039860175329}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:46,381]\u001b[0m Trial 42 finished with value: -2.197481745213089 and parameters: {'max_depth': 22, 'num_leaves': 39, 'learning_rate': 0.00011753584407493324, 'n_estimators': 211, 'reg_alpha': 0.02451513651312729, 'reg_lambda': 0.059037627881952236}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:15:57,091]\u001b[0m Trial 43 finished with value: -2.194556784543873 and parameters: {'max_depth': 20, 'num_leaves': 39, 'learning_rate': 0.00010386328758601425, 'n_estimators': 287, 'reg_alpha': 0.7640373177998452, 'reg_lambda': 0.03444144052272992}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:16:08,251]\u001b[0m Trial 45 finished with value: -2.185157832876766 and parameters: {'max_depth': 6, 'num_leaves': 24, 'learning_rate': 0.00011384717909581027, 'n_estimators': 417, 'reg_alpha': 0.6337866034187262, 'reg_lambda': 0.01644871118345719}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:16:12,367]\u001b[0m Trial 46 finished with value: -2.1298983302670376 and parameters: {'max_depth': 6, 'num_leaves': 24, 'learning_rate': 0.0005268714255700261, 'n_estimators': 412, 'reg_alpha': 0.8906213847992648, 'reg_lambda': 0.026853152005967034}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:16:13,999]\u001b[0m Trial 48 finished with value: -2.1739513741127574 and parameters: {'max_depth': 2, 'num_leaves': 23, 'learning_rate': 0.001193167453146077, 'n_estimators': 468, 'reg_alpha': 49.99389727012185, 'reg_lambda': 0.042510523207670424}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:16:14,831]\u001b[0m Trial 44 finished with value: -2.1777309032845094 and parameters: {'max_depth': 12, 'num_leaves': 38, 'learning_rate': 0.00014894581795872494, 'n_estimators': 417, 'reg_alpha': 0.6272911270872701, 'reg_lambda': 0.018357209271017368}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:16:20,534]\u001b[0m Trial 47 finished with value: -2.135252674480194 and parameters: {'max_depth': 13, 'num_leaves': 24, 'learning_rate': 0.000543296257024494, 'n_estimators': 412, 'reg_alpha': 46.7311144960898, 'reg_lambda': 0.016007625433951005}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:16:24,762]\u001b[0m Trial 49 finished with value: -2.1500639804857506 and parameters: {'max_depth': 13, 'num_leaves': 23, 'learning_rate': 0.0017359085436476581, 'n_estimators': 370, 'reg_alpha': 35.76792853521692, 'reg_lambda': 0.0013489892338381672}. Best is trial 35 with value: -2.1230301898009705.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|                                                             | 1/16 [06:53<1:43:20, 413.37s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 17:16:31,092]\u001b[0m A new study created in memory with name: no-name-6fd87fed-07c1-41e6-83be-45fd3a1a9fa2\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:16:47,452]\u001b[0m Trial 3 finished with value: -1.3443181323458302 and parameters: {'max_depth': 47, 'num_leaves': 21, 'learning_rate': 4.1772734244382633e-07, 'n_estimators': 317, 'reg_alpha': 1535099.2379272394, 'reg_lambda': 0.007550574599091759}. Best is trial 3 with value: -1.3443181323458302.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:16:49,546]\u001b[0m Trial 1 finished with value: -1.3443181323458302 and parameters: {'max_depth': 28, 'num_leaves': 24, 'learning_rate': 0.2214181695911187, 'n_estimators': 361, 'reg_alpha': 8002975.022493133, 'reg_lambda': 1.589782553807635e-07}. Best is trial 3 with value: -1.3443181323458302.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:16:55,101]\u001b[0m Trial 0 finished with value: -1.3440189338133892 and parameters: {'max_depth': 19, 'num_leaves': 37, 'learning_rate': 6.87209691455379e-06, 'n_estimators': 65, 'reg_alpha': 5.11839464323857e-06, 'reg_lambda': 0.14985201532665746}. Best is trial 0 with value: -1.3440189338133892.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:17:15,736]\u001b[0m Trial 4 finished with value: -1.3376474241506344 and parameters: {'max_depth': 38, 'num_leaves': 23, 'learning_rate': 8.356492571315679e-05, 'n_estimators': 119, 'reg_alpha': 2.9234692609731536, 'reg_lambda': 2.87016512570503e-07}. Best is trial 4 with value: -1.3376474241506344.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:17:22,026]\u001b[0m Trial 7 finished with value: -1.0789055791836046 and parameters: {'max_depth': 23, 'num_leaves': 43, 'learning_rate': 0.5797701827800709, 'n_estimators': 12, 'reg_alpha': 0.4066860799476739, 'reg_lambda': 571.1677807762942}. Best is trial 7 with value: -1.0789055791836046.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:17:43,928]\u001b[0m Trial 8 finished with value: -1.2995627354905879 and parameters: {'max_depth': 31, 'num_leaves': 30, 'learning_rate': 0.0009772122219186303, 'n_estimators': 76, 'reg_alpha': 5.7229662825480725, 'reg_lambda': 417.43217500807657}. Best is trial 7 with value: -1.0789055791836046.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:17:47,909]\u001b[0m Trial 9 finished with value: -1.3442438060319695 and parameters: {'max_depth': 39, 'num_leaves': 7, 'learning_rate': 1.1309108831228861e-05, 'n_estimators': 10, 'reg_alpha': 133.07993245307554, 'reg_lambda': 0.35386196479286486}. Best is trial 7 with value: -1.0789055791836046.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:17:56,472]\u001b[0m Trial 5 finished with value: -1.3195491937786392 and parameters: {'max_depth': 37, 'num_leaves': 18, 'learning_rate': 0.0001130457906799979, 'n_estimators': 349, 'reg_alpha': 5.927466529717216e-06, 'reg_lambda': 0.18723484077345248}. Best is trial 7 with value: -1.0789055791836046.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:18:05,817]\u001b[0m Trial 10 finished with value: -1.3438175941021653 and parameters: {'max_depth': 6, 'num_leaves': 5, 'learning_rate': 6.281307471050467e-06, 'n_estimators': 188, 'reg_alpha': 21565.768395480434, 'reg_lambda': 55570.17565066448}. Best is trial 7 with value: -1.0789055791836046.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:18:07,533]\u001b[0m Trial 2 finished with value: -1.2520370754367283 and parameters: {'max_depth': 17, 'num_leaves': 39, 'learning_rate': 0.0005001199169831477, 'n_estimators': 340, 'reg_alpha': 1472.0017383643706, 'reg_lambda': 520.7851462192604}. Best is trial 7 with value: -1.0789055791836046.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:18:24,055]\u001b[0m Trial 6 finished with value: -1.0796359680301275 and parameters: {'max_depth': 24, 'num_leaves': 30, 'learning_rate': 0.00476526457087283, 'n_estimators': 355, 'reg_alpha': 1.373014833024243e-07, 'reg_lambda': 1094.1252479929333}. Best is trial 7 with value: -1.0789055791836046.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:19:24,305]\u001b[0m Trial 12 finished with value: -1.1255399423547585 and parameters: {'max_depth': 41, 'num_leaves': 41, 'learning_rate': 0.08031995072132987, 'n_estimators': 373, 'reg_alpha': 6.394624801390417e-06, 'reg_lambda': 2.2603366341643317e-05}. Best is trial 7 with value: -1.0789055791836046.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:19:28,177]\u001b[0m Trial 11 finished with value: -1.3082336960072876 and parameters: {'max_depth': 21, 'num_leaves': 49, 'learning_rate': 0.0002077819832218861, 'n_estimators': 282, 'reg_alpha': 0.005600636387557998, 'reg_lambda': 222.45299061833057}. Best is trial 7 with value: -1.0789055791836046.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:19:59,938]\u001b[0m Trial 13 finished with value: -0.9806582516663045 and parameters: {'max_depth': 0, 'num_leaves': 50, 'learning_rate': 0.8825206546580305, 'n_estimators': 480, 'reg_alpha': 0.008283544636800779, 'reg_lambda': 5408787.246175255}. Best is trial 13 with value: -0.9806582516663045.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:20:03,083]\u001b[0m Trial 14 finished with value: -0.9709519830185822 and parameters: {'max_depth': 11, 'num_leaves': 50, 'learning_rate': 0.5950267486234927, 'n_estimators': 495, 'reg_alpha': 0.003962359706527511, 'reg_lambda': 6659839.820721553}. Best is trial 14 with value: -0.9709519830185822.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:20:13,297]\u001b[0m Trial 16 finished with value: -1.1951817910335023 and parameters: {'max_depth': 11, 'num_leaves': 49, 'learning_rate': 0.02097449935014723, 'n_estimators': 486, 'reg_alpha': 0.004874677122070276, 'reg_lambda': 7510596.044575073}. Best is trial 14 with value: -0.9709519830185822.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:20:25,676]\u001b[0m Trial 15 finished with value: -1.0646091413626326 and parameters: {'max_depth': 11, 'num_leaves': 48, 'learning_rate': 0.019826895705669118, 'n_estimators': 497, 'reg_alpha': 0.000981589751065977, 'reg_lambda': 2126638.090238191}. Best is trial 14 with value: -0.9709519830185822.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:21:26,346]\u001b[0m Trial 17 finished with value: -0.9697127297620824 and parameters: {'max_depth': -1, 'num_leaves': 47, 'learning_rate': 0.5411143621523713, 'n_estimators': 479, 'reg_alpha': 0.11474057239099003, 'reg_lambda': 9107353.636119235}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:21:39,351]\u001b[0m Trial 18 finished with value: -0.9711573779706846 and parameters: {'max_depth': -1, 'num_leaves': 48, 'learning_rate': 0.8882013494695603, 'n_estimators': 480, 'reg_alpha': 0.009458490690961779, 'reg_lambda': 9390405.791699132}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:22:04,549]\u001b[0m Trial 20 finished with value: -1.0621801557314543 and parameters: {'max_depth': -1, 'num_leaves': 35, 'learning_rate': 0.2717826421493129, 'n_estimators': 427, 'reg_alpha': 0.1301950589895735, 'reg_lambda': 128217.92877568661}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:22:09,282]\u001b[0m Trial 19 finished with value: -0.9867156209806978 and parameters: {'max_depth': -1, 'num_leaves': 50, 'learning_rate': 0.7375077826951069, 'n_estimators': 464, 'reg_alpha': 0.010881066256566312, 'reg_lambda': 3365459.9597059935}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:22:37,494]\u001b[0m Trial 22 finished with value: -1.0577349351024736 and parameters: {'max_depth': 5, 'num_leaves': 35, 'learning_rate': 0.08517290390169899, 'n_estimators': 405, 'reg_alpha': 0.10235298312460943, 'reg_lambda': 62887.129111834794}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:23:12,122]\u001b[0m Trial 21 finished with value: -1.0674718821521259 and parameters: {'max_depth': 0, 'num_leaves': 35, 'learning_rate': 0.1299375239394285, 'n_estimators': 432, 'reg_alpha': 0.35697185591566655, 'reg_lambda': 59412.62315933774}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:23:20,440]\u001b[0m Trial 23 finished with value: -1.0261474188035178 and parameters: {'max_depth': 6, 'num_leaves': 44, 'learning_rate': 0.07575465664412945, 'n_estimators': 412, 'reg_alpha': 21.984652891290438, 'reg_lambda': 88660.03925061558}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 17:23:25,700]\u001b[0m Trial 24 finished with value: -1.0216899908576615 and parameters: {'max_depth': 6, 'num_leaves': 44, 'learning_rate': 0.0775100418886103, 'n_estimators': 409, 'reg_alpha': 0.00020617866856777477, 'reg_lambda': 112616.61216461814}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:23:37,967]\u001b[0m Trial 25 finished with value: -0.9761044143212465 and parameters: {'max_depth': 5, 'num_leaves': 43, 'learning_rate': 0.09827514381908521, 'n_estimators': 434, 'reg_alpha': 0.0006047085363737122, 'reg_lambda': 381774.34890020674}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:23:42,868]\u001b[0m Trial 26 finished with value: -1.018153055768741 and parameters: {'max_depth': 6, 'num_leaves': 44, 'learning_rate': 0.03133506724366838, 'n_estimators': 217, 'reg_alpha': 0.0001563163809758714, 'reg_lambda': 717904.3120237144}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:24:03,770]\u001b[0m Trial 27 finished with value: -0.9720242616959467 and parameters: {'max_depth': 12, 'num_leaves': 44, 'learning_rate': 0.9409404965018339, 'n_estimators': 241, 'reg_alpha': 0.00025635200995146777, 'reg_lambda': 9399632.514120622}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:24:22,714]\u001b[0m Trial 28 finished with value: -1.03765653678121 and parameters: {'max_depth': 13, 'num_leaves': 45, 'learning_rate': 0.9327582881137149, 'n_estimators': 206, 'reg_alpha': 0.00029903532367884096, 'reg_lambda': 435823.5727719258}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:24:49,351]\u001b[0m Trial 31 finished with value: -1.1019979251294665 and parameters: {'max_depth': 14, 'num_leaves': 12, 'learning_rate': 0.35206485738165816, 'n_estimators': 457, 'reg_alpha': 0.09228750248616513, 'reg_lambda': 7559.614509659159}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:25:03,424]\u001b[0m Trial 30 finished with value: -0.970659035021851 and parameters: {'max_depth': 13, 'num_leaves': 46, 'learning_rate': 0.3968338185689808, 'n_estimators': 453, 'reg_alpha': 0.2405999715102058, 'reg_lambda': 6504141.109296468}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:25:12,513]\u001b[0m Trial 29 finished with value: -0.9744235336475187 and parameters: {'max_depth': 13, 'num_leaves': 46, 'learning_rate': 0.9700279737187313, 'n_estimators': 461, 'reg_alpha': 0.06595199130952947, 'reg_lambda': 8757595.436869977}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:25:28,890]\u001b[0m Trial 33 finished with value: -0.9800599459703057 and parameters: {'max_depth': 3, 'num_leaves': 38, 'learning_rate': 0.006549529280694104, 'n_estimators': 458, 'reg_alpha': 0.7146798879741554, 'reg_lambda': 8105.838926737025}. Best is trial 17 with value: -0.9697127297620824.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:25:52,684]\u001b[0m Trial 35 finished with value: -0.9675342159534908 and parameters: {'max_depth': 3, 'num_leaves': 40, 'learning_rate': 0.2853861546489005, 'n_estimators': 493, 'reg_alpha': 1.3068736664436345, 'reg_lambda': 982840.2556999105}. Best is trial 35 with value: -0.9675342159534908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:26:00,557]\u001b[0m Trial 32 finished with value: -1.0997517076448522 and parameters: {'max_depth': 16, 'num_leaves': 38, 'learning_rate': 0.2949924740601208, 'n_estimators': 457, 'reg_alpha': 0.08084034731007508, 'reg_lambda': 7698.5779459170535}. Best is trial 35 with value: -0.9675342159534908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:26:23,205]\u001b[0m Trial 34 finished with value: -0.9772954546934383 and parameters: {'max_depth': 17, 'num_leaves': 39, 'learning_rate': 0.3198899607017246, 'n_estimators': 499, 'reg_alpha': 0.9664701161227875, 'reg_lambda': 9944610.38660657}. Best is trial 35 with value: -0.9675342159534908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:27:14,632]\u001b[0m Trial 37 finished with value: -0.9747117761393445 and parameters: {'max_depth': 9, 'num_leaves': 39, 'learning_rate': 0.25987390201768884, 'n_estimators': 385, 'reg_alpha': 3.3143948029576165, 'reg_lambda': 1336272.3050645737}. Best is trial 35 with value: -0.9675342159534908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:27:25,697]\u001b[0m Trial 36 finished with value: -0.9860572257677258 and parameters: {'max_depth': 17, 'num_leaves': 40, 'learning_rate': 0.2822095517194193, 'n_estimators': 497, 'reg_alpha': 0.019218408871489588, 'reg_lambda': 1194397.8693952535}. Best is trial 35 with value: -0.9675342159534908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:27:32,489]\u001b[0m Trial 38 finished with value: -0.9891230848431708 and parameters: {'max_depth': 10, 'num_leaves': 40, 'learning_rate': 0.2260607727247015, 'n_estimators': 391, 'reg_alpha': 6.371466985624305, 'reg_lambda': 806405.189441884}. Best is trial 35 with value: -0.9675342159534908.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:27:34,737]\u001b[0m Trial 40 finished with value: -0.9522606750463967 and parameters: {'max_depth': 2, 'num_leaves': 47, 'learning_rate': 0.18340479770810544, 'n_estimators': 300, 'reg_alpha': 62.70952836160209, 'reg_lambda': 960062.4480899142}. Best is trial 40 with value: -0.9522606750463967.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:27:48,492]\u001b[0m Trial 42 finished with value: -0.9772621597651157 and parameters: {'max_depth': 3, 'num_leaves': 47, 'learning_rate': 0.03811364533912297, 'n_estimators': 161, 'reg_alpha': 182.18596664300202, 'reg_lambda': 3.0788155286111016}. Best is trial 40 with value: -0.9522606750463967.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:27:56,602]\u001b[0m Trial 43 finished with value: -0.9544155882995495 and parameters: {'max_depth': 2, 'num_leaves': 47, 'learning_rate': 0.03318614076540655, 'n_estimators': 327, 'reg_alpha': 44.869729251229145, 'reg_lambda': 4.084140081083412}. Best is trial 40 with value: -0.9522606750463967.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:27:58,853]\u001b[0m Trial 39 finished with value: -0.9929469241037612 and parameters: {'max_depth': 9, 'num_leaves': 41, 'learning_rate': 0.25071970547944605, 'n_estimators': 383, 'reg_alpha': 4.595179499827841, 'reg_lambda': 508308.43565179256}. Best is trial 40 with value: -0.9522606750463967.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:28:12,849]\u001b[0m Trial 44 finished with value: -0.9439380096062091 and parameters: {'max_depth': 2, 'num_leaves': 47, 'learning_rate': 0.19096348360644613, 'n_estimators': 330, 'reg_alpha': 1.4373251014359727, 'reg_lambda': 469265.80374819174}. Best is trial 44 with value: -0.9439380096062091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:28:22,681]\u001b[0m Trial 46 finished with value: -1.0168747413533548 and parameters: {'max_depth': 2, 'num_leaves': 27, 'learning_rate': 0.13023799630986851, 'n_estimators': 313, 'reg_alpha': 34.579774273460735, 'reg_lambda': 60.349453416423046}. Best is trial 44 with value: -0.9439380096062091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:28:30,049]\u001b[0m Trial 45 finished with value: -0.9459299844366824 and parameters: {'max_depth': 2, 'num_leaves': 42, 'learning_rate': 0.13377654592082758, 'n_estimators': 305, 'reg_alpha': 44.46624366159109, 'reg_lambda': 302559.0699677488}. Best is trial 44 with value: -0.9439380096062091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:28:35,284]\u001b[0m Trial 47 finished with value: -0.9768007575452269 and parameters: {'max_depth': 2, 'num_leaves': 29, 'learning_rate': 0.011551739415611204, 'n_estimators': 299, 'reg_alpha': 100.51901083369447, 'reg_lambda': 12498.381613592906}. Best is trial 44 with value: -0.9439380096062091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:28:43,969]\u001b[0m Trial 48 finished with value: -0.9692907525999773 and parameters: {'max_depth': 2, 'num_leaves': 32, 'learning_rate': 0.011759892717381265, 'n_estimators': 321, 'reg_alpha': 983.4519786551994, 'reg_lambda': 0.019472215343785466}. Best is trial 44 with value: -0.9439380096062091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:28:48,098]\u001b[0m Trial 49 finished with value: -0.9633224686974867 and parameters: {'max_depth': 2, 'num_leaves': 32, 'learning_rate': 0.013983565256292485, 'n_estimators': 324, 'reg_alpha': 1293.9962495963412, 'reg_lambda': 17866.655923854643}. Best is trial 44 with value: -0.9439380096062091.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:28:54,032]\u001b[0m Trial 41 finished with value: -1.1113255312375907 and parameters: {'max_depth': 8, 'num_leaves': 47, 'learning_rate': 0.04026068317038491, 'n_estimators': 392, 'reg_alpha': 37.66283949287251, 'reg_lambda': 27.110775621097552}. Best is trial 44 with value: -0.9439380096062091.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 17:28:59,487]\u001b[0m A new study created in memory with name: no-name-370a017b-f0ca-4d8a-aebc-10e6f116b421\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:29:09,480]\u001b[0m Trial 1 finished with value: -1.7309964058408225 and parameters: {'max_depth': 8, 'num_leaves': 7, 'learning_rate': 0.05244405103509031, 'n_estimators': 195, 'reg_alpha': 0.012069532592174843, 'reg_lambda': 13.733599645495485}. Best is trial 1 with value: -1.7309964058408225.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:29:10,126]\u001b[0m Trial 2 finished with value: -1.8869714654477023 and parameters: {'max_depth': 35, 'num_leaves': 39, 'learning_rate': 2.326390332737876e-06, 'n_estimators': 126, 'reg_alpha': 8080.322411424597, 'reg_lambda': 32890.499556628034}. Best is trial 1 with value: -1.7309964058408225.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:29:28,457]\u001b[0m Trial 3 finished with value: -1.8617750244283564 and parameters: {'max_depth': 42, 'num_leaves': 15, 'learning_rate': 0.00013639130007430755, 'n_estimators': 382, 'reg_alpha': 79.35069783190274, 'reg_lambda': 17.18861938749853}. Best is trial 1 with value: -1.7309964058408225.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:29:34,862]\u001b[0m Trial 0 finished with value: -1.7018895256458533 and parameters: {'max_depth': 20, 'num_leaves': 24, 'learning_rate': 0.003734356894981654, 'n_estimators': 327, 'reg_alpha': 273.9288064873642, 'reg_lambda': 0.021121126770590228}. Best is trial 0 with value: -1.7018895256458533.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:29:42,186]\u001b[0m Trial 4 finished with value: -1.887007077648431 and parameters: {'max_depth': -1, 'num_leaves': 38, 'learning_rate': 3.509185759858119e-07, 'n_estimators': 207, 'reg_alpha': 1.801692458533588e-06, 'reg_lambda': 0.0008579967211071616}. Best is trial 0 with value: -1.7018895256458533.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:29:42,935]\u001b[0m Trial 7 finished with value: -1.7617848547303858 and parameters: {'max_depth': 24, 'num_leaves': 5, 'learning_rate': 0.14604541565374748, 'n_estimators': 206, 'reg_alpha': 2.343451075655937e-05, 'reg_lambda': 0.003913353531598155}. Best is trial 0 with value: -1.7018895256458533.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:29:46,472]\u001b[0m Trial 6 finished with value: -1.8862625708189606 and parameters: {'max_depth': 13, 'num_leaves': 5, 'learning_rate': 3.4936911951030594e-06, 'n_estimators': 490, 'reg_alpha': 518.4701313570847, 'reg_lambda': 13.477514322191793}. Best is trial 0 with value: -1.7018895256458533.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:29:49,900]\u001b[0m Trial 10 finished with value: -1.7779199768005327 and parameters: {'max_depth': 1, 'num_leaves': 14, 'learning_rate': 0.0026478567921771326, 'n_estimators': 122, 'reg_alpha': 0.06337137026163925, 'reg_lambda': 2.4150790328353783e-06}. Best is trial 0 with value: -1.7018895256458533.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:29:53,811]\u001b[0m Trial 5 finished with value: -1.8867213263417955 and parameters: {'max_depth': 30, 'num_leaves': 29, 'learning_rate': 1.7102081098691871e-06, 'n_estimators': 346, 'reg_alpha': 3.419424111065008e-05, 'reg_lambda': 25.638977921786775}. Best is trial 0 with value: -1.7018895256458533.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:30:05,905]\u001b[0m Trial 9 finished with value: -1.6958346925203143 and parameters: {'max_depth': 8, 'num_leaves': 12, 'learning_rate': 0.011840246555075219, 'n_estimators': 365, 'reg_alpha': 0.16564221383216907, 'reg_lambda': 7.323411772260638}. Best is trial 9 with value: -1.6958346925203143.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:30:07,204]\u001b[0m Trial 13 finished with value: -1.8870504891356161 and parameters: {'max_depth': 12, 'num_leaves': 49, 'learning_rate': 0.7730492816198045, 'n_estimators': 2, 'reg_alpha': 3304821.9018714153, 'reg_lambda': 1095023.421518227}. Best is trial 9 with value: -1.6958346925203143.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:30:13,641]\u001b[0m Trial 8 finished with value: -1.815336861870352 and parameters: {'max_depth': 17, 'num_leaves': 29, 'learning_rate': 0.001228941428962757, 'n_estimators': 290, 'reg_alpha': 9.578640396020624, 'reg_lambda': 37273.15917124736}. Best is trial 9 with value: -1.6958346925203143.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:30:38,555]\u001b[0m Trial 11 finished with value: -1.7368650856731769 and parameters: {'max_depth': 27, 'num_leaves': 33, 'learning_rate': 0.007265687127152016, 'n_estimators': 373, 'reg_alpha': 0.26184814035644327, 'reg_lambda': 3.709165421208968}. Best is trial 9 with value: -1.6958346925203143.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:30:40,143]\u001b[0m Trial 14 finished with value: -1.7063378190867613 and parameters: {'max_depth': 19, 'num_leaves': 22, 'learning_rate': 0.0026715244854927057, 'n_estimators': 340, 'reg_alpha': 1.460433572316421, 'reg_lambda': 0.050152819408992806}. Best is trial 9 with value: -1.6958346925203143.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:30:50,160]\u001b[0m Trial 12 finished with value: -1.8512380593922 and parameters: {'max_depth': 41, 'num_leaves': 38, 'learning_rate': 0.5859925340880227, 'n_estimators': 445, 'reg_alpha': 50.67581007284439, 'reg_lambda': 7.538126740468535}. Best is trial 9 with value: -1.6958346925203143.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:30:50,886]\u001b[0m Trial 15 finished with value: -1.6951636522125504 and parameters: {'max_depth': 22, 'num_leaves': 19, 'learning_rate': 0.011260663077437639, 'n_estimators': 430, 'reg_alpha': 0.35703211199632073, 'reg_lambda': 0.09182792423540631}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:31:15,091]\u001b[0m Trial 18 finished with value: -1.870357533847472 and parameters: {'max_depth': 6, 'num_leaves': 20, 'learning_rate': 0.00012365638052161686, 'n_estimators': 272, 'reg_alpha': 0.0016469274152871624, 'reg_lambda': 3.868155766830321e-05}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:31:18,692]\u001b[0m Trial 17 finished with value: -1.8507080466688268 and parameters: {'max_depth': 6, 'num_leaves': 20, 'learning_rate': 0.00017032814709911555, 'n_estimators': 459, 'reg_alpha': 0.003557128442523548, 'reg_lambda': 3.2547546135057003e-05}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:31:20,081]\u001b[0m Trial 19 finished with value: -1.7425377178496144 and parameters: {'max_depth': 8, 'num_leaves': 15, 'learning_rate': 0.03633026504349158, 'n_estimators': 434, 'reg_alpha': 0.0016266328995639407, 'reg_lambda': 3.578053021860477e-05}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:31:20,496]\u001b[0m Trial 16 finished with value: -1.8563655245938313 and parameters: {'max_depth': 19, 'num_leaves': 19, 'learning_rate': 0.00012812273792729722, 'n_estimators': 451, 'reg_alpha': 0.002299953623518995, 'reg_lambda': 0.01996830888886417}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:31:41,689]\u001b[0m Trial 20 finished with value: -1.7570755433340364 and parameters: {'max_depth': 33, 'num_leaves': 12, 'learning_rate': 0.03495867899743786, 'n_estimators': 436, 'reg_alpha': 0.015495658536789143, 'reg_lambda': 8.729018954598396e-07}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:31:45,605]\u001b[0m Trial 22 finished with value: -1.7278020540927725 and parameters: {'max_depth': 32, 'num_leaves': 11, 'learning_rate': 0.017711059521797832, 'n_estimators': 406, 'reg_alpha': 1.1773298021512555, 'reg_lambda': 0.22441651860090625}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:31:47,528]\u001b[0m Trial 23 finished with value: -1.708732632386652 and parameters: {'max_depth': 47, 'num_leaves': 12, 'learning_rate': 0.014497087041379723, 'n_estimators': 400, 'reg_alpha': 1.2303149035150487, 'reg_lambda': 0.332042917626251}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:31:47,536]\u001b[0m Trial 21 finished with value: -1.731746154081311 and parameters: {'max_depth': 47, 'num_leaves': 14, 'learning_rate': 0.029898049821930405, 'n_estimators': 416, 'reg_alpha': 0.291742776960076, 'reg_lambda': 0.09404156115934802}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 17:32:13,399]\u001b[0m Trial 26 finished with value: -1.8262857888619277 and parameters: {'max_depth': 15, 'num_leaves': 24, 'learning_rate': 0.0007032220299339434, 'n_estimators': 297, 'reg_alpha': 7784.521718795448, 'reg_lambda': 0.0010059019446661058}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:32:16,599]\u001b[0m Trial 24 finished with value: -1.7197238423135248 and parameters: {'max_depth': 24, 'num_leaves': 25, 'learning_rate': 0.01027038476905036, 'n_estimators': 314, 'reg_alpha': 1.6026745718268773, 'reg_lambda': 0.2519135902692511}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:32:20,855]\u001b[0m Trial 25 finished with value: -1.7130535824507445 and parameters: {'max_depth': 23, 'num_leaves': 25, 'learning_rate': 0.007936363582472373, 'n_estimators': 316, 'reg_alpha': 0.7199960676615771, 'reg_lambda': 0.11128752205711802}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:32:22,587]\u001b[0m Trial 27 finished with value: -1.7665117157998647 and parameters: {'max_depth': 16, 'num_leaves': 25, 'learning_rate': 0.0015419653449967527, 'n_estimators': 330, 'reg_alpha': 820.8350406512546, 'reg_lambda': 478.8213357509382}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:32:39,393]\u001b[0m Trial 31 finished with value: -1.7691972680330597 and parameters: {'max_depth': 21, 'num_leaves': 18, 'learning_rate': 0.15266607236448884, 'n_estimators': 234, 'reg_alpha': 13.721735260809178, 'reg_lambda': 1.3501262144302724}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:32:42,043]\u001b[0m Trial 29 finished with value: -1.7677199018051386 and parameters: {'max_depth': 22, 'num_leaves': 18, 'learning_rate': 0.11829853448069788, 'n_estimators': 346, 'reg_alpha': 18.782844417666563, 'reg_lambda': 207.87452752769755}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:32:49,406]\u001b[0m Trial 28 finished with value: -1.7097253418410663 and parameters: {'max_depth': 23, 'num_leaves': 25, 'learning_rate': 0.005521231861911377, 'n_estimators': 341, 'reg_alpha': 6.726512706714951, 'reg_lambda': 157.27831113392782}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:32:56,878]\u001b[0m Trial 30 finished with value: -1.7783422481019593 and parameters: {'max_depth': 21, 'num_leaves': 18, 'learning_rate': 0.14214611759504503, 'n_estimators': 497, 'reg_alpha': 0.04294321504435497, 'reg_lambda': 205.65892200019388}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:01,647]\u001b[0m Trial 32 finished with value: -1.778320759138862 and parameters: {'max_depth': 10, 'num_leaves': 8, 'learning_rate': 0.10308210155929898, 'n_estimators': 493, 'reg_alpha': 0.04512723149446307, 'reg_lambda': 0.009030649639514063}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:08,070]\u001b[0m Trial 33 finished with value: -1.8140694406702147 and parameters: {'max_depth': 11, 'num_leaves': 8, 'learning_rate': 0.0004403097975473484, 'n_estimators': 495, 'reg_alpha': 0.04249734011119329, 'reg_lambda': 0.010197601338454692}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:11,249]\u001b[0m Trial 35 finished with value: -1.7069879677287165 and parameters: {'max_depth': 11, 'num_leaves': 8, 'learning_rate': 0.0037879355271528284, 'n_estimators': 258, 'reg_alpha': 0.07840395424985182, 'reg_lambda': 0.027174648724687694}. Best is trial 15 with value: -1.6951636522125504.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:17,243]\u001b[0m Trial 34 finished with value: -1.6887761589185772 and parameters: {'max_depth': 11, 'num_leaves': 9, 'learning_rate': 0.002726956050973258, 'n_estimators': 500, 'reg_alpha': 0.11489617686948145, 'reg_lambda': 0.011861832405035985}. Best is trial 34 with value: -1.6887761589185772.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:35,236]\u001b[0m Trial 39 finished with value: -1.7720093627838478 and parameters: {'max_depth': 4, 'num_leaves': 10, 'learning_rate': 0.001015744014137196, 'n_estimators': 362, 'reg_alpha': 153.57640353316359, 'reg_lambda': 1.4592697418804714}. Best is trial 34 with value: -1.6887761589185772.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:46,765]\u001b[0m Trial 37 finished with value: -1.7054972113457594 and parameters: {'max_depth': 26, 'num_leaves': 22, 'learning_rate': 0.0031339152060028633, 'n_estimators': 382, 'reg_alpha': 137.45851079999804, 'reg_lambda': 1.2052665904404503}. Best is trial 34 with value: -1.6887761589185772.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:49,776]\u001b[0m Trial 36 finished with value: -1.7193896247534102 and parameters: {'max_depth': 27, 'num_leaves': 31, 'learning_rate': 0.004274852956029304, 'n_estimators': 373, 'reg_alpha': 110.09939370010997, 'reg_lambda': 1.3895503648749992}. Best is trial 34 with value: -1.6887761589185772.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:51,466]\u001b[0m Trial 40 finished with value: -1.6996872455183103 and parameters: {'max_depth': 3, 'num_leaves': 31, 'learning_rate': 0.003567116455304522, 'n_estimators': 390, 'reg_alpha': 0.00013559551959810385, 'reg_lambda': 0.0015603209940072207}. Best is trial 34 with value: -1.6887761589185772.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:55,378]\u001b[0m Trial 42 finished with value: -1.6506158108598534 and parameters: {'max_depth': 2, 'num_leaves': 16, 'learning_rate': 0.017294696053782563, 'n_estimators': 157, 'reg_alpha': 0.00022051637869032145, 'reg_lambda': 0.0003886400635607334}. Best is trial 42 with value: -1.6506158108598534.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:57,055]\u001b[0m Trial 43 finished with value: -1.6472577895937826 and parameters: {'max_depth': 2, 'num_leaves': 35, 'learning_rate': 0.015165672075377569, 'n_estimators': 167, 'reg_alpha': 7.10180154555686e-05, 'reg_lambda': 0.0019699259441943954}. Best is trial 43 with value: -1.6472577895937826.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:33:59,590]\u001b[0m Trial 44 finished with value: -1.6133633808674595 and parameters: {'max_depth': 1, 'num_leaves': 34, 'learning_rate': 0.013899304149975096, 'n_estimators': 161, 'reg_alpha': 0.0005014056542711594, 'reg_lambda': 0.0015703361756090805}. Best is trial 44 with value: -1.6133633808674595.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:01,447]\u001b[0m Trial 38 finished with value: -1.7058283906022442 and parameters: {'max_depth': 27, 'num_leaves': 33, 'learning_rate': 0.002839745136091629, 'n_estimators': 370, 'reg_alpha': 159.0824085347297, 'reg_lambda': 1.2519864333332253}. Best is trial 44 with value: -1.6133633808674595.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:19,984]\u001b[0m Trial 45 finished with value: -1.7508575843738565 and parameters: {'max_depth': 0, 'num_leaves': 41, 'learning_rate': 0.016624626793595113, 'n_estimators': 144, 'reg_alpha': 1.6683153965393182e-07, 'reg_lambda': 0.00031784288326042876}. Best is trial 44 with value: -1.6133633808674595.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:20,280]\u001b[0m Trial 46 finished with value: -1.743281404206969 and parameters: {'max_depth': -1, 'num_leaves': 35, 'learning_rate': 0.023976964047816036, 'n_estimators': 147, 'reg_alpha': 3.5504908756385953e-06, 'reg_lambda': 0.0005245262942137056}. Best is trial 44 with value: -1.6133633808674595.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:24,104]\u001b[0m Trial 49 finished with value: -1.6682734679323454 and parameters: {'max_depth': 2, 'num_leaves': 42, 'learning_rate': 0.06587209900382726, 'n_estimators': 89, 'reg_alpha': 0.0002616246112198201, 'reg_lambda': 0.004652950799321505}. Best is trial 44 with value: -1.6133633808674595.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:24,748]\u001b[0m Trial 47 finished with value: -1.7518930981541134 and parameters: {'max_depth': -1, 'num_leaves': 41, 'learning_rate': 0.018680265376452485, 'n_estimators': 148, 'reg_alpha': 2.686506553158241e-06, 'reg_lambda': 0.00023073464672163218}. Best is trial 44 with value: -1.6133633808674595.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:25,080]\u001b[0m Trial 48 finished with value: -1.7030874374738028 and parameters: {'max_depth': 2, 'num_leaves': 43, 'learning_rate': 0.05916854738522602, 'n_estimators': 165, 'reg_alpha': 0.00020075874100582006, 'reg_lambda': 0.00023263130770866285}. Best is trial 44 with value: -1.6133633808674595.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:34,939]\u001b[0m Trial 41 finished with value: -1.8036952507436337 and parameters: {'max_depth': 14, 'num_leaves': 32, 'learning_rate': 0.0003769098118325149, 'n_estimators': 467, 'reg_alpha': 0.00023340456155145666, 'reg_lambda': 0.0009046191547835237}. Best is trial 44 with value: -1.6133633808674595.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 17:34:38,156]\u001b[0m A new study created in memory with name: no-name-4c4a8534-48c5-4d6a-a90c-4f51b29532ca\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:42,231]\u001b[0m Trial 0 finished with value: -2.0079453714568976 and parameters: {'max_depth': 40, 'num_leaves': 48, 'learning_rate': 0.00938350784543943, 'n_estimators': 10, 'reg_alpha': 561.1035018415475, 'reg_lambda': 3551259.467036493}. Best is trial 0 with value: -2.0079453714568976.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:47,129]\u001b[0m Trial 1 finished with value: -2.0105658942903757 and parameters: {'max_depth': -1, 'num_leaves': 6, 'learning_rate': 7.115301817087817e-07, 'n_estimators': 224, 'reg_alpha': 1773115.6060331236, 'reg_lambda': 18164.428064797725}. Best is trial 0 with value: -2.0079453714568976.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:50,321]\u001b[0m Trial 4 finished with value: -2.0105658942903757 and parameters: {'max_depth': 24, 'num_leaves': 19, 'learning_rate': 3.929103304548927e-07, 'n_estimators': 212, 'reg_alpha': 2675205.6234067865, 'reg_lambda': 86113.30730706676}. Best is trial 0 with value: -2.0079453714568976.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:34:59,767]\u001b[0m Trial 5 finished with value: -2.0105658942903757 and parameters: {'max_depth': 33, 'num_leaves': 44, 'learning_rate': 9.719418599009811e-06, 'n_estimators': 399, 'reg_alpha': 5273527.660448676, 'reg_lambda': 2989387.3714664252}. Best is trial 0 with value: -2.0079453714568976.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:35:02,473]\u001b[0m Trial 7 finished with value: -2.0102663306081547 and parameters: {'max_depth': 14, 'num_leaves': 48, 'learning_rate': 0.0011588324953672987, 'n_estimators': 5, 'reg_alpha': 206.29903597261654, 'reg_lambda': 1835731.9017939963}. Best is trial 0 with value: -2.0079453714568976.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:35:10,265]\u001b[0m Trial 2 finished with value: -1.7555039479537473 and parameters: {'max_depth': -1, 'num_leaves': 7, 'learning_rate': 0.044495183594733284, 'n_estimators': 426, 'reg_alpha': 0.01734053703042262, 'reg_lambda': 0.08155320738477378}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:35:13,953]\u001b[0m Trial 6 finished with value: -2.0097913023681127 and parameters: {'max_depth': 9, 'num_leaves': 25, 'learning_rate': 9.398511187534143e-06, 'n_estimators': 130, 'reg_alpha': 1.63006263397822e-05, 'reg_lambda': 33.925087157109054}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:35:26,053]\u001b[0m Trial 8 finished with value: -1.853024059336049 and parameters: {'max_depth': 20, 'num_leaves': 5, 'learning_rate': 0.005328688928273927, 'n_estimators': 398, 'reg_alpha': 40879.16410488323, 'reg_lambda': 453680.59583670454}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:35:27,348]\u001b[0m Trial 9 finished with value: -1.7596146354611495 and parameters: {'max_depth': 24, 'num_leaves': 35, 'learning_rate': 0.010012216296352825, 'n_estimators': 88, 'reg_alpha': 8753.116777174722, 'reg_lambda': 0.00011449420562132673}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:35:36,091]\u001b[0m Trial 11 finished with value: -1.956889554986307 and parameters: {'max_depth': 28, 'num_leaves': 9, 'learning_rate': 0.562447527523654, 'n_estimators': 134, 'reg_alpha': 7.172323385097474e-05, 'reg_lambda': 9.844598744853865e-06}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:35:37,917]\u001b[0m Trial 12 finished with value: -1.9856089554167364 and parameters: {'max_depth': 13, 'num_leaves': 38, 'learning_rate': 0.005127513588062664, 'n_estimators': 64, 'reg_alpha': 0.00018439193910445322, 'reg_lambda': 1020759.189747927}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:35:58,539]\u001b[0m Trial 3 finished with value: -2.0104969930844736 and parameters: {'max_depth': 16, 'num_leaves': 30, 'learning_rate': 2.660389065493589e-07, 'n_estimators': 475, 'reg_alpha': 0.007220021786061599, 'reg_lambda': 8999.569342043073}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:36:16,157]\u001b[0m Trial 13 finished with value: -2.1080524239262872 and parameters: {'max_depth': 0, 'num_leaves': 17, 'learning_rate': 0.6347022969540393, 'n_estimators': 492, 'reg_alpha': 0.04533399385256665, 'reg_lambda': 0.016417879131891924}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:36:40,340]\u001b[0m Trial 14 finished with value: -1.9596257419801755 and parameters: {'max_depth': -1, 'num_leaves': 35, 'learning_rate': 0.23351084625654783, 'n_estimators': 464, 'reg_alpha': 0.08790585068423179, 'reg_lambda': 0.0007003855995253854}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:36:46,183]\u001b[0m Trial 15 finished with value: -1.911630396332297 and parameters: {'max_depth': 0, 'num_leaves': 34, 'learning_rate': 0.09807824673738383, 'n_estimators': 330, 'reg_alpha': 0.4232945311653609, 'reg_lambda': 0.0011123330257528765}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:36:48,063]\u001b[0m Trial 10 finished with value: -2.0105095332672027 and parameters: {'max_depth': 38, 'num_leaves': 43, 'learning_rate': 2.0887504819605415e-07, 'n_estimators': 479, 'reg_alpha': 0.00045907305376069934, 'reg_lambda': 8040.209396025029}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:37:04,868]\u001b[0m Trial 16 finished with value: -1.8544781475228607 and parameters: {'max_depth': 43, 'num_leaves': 33, 'learning_rate': 0.043742730594383626, 'n_estimators': 321, 'reg_alpha': 1.3061491028491454e-07, 'reg_lambda': 0.0002661751988222673}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:37:08,758]\u001b[0m Trial 17 finished with value: -1.8395810026717188 and parameters: {'max_depth': 37, 'num_leaves': 15, 'learning_rate': 0.07695787378869391, 'n_estimators': 299, 'reg_alpha': 7.1556922033796235, 'reg_lambda': 1.163236008699534e-07}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:37:26,934]\u001b[0m Trial 18 finished with value: -1.8204070331738977 and parameters: {'max_depth': 44, 'num_leaves': 23, 'learning_rate': 0.03999292408292916, 'n_estimators': 302, 'reg_alpha': 1.4089093914892783e-07, 'reg_lambda': 4.2986068501143633e-07}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:37:28,238]\u001b[0m Trial 19 finished with value: -1.8194167459220816 and parameters: {'max_depth': 46, 'num_leaves': 23, 'learning_rate': 0.036963665227516575, 'n_estimators': 293, 'reg_alpha': 3.5822916340598727e-07, 'reg_lambda': 4.841814129246787e-07}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:37:30,846]\u001b[0m Trial 21 finished with value: -1.9824185684712983 and parameters: {'max_depth': 6, 'num_leaves': 23, 'learning_rate': 0.0003237415981878033, 'n_estimators': 147, 'reg_alpha': 6.047520981682354, 'reg_lambda': 1.6645526751397526}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:37:45,020]\u001b[0m Trial 22 finished with value: -1.972512614644236 and parameters: {'max_depth': 29, 'num_leaves': 12, 'learning_rate': 0.00043187504016989754, 'n_estimators': 159, 'reg_alpha': 12.272927682353574, 'reg_lambda': 0.21471475098414186}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:37:47,936]\u001b[0m Trial 20 finished with value: -1.9410437216508005 and parameters: {'max_depth': 8, 'num_leaves': 21, 'learning_rate': 0.0004384247079598553, 'n_estimators': 290, 'reg_alpha': 4.958926211429475, 'reg_lambda': 4.534776431932522e-07}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:38:05,011]\u001b[0m Trial 23 finished with value: -1.9610354934358614 and parameters: {'max_depth': 28, 'num_leaves': 40, 'learning_rate': 0.0005270584468327356, 'n_estimators': 159, 'reg_alpha': 6.4272370095602955, 'reg_lambda': 0.33398725741238927}. Best is trial 2 with value: -1.7555039479537473.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 17:38:10,042]\u001b[0m Trial 24 finished with value: -1.704601630467254 and parameters: {'max_depth': 30, 'num_leaves': 13, 'learning_rate': 0.012147026558037816, 'n_estimators': 383, 'reg_alpha': 0.0037273407717611754, 'reg_lambda': 5.078237622608865e-06}. Best is trial 24 with value: -1.704601630467254.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:38:47,056]\u001b[0m Trial 28 finished with value: -1.7008944093394454 and parameters: {'max_depth': 21, 'num_leaves': 12, 'learning_rate': 0.01294290746096375, 'n_estimators': 390, 'reg_alpha': 0.004299793650969783, 'reg_lambda': 2.098793718402176e-05}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:38:50,302]\u001b[0m Trial 26 finished with value: -1.7930426373591801 and parameters: {'max_depth': 47, 'num_leaves': 29, 'learning_rate': 0.015718619762713125, 'n_estimators': 381, 'reg_alpha': 5.60977194525662e-06, 'reg_lambda': 1.4484491646881917e-05}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:39:02,103]\u001b[0m Trial 25 finished with value: -1.8055561742191655 and parameters: {'max_depth': 46, 'num_leaves': 38, 'learning_rate': 0.015501318428864335, 'n_estimators': 385, 'reg_alpha': 0.005013631143020951, 'reg_lambda': 6.055501762730709e-06}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:39:09,945]\u001b[0m Trial 27 finished with value: -1.7821393986017025 and parameters: {'max_depth': 22, 'num_leaves': 29, 'learning_rate': 0.0136805573272662, 'n_estimators': 381, 'reg_alpha': 0.003718580639515269, 'reg_lambda': 2.483453861241305e-05}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:39:26,426]\u001b[0m Trial 29 finished with value: -1.7386303547053183 and parameters: {'max_depth': 20, 'num_leaves': 10, 'learning_rate': 0.002540468116130486, 'n_estimators': 397, 'reg_alpha': 0.005395989011532178, 'reg_lambda': 6.848105237671263e-06}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:39:30,081]\u001b[0m Trial 30 finished with value: -1.7808028936423448 and parameters: {'max_depth': 18, 'num_leaves': 12, 'learning_rate': 0.0017645089727266082, 'n_estimators': 361, 'reg_alpha': 0.002882075229487784, 'reg_lambda': 0.006368103151657902}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:39:49,256]\u001b[0m Trial 31 finished with value: -1.7336562590213398 and parameters: {'max_depth': 33, 'num_leaves': 11, 'learning_rate': 0.002396926662486189, 'n_estimators': 439, 'reg_alpha': 0.0016695167383768818, 'reg_lambda': 0.006838889759602905}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:40:00,470]\u001b[0m Trial 32 finished with value: -1.73818916887544 and parameters: {'max_depth': 32, 'num_leaves': 12, 'learning_rate': 0.0022397920395517755, 'n_estimators': 444, 'reg_alpha': 0.0008689389762956167, 'reg_lambda': 0.004511593248436947}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:40:06,078]\u001b[0m Trial 33 finished with value: -1.7691983325046425 and parameters: {'max_depth': 18, 'num_leaves': 12, 'learning_rate': 0.0020279705191799677, 'n_estimators': 348, 'reg_alpha': 0.001075809410439126, 'reg_lambda': 0.001743735261503807}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:40:11,643]\u001b[0m Trial 34 finished with value: -1.7339472432697958 and parameters: {'max_depth': 5, 'num_leaves': 9, 'learning_rate': 0.002380948151415617, 'n_estimators': 441, 'reg_alpha': 0.052319932081141426, 'reg_lambda': 3.566631788931936e-06}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:40:35,942]\u001b[0m Trial 35 finished with value: -1.720721252019348 and parameters: {'max_depth': 31, 'num_leaves': 11, 'learning_rate': 0.0027481896425824806, 'n_estimators': 445, 'reg_alpha': 0.0006555481406056581, 'reg_lambda': 6.234371017419978e-05}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:40:55,090]\u001b[0m Trial 36 finished with value: -1.7257608274055798 and parameters: {'max_depth': 33, 'num_leaves': 14, 'learning_rate': 0.002494930636631751, 'n_estimators': 451, 'reg_alpha': 0.0007926264092950911, 'reg_lambda': 0.003073615848963283}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:40:59,308]\u001b[0m Trial 37 finished with value: -1.9828704308936458 and parameters: {'max_depth': 33, 'num_leaves': 15, 'learning_rate': 0.00011398694339552448, 'n_estimators': 424, 'reg_alpha': 0.08963268108426173, 'reg_lambda': 0.00016060538489546722}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:41:07,073]\u001b[0m Trial 38 finished with value: -1.7057884215209833 and parameters: {'max_depth': 35, 'num_leaves': 16, 'learning_rate': 0.005181864284112816, 'n_estimators': 431, 'reg_alpha': 0.08192858795760749, 'reg_lambda': 0.0001678786462818877}. Best is trial 28 with value: -1.7008944093394454.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:41:21,757]\u001b[0m Trial 41 finished with value: -1.7007411345317311 and parameters: {'max_depth': 36, 'num_leaves': 7, 'learning_rate': 0.006182396315887445, 'n_estimators': 249, 'reg_alpha': 0.000126276557696326, 'reg_lambda': 4.798818438318794e-05}. Best is trial 41 with value: -1.7007411345317311.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:41:27,722]\u001b[0m Trial 40 finished with value: -1.9926725574455353 and parameters: {'max_depth': 35, 'num_leaves': 15, 'learning_rate': 0.00012860290665747724, 'n_estimators': 237, 'reg_alpha': 0.00011710280181157047, 'reg_lambda': 7.417376200310147e-05}. Best is trial 41 with value: -1.7007411345317311.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:41:29,893]\u001b[0m Trial 42 finished with value: -1.6850641141848117 and parameters: {'max_depth': 26, 'num_leaves': 7, 'learning_rate': 0.007167693634545555, 'n_estimators': 259, 'reg_alpha': 0.01594261888462542, 'reg_lambda': 8.778658846602759e-05}. Best is trial 42 with value: -1.6850641141848117.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:41:34,110]\u001b[0m Trial 39 finished with value: -1.9852204439072862 and parameters: {'max_depth': 34, 'num_leaves': 16, 'learning_rate': 0.00010389435445853732, 'n_estimators': 423, 'reg_alpha': 0.00018014389842504875, 'reg_lambda': 0.00012777050592210472}. Best is trial 42 with value: -1.6850641141848117.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:41:41,414]\u001b[0m Trial 43 finished with value: -1.6718804722178238 and parameters: {'max_depth': 36, 'num_leaves': 7, 'learning_rate': 0.009792391936563897, 'n_estimators': 220, 'reg_alpha': 0.013287709246925282, 'reg_lambda': 4.214326299063595e-05}. Best is trial 43 with value: -1.6718804722178238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:41:44,562]\u001b[0m Trial 44 finished with value: -1.7249911998101806 and parameters: {'max_depth': 39, 'num_leaves': 6, 'learning_rate': 0.006149317004718606, 'n_estimators': 195, 'reg_alpha': 0.009507654513850912, 'reg_lambda': 5.501444140215574e-05}. Best is trial 43 with value: -1.6718804722178238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:41:45,138]\u001b[0m Trial 45 finished with value: -1.6556254178754173 and parameters: {'max_depth': 40, 'num_leaves': 5, 'learning_rate': 0.023366762545222693, 'n_estimators': 197, 'reg_alpha': 0.011780481310396147, 'reg_lambda': 0.00037994534067765543}. Best is trial 45 with value: -1.6556254178754173.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:41:53,986]\u001b[0m Trial 46 finished with value: -1.7026027450020278 and parameters: {'max_depth': 26, 'num_leaves': 7, 'learning_rate': 0.007316669528817777, 'n_estimators': 206, 'reg_alpha': 0.017782886288569524, 'reg_lambda': 2.6992198803170568e-06}. Best is trial 45 with value: -1.6556254178754173.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:42:01,090]\u001b[0m Trial 47 finished with value: -1.6652809522419165 and parameters: {'max_depth': 25, 'num_leaves': 6, 'learning_rate': 0.02429045818670706, 'n_estimators': 265, 'reg_alpha': 0.010169886831148521, 'reg_lambda': 1.510711877633804e-06}. Best is trial 45 with value: -1.6556254178754173.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:42:01,419]\u001b[0m Trial 49 finished with value: -1.659125393783929 and parameters: {'max_depth': 42, 'num_leaves': 7, 'learning_rate': 0.02527132492649024, 'n_estimators': 198, 'reg_alpha': 0.027334861019732478, 'reg_lambda': 0.0005236280272776624}. Best is trial 45 with value: -1.6556254178754173.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:42:03,186]\u001b[0m Trial 48 finished with value: -1.6534339060608045 and parameters: {'max_depth': 25, 'num_leaves': 7, 'learning_rate': 0.016610133098237393, 'n_estimators': 256, 'reg_alpha': 0.011001832318193393, 'reg_lambda': 2.2015555442120063e-06}. Best is trial 48 with value: -1.6534339060608045.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|                                                        | 2/16 [32:32<4:10:54, 1075.34s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 17:42:11,566]\u001b[0m A new study created in memory with name: no-name-1d01165c-8251-465b-8768-fca50e4298a8\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:42:28,145]\u001b[0m Trial 2 finished with value: -0.9615210375246253 and parameters: {'max_depth': 1, 'num_leaves': 14, 'learning_rate': 0.4002228969690624, 'n_estimators': 102, 'reg_alpha': 6.424510802003678e-06, 'reg_lambda': 0.7036410579734151}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:42:29,739]\u001b[0m Trial 1 finished with value: -1.3972228373719657 and parameters: {'max_depth': 1, 'num_leaves': 38, 'learning_rate': 6.707911876683385e-05, 'n_estimators': 120, 'reg_alpha': 0.588211108423678, 'reg_lambda': 0.0015818942652871283}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:42:49,153]\u001b[0m Trial 3 finished with value: -1.1462041177341313 and parameters: {'max_depth': 24, 'num_leaves': 44, 'learning_rate': 0.00817090021260038, 'n_estimators': 66, 'reg_alpha': 0.01187718543492473, 'reg_lambda': 16063.238027496414}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:43:40,336]\u001b[0m Trial 0 finished with value: -1.3995651923115908 and parameters: {'max_depth': 6, 'num_leaves': 48, 'learning_rate': 8.522815547022939e-06, 'n_estimators': 209, 'reg_alpha': 4.623174788918504e-05, 'reg_lambda': 5.560649449783799e-05}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:43:50,097]\u001b[0m Trial 7 finished with value: -1.3999471499672311 and parameters: {'max_depth': 34, 'num_leaves': 41, 'learning_rate': 7.118593521378493e-05, 'n_estimators': 49, 'reg_alpha': 664539.6390044177, 'reg_lambda': 0.21869412204039496}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:43:53,193]\u001b[0m Trial 6 finished with value: -1.2232267846430656 and parameters: {'max_depth': 3, 'num_leaves': 6, 'learning_rate': 0.0007984102608392417, 'n_estimators': 368, 'reg_alpha': 0.0002810736603010686, 'reg_lambda': 1688.5051685588348}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:44:25,864]\u001b[0m Trial 9 finished with value: -1.4009587902965688 and parameters: {'max_depth': 34, 'num_leaves': 6, 'learning_rate': 9.892777419348936e-07, 'n_estimators': 165, 'reg_alpha': 96.07114576520127, 'reg_lambda': 0.0009305036831128465}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:45:16,262]\u001b[0m Trial 10 finished with value: -1.3603592302022076 and parameters: {'max_depth': 2, 'num_leaves': 10, 'learning_rate': 0.00014701973858198062, 'n_estimators': 369, 'reg_alpha': 3.2679165491996e-07, 'reg_lambda': 0.0001565532128092006}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:45:35,007]\u001b[0m Trial 11 finished with value: -1.1379942416445301 and parameters: {'max_depth': 43, 'num_leaves': 17, 'learning_rate': 0.0076768931183388974, 'n_estimators': 57, 'reg_alpha': 0.0006869986626938709, 'reg_lambda': 0.0002252665742346}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:45:39,847]\u001b[0m Trial 8 finished with value: -1.0960761213707668 and parameters: {'max_depth': 21, 'num_leaves': 31, 'learning_rate': 0.5506996056629243, 'n_estimators': 463, 'reg_alpha': 0.00011611741116774139, 'reg_lambda': 1.4796273809233796e-05}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:45:48,490]\u001b[0m Trial 4 finished with value: -1.399847013383726 and parameters: {'max_depth': 22, 'num_leaves': 50, 'learning_rate': 4.052077893093809e-06, 'n_estimators': 363, 'reg_alpha': 3.7336155416168193, 'reg_lambda': 0.000702041210670714}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:46:35,159]\u001b[0m Trial 12 finished with value: -1.3919967614848585 and parameters: {'max_depth': 37, 'num_leaves': 31, 'learning_rate': 7.86855923766707e-05, 'n_estimators': 137, 'reg_alpha': 0.0861253620176269, 'reg_lambda': 4.827899460923249e-07}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:46:50,060]\u001b[0m Trial 5 finished with value: -1.3995711280806566 and parameters: {'max_depth': 22, 'num_leaves': 47, 'learning_rate': 3.617388149107233e-06, 'n_estimators': 498, 'reg_alpha': 0.006570988714974092, 'reg_lambda': 8.70017461786852e-07}. Best is trial 2 with value: -0.9615210375246253.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:46:57,460]\u001b[0m Trial 13 finished with value: -0.9305421096127671 and parameters: {'max_depth': 13, 'num_leaves': 21, 'learning_rate': 0.6261774265583836, 'n_estimators': 281, 'reg_alpha': 1.2033451966803808e-07, 'reg_lambda': 8123177.348536602}. Best is trial 13 with value: -0.9305421096127671.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:47:39,899]\u001b[0m Trial 14 finished with value: -1.183829809789893 and parameters: {'max_depth': 14, 'num_leaves': 27, 'learning_rate': 0.9874278501598392, 'n_estimators': 492, 'reg_alpha': 6.204180200126306e-07, 'reg_lambda': 1.1560561658724696e-07}. Best is trial 13 with value: -0.9305421096127671.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:47:54,541]\u001b[0m Trial 16 finished with value: -1.128371754516686 and parameters: {'max_depth': 12, 'num_leaves': 22, 'learning_rate': 0.7277873925113395, 'n_estimators': 289, 'reg_alpha': 7.636185150810594e-07, 'reg_lambda': 6.3263643104405745}. Best is trial 13 with value: -0.9305421096127671.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:48:08,935]\u001b[0m Trial 17 finished with value: -0.929621482652701 and parameters: {'max_depth': 11, 'num_leaves': 19, 'learning_rate': 0.7025168228417551, 'n_estimators': 272, 'reg_alpha': 2.604989227861155e-07, 'reg_lambda': 9502565.137033647}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:48:20,592]\u001b[0m Trial 15 finished with value: -1.0854833076834762 and parameters: {'max_depth': 14, 'num_leaves': 22, 'learning_rate': 0.7318282142732695, 'n_estimators': 498, 'reg_alpha': 1.953706728333518e-06, 'reg_lambda': 16.57763863584255}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:49:04,158]\u001b[0m Trial 18 finished with value: -0.9358423968030294 and parameters: {'max_depth': 11, 'num_leaves': 18, 'learning_rate': 0.14331169132645755, 'n_estimators': 278, 'reg_alpha': 1.121140215393242e-07, 'reg_lambda': 2700580.8220791183}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:49:10,754]\u001b[0m Trial 19 finished with value: -0.9519301514963692 and parameters: {'max_depth': 11, 'num_leaves': 16, 'learning_rate': 0.10179605904129436, 'n_estimators': 270, 'reg_alpha': 1.5688323504241223e-07, 'reg_lambda': 2573773.0973957125}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:49:27,847]\u001b[0m Trial 20 finished with value: -1.024562848227874 and parameters: {'max_depth': 12, 'num_leaves': 20, 'learning_rate': 0.06349650550072587, 'n_estimators': 273, 'reg_alpha': 1.739771187417192e-07, 'reg_lambda': 4076810.6951220836}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:49:43,850]\u001b[0m Trial 21 finished with value: -1.011916522419637 and parameters: {'max_depth': 8, 'num_leaves': 20, 'learning_rate': 0.0591152098426593, 'n_estimators': 278, 'reg_alpha': 1.1018294574537829e-07, 'reg_lambda': 3348277.795797054}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:50:03,311]\u001b[0m Trial 23 finished with value: -1.1562809042561317 and parameters: {'max_depth': 18, 'num_leaves': 27, 'learning_rate': 0.06576375849652989, 'n_estimators': 203, 'reg_alpha': 1.3528468221095208e-05, 'reg_lambda': 9315543.888569294}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:50:14,142]\u001b[0m Trial 22 finished with value: -1.0094399156179061 and parameters: {'max_depth': 8, 'num_leaves': 26, 'learning_rate': 0.0699112464289754, 'n_estimators': 225, 'reg_alpha': 9.30272398101382e-06, 'reg_lambda': 3088675.338203321}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 17:50:51,618]\u001b[0m Trial 24 finished with value: -1.1429868938506507 and parameters: {'max_depth': 8, 'num_leaves': 26, 'learning_rate': 0.046245076192704376, 'n_estimators': 325, 'reg_alpha': 2.1340123571968256e-05, 'reg_lambda': 9513831.313814487}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:51:13,204]\u001b[0m Trial 25 finished with value: -0.971946271821027 and parameters: {'max_depth': 17, 'num_leaves': 26, 'learning_rate': 0.11196681647193275, 'n_estimators': 208, 'reg_alpha': 7.454459846142054e-06, 'reg_lambda': 119961.81498178898}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:51:30,262]\u001b[0m Trial 26 finished with value: -0.9950796492788156 and parameters: {'max_depth': 17, 'num_leaves': 12, 'learning_rate': 0.2113303485014559, 'n_estimators': 324, 'reg_alpha': 6.921102008645304e-06, 'reg_lambda': 111947.85979740127}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:51:38,729]\u001b[0m Trial 27 finished with value: -0.9889118694549184 and parameters: {'max_depth': 17, 'num_leaves': 11, 'learning_rate': 0.21598884845407243, 'n_estimators': 328, 'reg_alpha': 6.12174500099315e-06, 'reg_lambda': 126162.41812512881}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:52:26,098]\u001b[0m Trial 28 finished with value: -0.9639215751376334 and parameters: {'max_depth': 17, 'num_leaves': 13, 'learning_rate': 0.22779963879547407, 'n_estimators': 327, 'reg_alpha': 2.266256241840909e-06, 'reg_lambda': 232802.57247296593}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:52:39,357]\u001b[0m Trial 29 finished with value: -0.9752477435018826 and parameters: {'max_depth': 27, 'num_leaves': 12, 'learning_rate': 0.25155326779432163, 'n_estimators': 321, 'reg_alpha': 1.0602381776593556e-07, 'reg_lambda': 182458.4834684875}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:54:01,870]\u001b[0m Trial 30 finished with value: -0.9530029456745709 and parameters: {'max_depth': 26, 'num_leaves': 31, 'learning_rate': 0.012231869490136799, 'n_estimators': 403, 'reg_alpha': 0.0009473581874378006, 'reg_lambda': 277233.4834117107}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:54:28,308]\u001b[0m Trial 32 finished with value: -0.9718263769248404 and parameters: {'max_depth': 28, 'num_leaves': 18, 'learning_rate': 0.016510219444062064, 'n_estimators': 417, 'reg_alpha': 7.856414929023194e-05, 'reg_lambda': 1472.7015611987915}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:54:28,752]\u001b[0m Trial 31 finished with value: -0.9736348946649633 and parameters: {'max_depth': 28, 'num_leaves': 32, 'learning_rate': 0.012916535070426222, 'n_estimators': 415, 'reg_alpha': 0.000406888221931215, 'reg_lambda': 293.2983533328248}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:54:59,879]\u001b[0m Trial 34 finished with value: -1.0868798261294197 and parameters: {'max_depth': 5, 'num_leaves': 17, 'learning_rate': 0.9994914255169609, 'n_estimators': 245, 'reg_alpha': 1.0500993902760176e-07, 'reg_lambda': 4540.7490409076745}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:55:10,686]\u001b[0m Trial 33 finished with value: -0.9886159565535813 and parameters: {'max_depth': 7, 'num_leaves': 32, 'learning_rate': 0.017132392029214856, 'n_estimators': 419, 'reg_alpha': 8.075788136163733e-05, 'reg_lambda': 1319.9666185884855}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:55:25,292]\u001b[0m Trial 35 finished with value: -1.3073603129439122 and parameters: {'max_depth': 5, 'num_leaves': 17, 'learning_rate': 0.0023009997102678855, 'n_estimators': 236, 'reg_alpha': 1.0657353137234983e-07, 'reg_lambda': 1023512.3245678497}. Best is trial 17 with value: -0.929621482652701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:55:42,381]\u001b[0m Trial 36 finished with value: -0.9193436244433645 and parameters: {'max_depth': 6, 'num_leaves': 16, 'learning_rate': 0.3220605557131586, 'n_estimators': 249, 'reg_alpha': 6.126595053262537e-07, 'reg_lambda': 1246174.4338362885}. Best is trial 36 with value: -0.9193436244433645.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:56:15,525]\u001b[0m Trial 37 finished with value: -0.9148054710751665 and parameters: {'max_depth': 11, 'num_leaves': 15, 'learning_rate': 0.3375226648607895, 'n_estimators': 244, 'reg_alpha': 8.823247836895107e-07, 'reg_lambda': 1294468.1573579935}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:56:16,885]\u001b[0m Trial 38 finished with value: -0.9188325001343476 and parameters: {'max_depth': -1, 'num_leaves': 23, 'learning_rate': 0.37815140547848053, 'n_estimators': 178, 'reg_alpha': 6.046932018416213e-07, 'reg_lambda': 1246126.7346237618}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:56:22,882]\u001b[0m Trial 41 finished with value: -0.9254582215282341 and parameters: {'max_depth': 5, 'num_leaves': 9, 'learning_rate': 0.3722468887539759, 'n_estimators': 9, 'reg_alpha': 1.8563353177362834e-06, 'reg_lambda': 23304.847190529443}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:56:24,859]\u001b[0m Trial 39 finished with value: -1.0225446877585043 and parameters: {'max_depth': 12, 'num_leaves': 24, 'learning_rate': 0.2941025967540371, 'n_estimators': 163, 'reg_alpha': 1.2893728802822705e-06, 'reg_lambda': 24188.76872915129}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:56:34,487]\u001b[0m Trial 43 finished with value: -0.9352074218077187 and parameters: {'max_depth': -1, 'num_leaves': 8, 'learning_rate': 0.3017526141127483, 'n_estimators': 18, 'reg_alpha': 1.8727834094167675e-06, 'reg_lambda': 12654.019731927765}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:56:38,744]\u001b[0m Trial 44 finished with value: -0.9269634911117125 and parameters: {'max_depth': 0, 'num_leaves': 10, 'learning_rate': 0.3339832385688819, 'n_estimators': 30, 'reg_alpha': 1.6299108417106432e-06, 'reg_lambda': 466324.63452438836}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:56:39,822]\u001b[0m Trial 40 finished with value: -1.026237243869823 and parameters: {'max_depth': 0, 'num_leaves': 23, 'learning_rate': 0.35088514314036967, 'n_estimators': 160, 'reg_alpha': 1.043367984303281e-06, 'reg_lambda': 17578.069534068283}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:56:41,830]\u001b[0m Trial 42 finished with value: -0.9655330198650272 and parameters: {'max_depth': 1, 'num_leaves': 23, 'learning_rate': 0.37244290870925323, 'n_estimators': 179, 'reg_alpha': 1.2339401802278462e-06, 'reg_lambda': 27036.505409782385}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:56:46,851]\u001b[0m Trial 47 finished with value: -1.3534370779104985 and parameters: {'max_depth': 2, 'num_leaves': 9, 'learning_rate': 0.03227407939196534, 'n_estimators': 7, 'reg_alpha': 4.1943087975194344e-05, 'reg_lambda': 826141.3745877708}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:57:05,565]\u001b[0m Trial 48 finished with value: -1.0422449569696823 and parameters: {'max_depth': 3, 'num_leaves': 5, 'learning_rate': 0.036141165130172105, 'n_estimators': 96, 'reg_alpha': 4.847109854135787e-05, 'reg_lambda': 697320.4930568042}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:57:07,899]\u001b[0m Trial 46 finished with value: -1.0613736926331585 and parameters: {'max_depth': -1, 'num_leaves': 9, 'learning_rate': 0.030185483866019613, 'n_estimators': 100, 'reg_alpha': 2.6792395816398548e-05, 'reg_lambda': 680093.9481172243}. Best is trial 37 with value: -0.9148054710751665.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:57:07,942]\u001b[0m Trial 45 finished with value: -0.9134100661664587 and parameters: {'max_depth': -1, 'num_leaves': 15, 'learning_rate': 0.3776586254813462, 'n_estimators': 91, 'reg_alpha': 8.96581424208295e-07, 'reg_lambda': 868934.3716386309}. Best is trial 45 with value: -0.9134100661664587.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:57:09,091]\u001b[0m Trial 49 finished with value: -0.9426175918488178 and parameters: {'max_depth': 4, 'num_leaves': 15, 'learning_rate': 0.13544634698286265, 'n_estimators': 82, 'reg_alpha': 3.117447246217102e-05, 'reg_lambda': 694855.063254289}. Best is trial 45 with value: -0.9134100661664587.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|                                                     | 3/16 [47:39<3:36:21, 998.60s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 17:57:15,654]\u001b[0m A new study created in memory with name: no-name-75ae15b5-3609-4f36-98b2-5e9a28970bff\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:57:27,216]\u001b[0m Trial 0 finished with value: -1.6230292474766757 and parameters: {'max_depth': 42, 'num_leaves': 39, 'learning_rate': 0.03632903026036339, 'n_estimators': 165, 'reg_alpha': 0.0009279809901262659, 'reg_lambda': 4273280.887407052}. Best is trial 0 with value: -1.6230292474766757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:57:46,458]\u001b[0m Trial 3 finished with value: -1.7318068613468738 and parameters: {'max_depth': 17, 'num_leaves': 27, 'learning_rate': 0.0004718958510612301, 'n_estimators': 163, 'reg_alpha': 0.00821096572907666, 'reg_lambda': 0.15165242440959584}. Best is trial 0 with value: -1.6230292474766757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:57:55,598]\u001b[0m Trial 2 finished with value: -1.8364802785996543 and parameters: {'max_depth': 31, 'num_leaves': 46, 'learning_rate': 3.280437567497484e-07, 'n_estimators': 450, 'reg_alpha': 6.877639061167975, 'reg_lambda': 91149.80012908395}. Best is trial 0 with value: -1.6230292474766757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:58:16,304]\u001b[0m Trial 4 finished with value: -0.9738914549230765 and parameters: {'max_depth': 9, 'num_leaves': 34, 'learning_rate': 0.0062914776058103404, 'n_estimators': 243, 'reg_alpha': 0.00016772799955446977, 'reg_lambda': 329.92059845678335}. Best is trial 4 with value: -0.9738914549230765.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:58:17,815]\u001b[0m Trial 5 finished with value: -0.8885030453395258 and parameters: {'max_depth': 36, 'num_leaves': 6, 'learning_rate': 0.005362484099992922, 'n_estimators': 462, 'reg_alpha': 1.271063294149209, 'reg_lambda': 5.149211338063829}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:58:22,221]\u001b[0m Trial 6 finished with value: -1.836512727653566 and parameters: {'max_depth': 38, 'num_leaves': 6, 'learning_rate': 1.396859054909435e-07, 'n_estimators': 395, 'reg_alpha': 0.0010680727618624568, 'reg_lambda': 2161.865577751801}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:58:26,270]\u001b[0m Trial 1 finished with value: -1.806234444896439 and parameters: {'max_depth': 30, 'num_leaves': 20, 'learning_rate': 4.188815160342255e-05, 'n_estimators': 497, 'reg_alpha': 4.120852924373127, 'reg_lambda': 700.9932694944674}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:58:37,366]\u001b[0m Trial 8 finished with value: -1.5870028411514117 and parameters: {'max_depth': 45, 'num_leaves': 41, 'learning_rate': 0.002389852180100033, 'n_estimators': 83, 'reg_alpha': 1.1479526430336817e-05, 'reg_lambda': 77.25255415572795}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:58:47,662]\u001b[0m Trial 9 finished with value: -1.7120119116038883 and parameters: {'max_depth': 19, 'num_leaves': 34, 'learning_rate': 0.00038772152365897355, 'n_estimators': 479, 'reg_alpha': 111808.59253087768, 'reg_lambda': 28.14012860879166}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:58:56,365]\u001b[0m Trial 12 finished with value: -1.8365629179663419 and parameters: {'max_depth': 41, 'num_leaves': 26, 'learning_rate': 7.423089539963095e-06, 'n_estimators': 141, 'reg_alpha': 0.8307872042429534, 'reg_lambda': 6268073.424763212}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:58:57,298]\u001b[0m Trial 11 finished with value: -1.820446826813249 and parameters: {'max_depth': 19, 'num_leaves': 42, 'learning_rate': 0.0003006606136990828, 'n_estimators': 366, 'reg_alpha': 6.056961449503022e-07, 'reg_lambda': 1124682.7124207255}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:11,661]\u001b[0m Trial 14 finished with value: -1.0065311185907027 and parameters: {'max_depth': 3, 'num_leaves': 5, 'learning_rate': 0.2552490577718052, 'n_estimators': 284, 'reg_alpha': 4.4567153887752736e-07, 'reg_lambda': 0.0003549279994919536}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:14,465]\u001b[0m Trial 13 finished with value: -0.9287546625213281 and parameters: {'max_depth': 4, 'num_leaves': 7, 'learning_rate': 0.6566514136258365, 'n_estimators': 327, 'reg_alpha': 3.431748056049406e-07, 'reg_lambda': 0.0001048730278508227}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:23,000]\u001b[0m Trial 7 finished with value: -0.9213451502828467 and parameters: {'max_depth': 14, 'num_leaves': 48, 'learning_rate': 0.1763410581181803, 'n_estimators': 345, 'reg_alpha': 19.518679966712053, 'reg_lambda': 5.705784265466085e-05}. Best is trial 5 with value: -0.8885030453395258.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:39,853]\u001b[0m Trial 15 finished with value: -0.8718997099077743 and parameters: {'max_depth': 5, 'num_leaves': 15, 'learning_rate': 0.011456120596045742, 'n_estimators': 278, 'reg_alpha': 1229.9818858125625, 'reg_lambda': 0.07233252612579888}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:40,868]\u001b[0m Trial 16 finished with value: -0.9669091798676969 and parameters: {'max_depth': -1, 'num_leaves': 15, 'learning_rate': 0.9054365779313546, 'n_estimators': 317, 'reg_alpha': 2.8410317230745996e-07, 'reg_lambda': 6.309019290584135e-07}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:42,003]\u001b[0m Trial 18 finished with value: -1.8074614113331433 and parameters: {'max_depth': 27, 'num_leaves': 15, 'learning_rate': 0.01937073078708359, 'n_estimators': 1, 'reg_alpha': 3574.1405185020803, 'reg_lambda': 0.08762055601709835}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:43,100]\u001b[0m Trial 19 finished with value: -1.7788102004445672 and parameters: {'max_depth': 28, 'num_leaves': 13, 'learning_rate': 0.019219281392407472, 'n_estimators': 2, 'reg_alpha': 1119.9142983548409, 'reg_lambda': 0.2662973760307981}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:46,903]\u001b[0m Trial 17 finished with value: -0.8887931618200199 and parameters: {'max_depth': 28, 'num_leaves': 16, 'learning_rate': 0.08256490464335409, 'n_estimators': 398, 'reg_alpha': 2454.9751693474846, 'reg_lambda': 2.875393990719028e-06}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:55,213]\u001b[0m Trial 20 finished with value: -1.836593331707063 and parameters: {'max_depth': 35, 'num_leaves': 12, 'learning_rate': 0.04170459234624723, 'n_estimators': 420, 'reg_alpha': 5917729.954895308, 'reg_lambda': 4.397286885987615}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:55,238]\u001b[0m Trial 22 finished with value: -1.836593331707063 and parameters: {'max_depth': 35, 'num_leaves': 20, 'learning_rate': 0.0037701817204917783, 'n_estimators': 236, 'reg_alpha': 2495524.0063230717, 'reg_lambda': 0.00936441991419647}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 17:59:56,335]\u001b[0m Trial 21 finished with value: -1.836593331707063 and parameters: {'max_depth': 33, 'num_leaves': 21, 'learning_rate': 0.0027376653815223712, 'n_estimators': 418, 'reg_alpha': 1482883.213149592, 'reg_lambda': 3.5210832305935584}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:00:12,014]\u001b[0m Trial 10 finished with value: -0.9105687407392472 and parameters: {'max_depth': 9, 'num_leaves': 49, 'learning_rate': 0.004902107738926467, 'n_estimators': 457, 'reg_alpha': 0.0017888853232463102, 'reg_lambda': 847.5203857027884}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:00:19,613]\u001b[0m Trial 24 finished with value: -0.8745581210254342 and parameters: {'max_depth': 24, 'num_leaves': 20, 'learning_rate': 0.11551185355077172, 'n_estimators': 433, 'reg_alpha': 1149.0936265959642, 'reg_lambda': 6.3303657070417065}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:00:27,233]\u001b[0m Trial 25 finished with value: -0.9650482334224575 and parameters: {'max_depth': 10, 'num_leaves': 10, 'learning_rate': 0.10580558401662404, 'n_estimators': 381, 'reg_alpha': 195.52069850475252, 'reg_lambda': 2.8589802902345554e-07}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:00:33,703]\u001b[0m Trial 23 finished with value: -1.2295417615905282 and parameters: {'max_depth': 22, 'num_leaves': 22, 'learning_rate': 0.002780846622824546, 'n_estimators': 237, 'reg_alpha': 0.26311038884440313, 'reg_lambda': 0.026416095316777966}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:00:35,412]\u001b[0m Trial 26 finished with value: -0.9329611811369942 and parameters: {'max_depth': 24, 'num_leaves': 10, 'learning_rate': 0.10001500685702372, 'n_estimators': 281, 'reg_alpha': 459.82575923895865, 'reg_lambda': 0.007881226686128246}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:00:41,988]\u001b[0m Trial 27 finished with value: -0.9583825138576219 and parameters: {'max_depth': 24, 'num_leaves': 9, 'learning_rate': 0.0882798130620002, 'n_estimators': 287, 'reg_alpha': 0.1970363516670935, 'reg_lambda': 0.00770620010436529}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:00:54,789]\u001b[0m Trial 29 finished with value: -0.9348341746829333 and parameters: {'max_depth': 47, 'num_leaves': 10, 'learning_rate': 0.015152148336039312, 'n_estimators': 292, 'reg_alpha': 38797.78529357472, 'reg_lambda': 2.7342745185880375}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:01:06,074]\u001b[0m Trial 30 finished with value: -0.926454960633796 and parameters: {'max_depth': 24, 'num_leaves': 18, 'learning_rate': 0.012855911071373436, 'n_estimators': 438, 'reg_alpha': 35629.65269116601, 'reg_lambda': 1.1907051282539123}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:01:12,433]\u001b[0m Trial 28 finished with value: -0.9083624777606141 and parameters: {'max_depth': 23, 'num_leaves': 24, 'learning_rate': 0.016522925676510293, 'n_estimators': 275, 'reg_alpha': 0.19368306893871, 'reg_lambda': 0.021705782780585627}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:01:15,008]\u001b[0m Trial 31 finished with value: -0.926604794113101 and parameters: {'max_depth': 13, 'num_leaves': 18, 'learning_rate': 0.01325747889221811, 'n_estimators': 451, 'reg_alpha': 24236.76199197355, 'reg_lambda': 0.8351060357441444}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:01:24,173]\u001b[0m Trial 33 finished with value: -0.9093818117848523 and parameters: {'max_depth': 40, 'num_leaves': 31, 'learning_rate': 0.3289088732607348, 'n_estimators': 205, 'reg_alpha': 132.75255021470775, 'reg_lambda': 21.857967183286547}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:01:55,039]\u001b[0m Trial 34 finished with value: -0.9236544485741779 and parameters: {'max_depth': 39, 'num_leaves': 17, 'learning_rate': 0.050334769947969135, 'n_estimators': 407, 'reg_alpha': 63.53202520675943, 'reg_lambda': 17.104425138512788}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:02:09,393]\u001b[0m Trial 32 finished with value: -0.8993038470045756 and parameters: {'max_depth': 40, 'num_leaves': 31, 'learning_rate': 0.0324695669343938, 'n_estimators': 440, 'reg_alpha': 67.60544610233201, 'reg_lambda': 0.5196473589842058}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:02:15,040]\u001b[0m Trial 36 finished with value: -0.929094885537259 and parameters: {'max_depth': 30, 'num_leaves': 17, 'learning_rate': 0.051384503734868935, 'n_estimators': 485, 'reg_alpha': 21.676791938960626, 'reg_lambda': 4.331016128180697e-06}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:02:31,176]\u001b[0m Trial 38 finished with value: -0.9200388002069584 and parameters: {'max_depth': 29, 'num_leaves': 14, 'learning_rate': 0.26297539141600423, 'n_estimators': 495, 'reg_alpha': 1186.8718134899525, 'reg_lambda': 166.78550114506575}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:02:31,577]\u001b[0m Trial 39 finished with value: -0.876253347605335 and parameters: {'max_depth': 27, 'num_leaves': 24, 'learning_rate': 0.5050008962138306, 'n_estimators': 353, 'reg_alpha': 1730.1227145849282, 'reg_lambda': 0.0012229726394795556}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:02:50,542]\u001b[0m Trial 35 finished with value: -0.8974499865821093 and parameters: {'max_depth': 28, 'num_leaves': 32, 'learning_rate': 0.03755205480880307, 'n_estimators': 499, 'reg_alpha': 186.96829257000573, 'reg_lambda': 20.67176616167234}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:02:56,338]\u001b[0m Trial 37 finished with value: -0.9158987732046967 and parameters: {'max_depth': 30, 'num_leaves': 14, 'learning_rate': 0.05149609333588244, 'n_estimators': 487, 'reg_alpha': 9.264308635408684, 'reg_lambda': 4346.022727257008}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:07,486]\u001b[0m Trial 40 finished with value: -1.3219829484385741 and parameters: {'max_depth': 33, 'num_leaves': 8, 'learning_rate': 0.0012061727996846264, 'n_estimators': 365, 'reg_alpha': 4.4192842092577775, 'reg_lambda': 1.2824606589177457e-07}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:19,684]\u001b[0m Trial 44 finished with value: -0.9034260506660238 and parameters: {'max_depth': 20, 'num_leaves': 23, 'learning_rate': 0.4888159056425989, 'n_estimators': 337, 'reg_alpha': 4525.2399684843585, 'reg_lambda': 0.0007970482483616904}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:23,835]\u001b[0m Trial 41 finished with value: -0.9219947824689342 and parameters: {'max_depth': 32, 'num_leaves': 24, 'learning_rate': 0.5855480813681713, 'n_estimators': 354, 'reg_alpha': 5.709240847220994, 'reg_lambda': 2883.486719369668}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:37,610]\u001b[0m Trial 45 finished with value: -0.8866844838231528 and parameters: {'max_depth': 26, 'num_leaves': 28, 'learning_rate': 0.1758975278315517, 'n_estimators': 389, 'reg_alpha': 4465.9925902081, 'reg_lambda': 0.15468645461681163}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:38,399]\u001b[0m Trial 43 finished with value: -0.9069602764296523 and parameters: {'max_depth': 16, 'num_leaves': 25, 'learning_rate': 0.49852897827352766, 'n_estimators': 353, 'reg_alpha': 0.02013105500559438, 'reg_lambda': 0.001722532885675475}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:41,157]\u001b[0m Trial 42 finished with value: -0.9826645837876402 and parameters: {'max_depth': 33, 'num_leaves': 24, 'learning_rate': 0.9946558731846443, 'n_estimators': 366, 'reg_alpha': 9.841814376798043, 'reg_lambda': 4298.835982406164}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:45,913]\u001b[0m Trial 46 finished with value: -0.8906772426471827 and parameters: {'max_depth': 16, 'num_leaves': 27, 'learning_rate': 0.17457267753512706, 'n_estimators': 388, 'reg_alpha': 2767.5939968827433, 'reg_lambda': 1.4405552203364933e-05}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:52,347]\u001b[0m Trial 47 finished with value: -0.9071007705430234 and parameters: {'max_depth': 16, 'num_leaves': 27, 'learning_rate': 0.3153553602541061, 'n_estimators': 381, 'reg_alpha': 7701.67241194843, 'reg_lambda': 0.0018584873357168602}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:53,215]\u001b[0m Trial 49 finished with value: -1.5338989735728124 and parameters: {'max_depth': 43, 'num_leaves': 29, 'learning_rate': 0.1526607661889751, 'n_estimators': 313, 'reg_alpha': 205159.63429228967, 'reg_lambda': 0.289790550949162}. Best is trial 15 with value: -0.8718997099077743.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:03:56,478]\u001b[0m Trial 48 finished with value: -0.8693479927866223 and parameters: {'max_depth': 26, 'num_leaves': 28, 'learning_rate': 0.1880018142968745, 'n_estimators': 392, 'reg_alpha': 746.2068029495574, 'reg_lambda': 0.1416566367293462}. Best is trial 48 with value: -0.8693479927866223.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|                                                 | 4/16 [54:25<2:32:56, 764.74s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:04:02,395]\u001b[0m A new study created in memory with name: no-name-cef3caaf-2c22-4430-a975-40ef7391fa20\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:04:35,330]\u001b[0m Trial 0 finished with value: -1.279749796911224 and parameters: {'max_depth': 5, 'num_leaves': 22, 'learning_rate': 7.962940461174878e-07, 'n_estimators': 318, 'reg_alpha': 1.9335355327256077e-06, 'reg_lambda': 70.32721401500572}. Best is trial 0 with value: -1.279749796911224.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:04:38,156]\u001b[0m Trial 1 finished with value: -1.2796083739942166 and parameters: {'max_depth': 30, 'num_leaves': 42, 'learning_rate': 2.595999213873801e-06, 'n_estimators': 174, 'reg_alpha': 240.64081493176604, 'reg_lambda': 5.4958727124166075e-06}. Best is trial 1 with value: -1.2796083739942166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:04:47,735]\u001b[0m Trial 5 finished with value: -1.1478417345506031 and parameters: {'max_depth': 8, 'num_leaves': 5, 'learning_rate': 0.008415570630662502, 'n_estimators': 170, 'reg_alpha': 4.1484601547584536e-07, 'reg_lambda': 533413.8376822517}. Best is trial 5 with value: -1.1478417345506031.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:04:52,253]\u001b[0m Trial 4 finished with value: -0.957099903688116 and parameters: {'max_depth': 39, 'num_leaves': 18, 'learning_rate': 0.03128887681871345, 'n_estimators': 143, 'reg_alpha': 26.65899467022181, 'reg_lambda': 0.030407794006093482}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:03,647]\u001b[0m Trial 7 finished with value: -1.2727776914362987 and parameters: {'max_depth': 8, 'num_leaves': 26, 'learning_rate': 0.0009267490925777452, 'n_estimators': 124, 'reg_alpha': 3.69789790097515e-06, 'reg_lambda': 1136970.891705525}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:06,697]\u001b[0m Trial 3 finished with value: -1.279569087527906 and parameters: {'max_depth': 47, 'num_leaves': 25, 'learning_rate': 1.2676699841978173e-06, 'n_estimators': 483, 'reg_alpha': 9.00654392084809e-07, 'reg_lambda': 6631.575379459602}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:10,066]\u001b[0m Trial 8 finished with value: -1.2799906421586542 and parameters: {'max_depth': 8, 'num_leaves': 18, 'learning_rate': 0.00019310214679411187, 'n_estimators': 192, 'reg_alpha': 976752.5071133944, 'reg_lambda': 136.6733526222515}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:10,122]\u001b[0m Trial 6 finished with value: -1.2798299626289238 and parameters: {'max_depth': 43, 'num_leaves': 18, 'learning_rate': 5.351268975684416e-07, 'n_estimators': 184, 'reg_alpha': 2.965369299984001e-07, 'reg_lambda': 0.04130173676086491}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:18,597]\u001b[0m Trial 2 finished with value: -1.2798051952522156 and parameters: {'max_depth': 35, 'num_leaves': 35, 'learning_rate': 3.236286600421001e-07, 'n_estimators': 418, 'reg_alpha': 3.147632400221537e-06, 'reg_lambda': 4.091143593521806e-07}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:19,659]\u001b[0m Trial 10 finished with value: -1.1686677182341791 and parameters: {'max_depth': 30, 'num_leaves': 37, 'learning_rate': 0.010920003266210341, 'n_estimators': 212, 'reg_alpha': 123493.98679812717, 'reg_lambda': 39285.03430740101}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:22,231]\u001b[0m Trial 13 finished with value: -1.0102758503560372 and parameters: {'max_depth': 19, 'num_leaves': 7, 'learning_rate': 0.8575408541181909, 'n_estimators': 7, 'reg_alpha': 0.06874974541783782, 'reg_lambda': 0.007813621239227624}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:24,895]\u001b[0m Trial 14 finished with value: -1.0364732563995318 and parameters: {'max_depth': 19, 'num_leaves': 6, 'learning_rate': 0.7834638150026234, 'n_estimators': 12, 'reg_alpha': 0.11983914392500315, 'reg_lambda': 0.008461004437729198}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:26,980]\u001b[0m Trial 12 finished with value: -1.2680524503695596 and parameters: {'max_depth': 13, 'num_leaves': 41, 'learning_rate': 0.0007032106166299685, 'n_estimators': 29, 'reg_alpha': 0.02855047335833192, 'reg_lambda': 4070.733105099782}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:27,650]\u001b[0m Trial 15 finished with value: -0.99245613531048 and parameters: {'max_depth': 17, 'num_leaves': 12, 'learning_rate': 0.6995945800267893, 'n_estimators': 9, 'reg_alpha': 0.553267398450721, 'reg_lambda': 0.0017030411347386312}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:28,968]\u001b[0m Trial 11 finished with value: -0.9735267241703045 and parameters: {'max_depth': 32, 'num_leaves': 5, 'learning_rate': 0.005246259784561022, 'n_estimators': 365, 'reg_alpha': 55.30484518165075, 'reg_lambda': 93.86239713023235}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:34,204]\u001b[0m Trial 16 finished with value: -1.021925418121241 and parameters: {'max_depth': 19, 'num_leaves': 10, 'learning_rate': 0.5348513577723393, 'n_estimators': 88, 'reg_alpha': 28.97280514865287, 'reg_lambda': 0.00038969586807055865}. Best is trial 4 with value: -0.957099903688116.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:36,204]\u001b[0m Trial 17 finished with value: -0.9505223760331336 and parameters: {'max_depth': -1, 'num_leaves': 13, 'learning_rate': 0.15812740882250415, 'n_estimators': 74, 'reg_alpha': 30.634290289877303, 'reg_lambda': 5.1265061479418945e-05}. Best is trial 17 with value: -0.9505223760331336.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:46,239]\u001b[0m Trial 20 finished with value: -0.9497942560473012 and parameters: {'max_depth': -1, 'num_leaves': 15, 'learning_rate': 0.061841995282093956, 'n_estimators': 97, 'reg_alpha': 10188.26783110751, 'reg_lambda': 1.3985223003003147}. Best is trial 20 with value: -0.9497942560473012.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:55,474]\u001b[0m Trial 19 finished with value: -0.9394851841095447 and parameters: {'max_depth': 39, 'num_leaves': 13, 'learning_rate': 0.05194951294729889, 'n_estimators': 293, 'reg_alpha': 3827.39257568429, 'reg_lambda': 2.999184315246437}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:05:55,578]\u001b[0m Trial 18 finished with value: -0.9452601297930383 and parameters: {'max_depth': 38, 'num_leaves': 12, 'learning_rate': 0.032037390964391066, 'n_estimators': 315, 'reg_alpha': 67.00270008242771, 'reg_lambda': 2.36572029869266}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:00,103]\u001b[0m Trial 21 finished with value: -0.9568274884816881 and parameters: {'max_depth': 0, 'num_leaves': 50, 'learning_rate': 0.0778610672938363, 'n_estimators': 275, 'reg_alpha': 14949.393423401767, 'reg_lambda': 1.3146980299810394}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:05,886]\u001b[0m Trial 9 finished with value: -1.2795157600198872 and parameters: {'max_depth': 9, 'num_leaves': 27, 'learning_rate': 1.746913755911684e-06, 'n_estimators': 388, 'reg_alpha': 0.03320590100313397, 'reg_lambda': 4663.035362294063}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:12,124]\u001b[0m Trial 23 finished with value: -0.9446168405269162 and parameters: {'max_depth': 25, 'num_leaves': 50, 'learning_rate': 0.12853774138530483, 'n_estimators': 291, 'reg_alpha': 6418.497033923296, 'reg_lambda': 1.484015141544735}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:13,331]\u001b[0m Trial 22 finished with value: -0.9432746542680666 and parameters: {'max_depth': 25, 'num_leaves': 32, 'learning_rate': 0.10781252136540628, 'n_estimators': 274, 'reg_alpha': 4400.752084438607, 'reg_lambda': 0.5710172365741955}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:06:19,193]\u001b[0m Trial 26 finished with value: -1.2798910730878017 and parameters: {'max_depth': 26, 'num_leaves': 32, 'learning_rate': 0.15429619268007688, 'n_estimators': 277, 'reg_alpha': 1916873.4447523274, 'reg_lambda': 0.18532503662966326}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:20,008]\u001b[0m Trial 27 finished with value: -1.2798910730878017 and parameters: {'max_depth': 29, 'num_leaves': 32, 'learning_rate': 0.18119489766011537, 'n_estimators': 247, 'reg_alpha': 4917748.173359944, 'reg_lambda': 0.3470373220311589}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:20,904]\u001b[0m Trial 24 finished with value: -0.940298479964367 and parameters: {'max_depth': 26, 'num_leaves': 15, 'learning_rate': 0.07196036758700576, 'n_estimators': 265, 'reg_alpha': 6616.343499032223, 'reg_lambda': 1.1715662828419071}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:25,332]\u001b[0m Trial 28 finished with value: -1.2798910730878017 and parameters: {'max_depth': 26, 'num_leaves': 47, 'learning_rate': 0.22913921425353845, 'n_estimators': 244, 'reg_alpha': 8831336.74760873, 'reg_lambda': 8.252195190005276}. Best is trial 19 with value: -0.9394851841095447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:28,627]\u001b[0m Trial 25 finished with value: -0.9349816143659695 and parameters: {'max_depth': 38, 'num_leaves': 15, 'learning_rate': 0.06850739413554803, 'n_estimators': 268, 'reg_alpha': 1745.924296076742, 'reg_lambda': 0.661209796985123}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:42,769]\u001b[0m Trial 32 finished with value: -1.8237050882962351 and parameters: {'max_depth': 43, 'num_leaves': 21, 'learning_rate': 0.018714488870994125, 'n_estimators': 317, 'reg_alpha': 173457.08199589493, 'reg_lambda': 16.08319424143063}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:06:54,395]\u001b[0m Trial 30 finished with value: -0.9410839545111696 and parameters: {'max_depth': 23, 'num_leaves': 22, 'learning_rate': 0.018440504782331352, 'n_estimators': 239, 'reg_alpha': 1603.6634468226925, 'reg_lambda': 32.13082785544871}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:07:07,939]\u001b[0m Trial 29 finished with value: -0.9353362274889305 and parameters: {'max_depth': 24, 'num_leaves': 49, 'learning_rate': 0.01961420909971288, 'n_estimators': 331, 'reg_alpha': 3974.4235068849493, 'reg_lambda': 10.17014143509887}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:07:13,499]\u001b[0m Trial 31 finished with value: -0.9379699976700386 and parameters: {'max_depth': 35, 'num_leaves': 23, 'learning_rate': 0.027259302762246446, 'n_estimators': 351, 'reg_alpha': 850.9233918597275, 'reg_lambda': 17.34513303096363}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:07:33,529]\u001b[0m Trial 35 finished with value: -1.0123836095367547 and parameters: {'max_depth': 35, 'num_leaves': 9, 'learning_rate': 0.003015841441724745, 'n_estimators': 341, 'reg_alpha': 625.2243831907073, 'reg_lambda': 227.42045489949842}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:07:37,829]\u001b[0m Trial 33 finished with value: -0.9789585399744618 and parameters: {'max_depth': 36, 'num_leaves': 23, 'learning_rate': 0.0037140426179854934, 'n_estimators': 361, 'reg_alpha': 301.8593405568643, 'reg_lambda': 266.99417116889936}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:07:47,514]\u001b[0m Trial 34 finished with value: -0.9491146868569311 and parameters: {'max_depth': 35, 'num_leaves': 23, 'learning_rate': 0.005652703292341117, 'n_estimators': 351, 'reg_alpha': 985.8275961893213, 'reg_lambda': 52.46021263394043}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:07:58,709]\u001b[0m Trial 38 finished with value: -1.0419516562822124 and parameters: {'max_depth': 42, 'num_leaves': 20, 'learning_rate': 0.02634083523790373, 'n_estimators': 441, 'reg_alpha': 61979.86998383734, 'reg_lambda': 10.678373271264746}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:08:04,116]\u001b[0m Trial 39 finished with value: -1.0212547388532633 and parameters: {'max_depth': 42, 'num_leaves': 20, 'learning_rate': 0.03631638361030776, 'n_estimators': 475, 'reg_alpha': 43330.00806532464, 'reg_lambda': 0.10640347564925204}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:08:06,599]\u001b[0m Trial 36 finished with value: -0.9540495563942926 and parameters: {'max_depth': 35, 'num_leaves': 24, 'learning_rate': 0.005745426072955974, 'n_estimators': 357, 'reg_alpha': 772.700821035656, 'reg_lambda': 220.1859931821654}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:08:13,866]\u001b[0m Trial 40 finished with value: -1.015186602302581 and parameters: {'max_depth': 46, 'num_leaves': 30, 'learning_rate': 0.03853448047939162, 'n_estimators': 426, 'reg_alpha': 40098.31918175781, 'reg_lambda': 0.07580592077162404}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:08:16,734]\u001b[0m Trial 42 finished with value: -1.905079868294289 and parameters: {'max_depth': 32, 'num_leaves': 30, 'learning_rate': 0.31108044754102976, 'n_estimators': 392, 'reg_alpha': 459720.6756057484, 'reg_lambda': 0.06702303478943217}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:08:22,325]\u001b[0m Trial 43 finished with value: -2.262072433056579 and parameters: {'max_depth': 39, 'num_leaves': 16, 'learning_rate': 0.3323224222365077, 'n_estimators': 303, 'reg_alpha': 289594.3435145499, 'reg_lambda': 8.384851801936193}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:08:30,054]\u001b[0m Trial 37 finished with value: -0.9463106769863235 and parameters: {'max_depth': 40, 'num_leaves': 23, 'learning_rate': 0.03794916562594857, 'n_estimators': 432, 'reg_alpha': 432.31231455321955, 'reg_lambda': 9.730867196499139}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:08:39,246]\u001b[0m Trial 44 finished with value: -0.9421976506754459 and parameters: {'max_depth': 38, 'num_leaves': 16, 'learning_rate': 0.06093277478574526, 'n_estimators': 303, 'reg_alpha': 5101.672568619745, 'reg_lambda': 4.508026387533933}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:08:41,383]\u001b[0m Trial 45 finished with value: -0.9375725672554465 and parameters: {'max_depth': 28, 'num_leaves': 15, 'learning_rate': 0.06375151378235307, 'n_estimators': 226, 'reg_alpha': 5403.614299579399, 'reg_lambda': 2.8741871105188928}. Best is trial 25 with value: -0.9349816143659695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:08:49,281]\u001b[0m Trial 46 finished with value: -0.9323330692184074 and parameters: {'max_depth': 31, 'num_leaves': 16, 'learning_rate': 0.0682839647607828, 'n_estimators': 218, 'reg_alpha': 3058.060001428201, 'reg_lambda': 0.5408896917527801}. Best is trial 46 with value: -0.9323330692184074.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:05,273]\u001b[0m Trial 47 finished with value: -0.9623081433109952 and parameters: {'max_depth': 32, 'num_leaves': 18, 'learning_rate': 0.008680007773671082, 'n_estimators': 216, 'reg_alpha': 6.302467064224103, 'reg_lambda': 0.6048487025396112}. Best is trial 46 with value: -0.9323330692184074.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:09,166]\u001b[0m Trial 41 finished with value: -0.967853162693378 and parameters: {'max_depth': 47, 'num_leaves': 29, 'learning_rate': 0.011307619333769036, 'n_estimators': 392, 'reg_alpha': 5.00408715002556, 'reg_lambda': 0.12404728405738863}. Best is trial 46 with value: -0.9323330692184074.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:12,223]\u001b[0m Trial 49 finished with value: -0.9597569286326408 and parameters: {'max_depth': 29, 'num_leaves': 18, 'learning_rate': 0.012789671479888229, 'n_estimators': 210, 'reg_alpha': 3.1163790344222346, 'reg_lambda': 0.5199605176190581}. Best is trial 46 with value: -0.9323330692184074.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:15,640]\u001b[0m Trial 48 finished with value: -0.9591048743937156 and parameters: {'max_depth': 31, 'num_leaves': 38, 'learning_rate': 0.014031677345115021, 'n_estimators': 207, 'reg_alpha': 153.17601139598312, 'reg_lambda': 0.6222367247328403}. Best is trial 46 with value: -0.9323330692184074.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|                                             | 5/16 [59:44<1:50:43, 603.93s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:09:20,270]\u001b[0m A new study created in memory with name: no-name-36a74a71-c5ba-4233-acf4-e83c2d3d7441\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:22,011]\u001b[0m Trial 1 finished with value: -1.0335677132899268 and parameters: {'max_depth': 45, 'num_leaves': 11, 'learning_rate': 3.449299756438301e-05, 'n_estimators': 50, 'reg_alpha': 72162.40515161892, 'reg_lambda': 661036.2818908162}. Best is trial 1 with value: -1.0335677132899268.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:30,883]\u001b[0m Trial 0 finished with value: -1.033557105425147 and parameters: {'max_depth': 28, 'num_leaves': 22, 'learning_rate': 1.787655945278378e-07, 'n_estimators': 113, 'reg_alpha': 130.3894420337961, 'reg_lambda': 8.557610459580909}. Best is trial 0 with value: -1.033557105425147.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:32,598]\u001b[0m Trial 3 finished with value: -1.007663262608878 and parameters: {'max_depth': 43, 'num_leaves': 29, 'learning_rate': 0.0003752715325572588, 'n_estimators': 348, 'reg_alpha': 641.883192294632, 'reg_lambda': 47853.41078138589}. Best is trial 3 with value: -1.007663262608878.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:39,066]\u001b[0m Trial 6 finished with value: -0.9421500538716667 and parameters: {'max_depth': 18, 'num_leaves': 26, 'learning_rate': 0.6944947881452564, 'n_estimators': 425, 'reg_alpha': 28707.157672314217, 'reg_lambda': 122202.69714686052}. Best is trial 6 with value: -0.9421500538716667.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:39,541]\u001b[0m Trial 2 finished with value: -1.0210685286631396 and parameters: {'max_depth': 22, 'num_leaves': 45, 'learning_rate': 8.384352228426189e-05, 'n_estimators': 500, 'reg_alpha': 7357.907920451098, 'reg_lambda': 1.7895429382129533e-06}. Best is trial 6 with value: -0.9421500538716667.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:40,172]\u001b[0m Trial 7 finished with value: -1.0335677132899268 and parameters: {'max_depth': 30, 'num_leaves': 42, 'learning_rate': 9.21604762695407e-06, 'n_estimators': 15, 'reg_alpha': 8518126.211892536, 'reg_lambda': 2087.844704784277}. Best is trial 6 with value: -0.9421500538716667.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:50,483]\u001b[0m Trial 9 finished with value: -1.0334357214332643 and parameters: {'max_depth': 6, 'num_leaves': 46, 'learning_rate': 1.6970217184768489e-06, 'n_estimators': 288, 'reg_alpha': 10690.758650247179, 'reg_lambda': 1.2415119524114626e-07}. Best is trial 6 with value: -0.9421500538716667.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:53,359]\u001b[0m Trial 5 finished with value: -1.0259420515985918 and parameters: {'max_depth': 5, 'num_leaves': 18, 'learning_rate': 0.00397527847503786, 'n_estimators': 346, 'reg_alpha': 0.0032106882591016787, 'reg_lambda': 28.067028057818746}. Best is trial 6 with value: -0.9421500538716667.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:55,001]\u001b[0m Trial 8 finished with value: -1.03353822121846 and parameters: {'max_depth': 4, 'num_leaves': 16, 'learning_rate': 1.944194147787108e-07, 'n_estimators': 306, 'reg_alpha': 382.95141069260063, 'reg_lambda': 5.3800702386694576e-05}. Best is trial 6 with value: -0.9421500538716667.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:09:55,696]\u001b[0m Trial 11 finished with value: -1.0335677132899268 and parameters: {'max_depth': 16, 'num_leaves': 11, 'learning_rate': 0.2738690103267602, 'n_estimators': 129, 'reg_alpha': 359210.2435756637, 'reg_lambda': 725.3541099795984}. Best is trial 6 with value: -0.9421500538716667.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:10:05,699]\u001b[0m Trial 4 finished with value: -1.1116991471041346 and parameters: {'max_depth': 19, 'num_leaves': 40, 'learning_rate': 0.007281976692374163, 'n_estimators': 303, 'reg_alpha': 1.2592564555925354, 'reg_lambda': 3.899869872313606e-05}. Best is trial 6 with value: -0.9421500538716667.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:10:07,125]\u001b[0m Trial 12 finished with value: -0.9174106495650747 and parameters: {'max_depth': 14, 'num_leaves': 46, 'learning_rate': 0.003490650586292982, 'n_estimators': 463, 'reg_alpha': 21411.352368805805, 'reg_lambda': 1091.805261654241}. Best is trial 12 with value: -0.9174106495650747.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:10:26,744]\u001b[0m Trial 13 finished with value: -0.9180651457209215 and parameters: {'max_depth': 15, 'num_leaves': 33, 'learning_rate': 0.5809881381564843, 'n_estimators': 483, 'reg_alpha': 5.01420152509401e-07, 'reg_lambda': 2703629.1678920803}. Best is trial 12 with value: -0.9174106495650747.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:10:28,679]\u001b[0m Trial 10 finished with value: -0.9438203948895327 and parameters: {'max_depth': 9, 'num_leaves': 24, 'learning_rate': 0.0005863125736709984, 'n_estimators': 422, 'reg_alpha': 1.709205831551109e-07, 'reg_lambda': 0.10303054879700692}. Best is trial 12 with value: -0.9174106495650747.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:10:38,958]\u001b[0m Trial 16 finished with value: -0.9843632760268539 and parameters: {'max_depth': 12, 'num_leaves': 34, 'learning_rate': 0.06648139977026592, 'n_estimators': 499, 'reg_alpha': 6.580603769805692e-07, 'reg_lambda': 9032067.549200512}. Best is trial 12 with value: -0.9174106495650747.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:10:41,154]\u001b[0m Trial 15 finished with value: -0.9173709223958753 and parameters: {'max_depth': 15, 'num_leaves': 31, 'learning_rate': 0.7647772174567977, 'n_estimators': 493, 'reg_alpha': 2.8850169166228988e-05, 'reg_lambda': 3666294.039270768}. Best is trial 15 with value: -0.9173709223958753.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:10:42,722]\u001b[0m Trial 14 finished with value: -1.0015863773275122 and parameters: {'max_depth': 46, 'num_leaves': 31, 'learning_rate': 0.6925079064726998, 'n_estimators': 458, 'reg_alpha': 1.6789989223817526e-07, 'reg_lambda': 1453448.0751960338}. Best is trial 15 with value: -0.9173709223958753.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:10:45,106]\u001b[0m Trial 18 finished with value: -0.9884906278704071 and parameters: {'max_depth': 0, 'num_leaves': 35, 'learning_rate': 0.041101225647068466, 'n_estimators': 207, 'reg_alpha': 0.0001390612521878234, 'reg_lambda': 2579254.4207621496}. Best is trial 15 with value: -0.9173709223958753.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:10:49,522]\u001b[0m Trial 17 finished with value: -0.9001167810803965 and parameters: {'max_depth': 12, 'num_leaves': 34, 'learning_rate': 0.08491647063804601, 'n_estimators': 499, 'reg_alpha': 1.0579522970578683e-07, 'reg_lambda': 979933.0392699516}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:11:10,913]\u001b[0m Trial 20 finished with value: -1.0948058985195461 and parameters: {'max_depth': -1, 'num_leaves': 49, 'learning_rate': 0.03526019407306514, 'n_estimators': 193, 'reg_alpha': 0.0006613520243859228, 'reg_lambda': 13215.888732127112}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:11:14,311]\u001b[0m Trial 19 finished with value: -1.1004277201206818 and parameters: {'max_depth': 30, 'num_leaves': 50, 'learning_rate': 0.03501775399677113, 'n_estimators': 208, 'reg_alpha': 0.0002655326529241454, 'reg_lambda': 9471.702548345438}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:11:22,463]\u001b[0m Trial 23 finished with value: -1.1117735283006502 and parameters: {'max_depth': 28, 'num_leaves': 5, 'learning_rate': 0.12912795515347975, 'n_estimators': 389, 'reg_alpha': 9.966950753330369e-06, 'reg_lambda': 54606.01719278519}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:11:27,908]\u001b[0m Trial 24 finished with value: -0.9459914928100175 and parameters: {'max_depth': 12, 'num_leaves': 38, 'learning_rate': 0.0034762648207594935, 'n_estimators': 404, 'reg_alpha': 1.2182495291280933e-05, 'reg_lambda': 160751.0796121657}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:11:31,806]\u001b[0m Trial 22 finished with value: -1.0800575514956556 and parameters: {'max_depth': 28, 'num_leaves': 38, 'learning_rate': 0.09506861941380572, 'n_estimators': 389, 'reg_alpha': 2.5917679251702383e-05, 'reg_lambda': 54570.981825404044}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:11:35,551]\u001b[0m Trial 21 finished with value: -1.0956430187342874 and parameters: {'max_depth': 27, 'num_leaves': 50, 'learning_rate': 0.016555015482707564, 'n_estimators': 391, 'reg_alpha': 0.5416766476676506, 'reg_lambda': 9731.228501069774}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:11:36,255]\u001b[0m Trial 25 finished with value: -0.9288402460348963 and parameters: {'max_depth': 11, 'num_leaves': 37, 'learning_rate': 0.007637204432874987, 'n_estimators': 436, 'reg_alpha': 0.02992047115894121, 'reg_lambda': 294729.6482591159}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:11:42,491]\u001b[0m Trial 27 finished with value: -1.0226325513111352 and parameters: {'max_depth': 23, 'num_leaves': 44, 'learning_rate': 0.013080389687669019, 'n_estimators': 452, 'reg_alpha': 0.3383327159984278, 'reg_lambda': 9159351.083333375}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:11:47,810]\u001b[0m Trial 28 finished with value: -0.9455454736075831 and parameters: {'max_depth': 22, 'num_leaves': 28, 'learning_rate': 0.1543776544725235, 'n_estimators': 449, 'reg_alpha': 1.9849261395722693e-06, 'reg_lambda': 8323416.702534906}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:11:50,619]\u001b[0m Trial 29 finished with value: -0.9312875504259227 and parameters: {'max_depth': 23, 'num_leaves': 44, 'learning_rate': 0.19772011814100227, 'n_estimators': 461, 'reg_alpha': 2.11104685243252e-06, 'reg_lambda': 8593468.605849277}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:12:16,356]\u001b[0m Trial 31 finished with value: -0.9255259509555658 and parameters: {'max_depth': 8, 'num_leaves': 31, 'learning_rate': 0.0019144502877658101, 'n_estimators': 351, 'reg_alpha': 1.0372920310561933e-07, 'reg_lambda': 655.7018811361685}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:12:19,996]\u001b[0m Trial 32 finished with value: -0.9213248770705302 and parameters: {'max_depth': 39, 'num_leaves': 21, 'learning_rate': 0.0015184253424308266, 'n_estimators': 354, 'reg_alpha': 15.78882967990426, 'reg_lambda': 417.98499196928185}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:12:21,274]\u001b[0m Trial 26 finished with value: -1.174084127439262 and parameters: {'max_depth': 22, 'num_leaves': 37, 'learning_rate': 0.168992011054979, 'n_estimators': 450, 'reg_alpha': 0.14038362402172025, 'reg_lambda': 1101.05357282445}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:12:22,589]\u001b[0m Trial 30 finished with value: -1.1844711182404422 and parameters: {'max_depth': 37, 'num_leaves': 30, 'learning_rate': 0.1793290311957616, 'n_estimators': 469, 'reg_alpha': 3.578208610266485e-06, 'reg_lambda': 597.6218896825848}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:12:22,807]\u001b[0m Trial 33 finished with value: -1.0230159428186427 and parameters: {'max_depth': 37, 'num_leaves': 19, 'learning_rate': 0.001284624313983656, 'n_estimators': 255, 'reg_alpha': 52.870256399234385, 'reg_lambda': 456802.4925341357}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:13:08,353]\u001b[0m Trial 36 finished with value: -1.0767472795546822 and parameters: {'max_depth': 15, 'num_leaves': 33, 'learning_rate': 0.9879347076111146, 'n_estimators': 499, 'reg_alpha': 5.200771202452329e-05, 'reg_lambda': 705533.8803578245}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:13:09,634]\u001b[0m Trial 34 finished with value: -1.0593586868167815 and parameters: {'max_depth': 16, 'num_leaves': 33, 'learning_rate': 0.7442060273198179, 'n_estimators': 484, 'reg_alpha': 1.1007782428323231e-06, 'reg_lambda': 711399.4764628151}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:13:09,939]\u001b[0m Trial 37 finished with value: -1.0743752821759645 and parameters: {'max_depth': 15, 'num_leaves': 33, 'learning_rate': 0.7533933595243676, 'n_estimators': 498, 'reg_alpha': 2.7270367985441416e-05, 'reg_lambda': 296796.9798502831}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:13:13,742]\u001b[0m Trial 35 finished with value: -1.0606633505099854 and parameters: {'max_depth': 15, 'num_leaves': 33, 'learning_rate': 0.7175996752194598, 'n_estimators': 499, 'reg_alpha': 1.398134232219018e-06, 'reg_lambda': 641088.5241660426}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:13:37,578]\u001b[0m Trial 39 finished with value: -0.9009506111993079 and parameters: {'max_depth': 19, 'num_leaves': 25, 'learning_rate': 0.29395046387285634, 'n_estimators': 477, 'reg_alpha': 1.902259579827369e-05, 'reg_lambda': 1878825.6367517102}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:13:44,129]\u001b[0m Trial 38 finished with value: -1.0258166820631192 and parameters: {'max_depth': 15, 'num_leaves': 25, 'learning_rate': 0.36832365682442314, 'n_estimators': 485, 'reg_alpha': 6.159562033388713e-07, 'reg_lambda': 592997.3489899061}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:13:44,160]\u001b[0m Trial 40 finished with value: -0.9625756408896903 and parameters: {'max_depth': 18, 'num_leaves': 41, 'learning_rate': 0.3804848425783255, 'n_estimators': 418, 'reg_alpha': 6.455636560619416e-07, 'reg_lambda': 1043089.1116226165}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:13:54,796]\u001b[0m Trial 41 finished with value: -1.0946299919796187 and parameters: {'max_depth': 19, 'num_leaves': 26, 'learning_rate': 0.33082554978843104, 'n_estimators': 418, 'reg_alpha': 0.0020718199237535107, 'reg_lambda': 32923.71089086748}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:14,974]\u001b[0m Trial 42 finished with value: -1.122694713569058 and parameters: {'max_depth': 19, 'num_leaves': 25, 'learning_rate': 0.3249260339599456, 'n_estimators': 410, 'reg_alpha': 0.002540732341572905, 'reg_lambda': 29888.716307226805}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:18,684]\u001b[0m Trial 44 finished with value: -1.0744898255945436 and parameters: {'max_depth': 20, 'num_leaves': 23, 'learning_rate': 0.0665247248128008, 'n_estimators': 465, 'reg_alpha': 0.0015065339520157878, 'reg_lambda': 55717.99968796348}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:21,550]\u001b[0m Trial 47 finished with value: -0.9850899775977282 and parameters: {'max_depth': 10, 'num_leaves': 29, 'learning_rate': 0.07836686260679071, 'n_estimators': 94, 'reg_alpha': 4.717602694696918e-06, 'reg_lambda': 2026614.8293463555}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:32,213]\u001b[0m Trial 43 finished with value: -1.097344670985363 and parameters: {'max_depth': 19, 'num_leaves': 41, 'learning_rate': 0.05814444665575608, 'n_estimators': 417, 'reg_alpha': 0.0015925956854456638, 'reg_lambda': 27294.183975341195}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:36,810]\u001b[0m Trial 48 finished with value: -0.9156953474196055 and parameters: {'max_depth': 7, 'num_leaves': 14, 'learning_rate': 0.017424846106593804, 'n_estimators': 370, 'reg_alpha': 8.776530968839897e-05, 'reg_lambda': 137463.47366265138}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:37,919]\u001b[0m Trial 45 finished with value: -1.032440696478234 and parameters: {'max_depth': 10, 'num_leaves': 27, 'learning_rate': 0.07180941557951838, 'n_estimators': 471, 'reg_alpha': 5.492513613422472e-06, 'reg_lambda': 113770.63330680568}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:41,604]\u001b[0m Trial 49 finished with value: -1.0913035711055414 and parameters: {'max_depth': 3, 'num_leaves': 21, 'learning_rate': 0.020464511378742795, 'n_estimators': 365, 'reg_alpha': 0.00013243936250686384, 'reg_lambda': 4493.526488257284}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:44,944]\u001b[0m Trial 46 finished with value: -1.0392167016954652 and parameters: {'max_depth': 9, 'num_leaves': 23, 'learning_rate': 0.07253004281162759, 'n_estimators': 467, 'reg_alpha': 6.562828000383005e-06, 'reg_lambda': 107484.0134868124}. Best is trial 17 with value: -0.9001167810803965.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:14:49,690]\u001b[0m A new study created in memory with name: no-name-f0e3c07b-45bb-4798-a9c2-7a5640bc991f\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:53,870]\u001b[0m Trial 1 finished with value: -2.659957639390577 and parameters: {'max_depth': 3, 'num_leaves': 7, 'learning_rate': 0.0007863567079896383, 'n_estimators': 411, 'reg_alpha': 8443636.007166162, 'reg_lambda': 622.9774515600187}. Best is trial 1 with value: -2.659957639390577.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:54,129]\u001b[0m Trial 3 finished with value: -2.8844825982224886 and parameters: {'max_depth': 27, 'num_leaves': 14, 'learning_rate': 0.17503526013779963, 'n_estimators': 428, 'reg_alpha': 67074.37295645312, 'reg_lambda': 3.6019065179899425}. Best is trial 1 with value: -2.659957639390577.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:55,757]\u001b[0m Trial 2 finished with value: -2.65994446864105 and parameters: {'max_depth': 24, 'num_leaves': 30, 'learning_rate': 4.494442846573028e-07, 'n_estimators': 158, 'reg_alpha': 37563.79147773322, 'reg_lambda': 8.475194708637841e-07}. Best is trial 2 with value: -2.65994446864105.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:56,427]\u001b[0m Trial 6 finished with value: -2.659957639390577 and parameters: {'max_depth': 40, 'num_leaves': 37, 'learning_rate': 1.1766181861654866e-05, 'n_estimators': 14, 'reg_alpha': 153614.6421087127, 'reg_lambda': 1511858.7415482185}. Best is trial 2 with value: -2.65994446864105.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:57,419]\u001b[0m Trial 7 finished with value: -2.659957639390577 and parameters: {'max_depth': 39, 'num_leaves': 48, 'learning_rate': 5.6140106286170465e-06, 'n_estimators': 45, 'reg_alpha': 9172410.830307506, 'reg_lambda': 158.3077897563348}. Best is trial 2 with value: -2.65994446864105.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:14:59,882]\u001b[0m Trial 4 finished with value: -2.6177829234667294 and parameters: {'max_depth': 15, 'num_leaves': 37, 'learning_rate': 0.0032747114647420014, 'n_estimators': 50, 'reg_alpha': 409.417320085669, 'reg_lambda': 0.09937120784570501}. Best is trial 4 with value: -2.6177829234667294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:11,263]\u001b[0m Trial 5 finished with value: -2.6560068537544557 and parameters: {'max_depth': 35, 'num_leaves': 18, 'learning_rate': 4.0833333629270485e-05, 'n_estimators': 277, 'reg_alpha': 2107.530794079523, 'reg_lambda': 9.919391964388073e-05}. Best is trial 4 with value: -2.6177829234667294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:14,325]\u001b[0m Trial 8 finished with value: -2.659383869794879 and parameters: {'max_depth': 35, 'num_leaves': 31, 'learning_rate': 9.893043616903875e-06, 'n_estimators': 172, 'reg_alpha': 23.203441416776574, 'reg_lambda': 1579.1938700004503}. Best is trial 4 with value: -2.6177829234667294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:20,313]\u001b[0m Trial 0 finished with value: -2.6567070223150386 and parameters: {'max_depth': 25, 'num_leaves': 27, 'learning_rate': 2.4062292079341583e-05, 'n_estimators': 398, 'reg_alpha': 8.26927909067493e-05, 'reg_lambda': 4.77488571834485e-07}. Best is trial 4 with value: -2.6177829234667294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:23,464]\u001b[0m Trial 12 finished with value: -2.643863412597811 and parameters: {'max_depth': 1, 'num_leaves': 33, 'learning_rate': 0.00019915223242535955, 'n_estimators': 284, 'reg_alpha': 25022.297228109976, 'reg_lambda': 3.223049730508075e-07}. Best is trial 4 with value: -2.6177829234667294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:23,971]\u001b[0m Trial 9 finished with value: -3.00172583395721 and parameters: {'max_depth': 37, 'num_leaves': 40, 'learning_rate': 0.38707028639179025, 'n_estimators': 267, 'reg_alpha': 0.0748716912038896, 'reg_lambda': 0.007930618567855992}. Best is trial 4 with value: -2.6177829234667294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:26,653]\u001b[0m Trial 11 finished with value: -2.659889687534836 and parameters: {'max_depth': 30, 'num_leaves': 50, 'learning_rate': 2.0883220896954216e-06, 'n_estimators': 82, 'reg_alpha': 0.001988919463586673, 'reg_lambda': 227.66801048620292}. Best is trial 4 with value: -2.6177829234667294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:29,648]\u001b[0m Trial 14 finished with value: -2.5885062204159883 and parameters: {'max_depth': 4, 'num_leaves': 47, 'learning_rate': 0.0031415825184405396, 'n_estimators': 149, 'reg_alpha': 77.32072122599921, 'reg_lambda': 0.006122692143926931}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:43,419]\u001b[0m Trial 16 finished with value: -2.7810927144268716 and parameters: {'max_depth': 12, 'num_leaves': 40, 'learning_rate': 0.011300227579715032, 'n_estimators': 133, 'reg_alpha': 36.22657079758656, 'reg_lambda': 0.015053369809103871}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:44,524]\u001b[0m Trial 13 finished with value: -2.8161783638197178 and parameters: {'max_depth': 10, 'num_leaves': 50, 'learning_rate': 0.010871545098796372, 'n_estimators': 162, 'reg_alpha': 0.11622726460883302, 'reg_lambda': 0.02233507558130206}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:47,715]\u001b[0m Trial 10 finished with value: -2.6590637109664494 and parameters: {'max_depth': 17, 'num_leaves': 45, 'learning_rate': 9.596537269378732e-06, 'n_estimators': 264, 'reg_alpha': 0.01229480576824495, 'reg_lambda': 1.6133300062245748e-05}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:55,014]\u001b[0m Trial 19 finished with value: -2.633665333338649 and parameters: {'max_depth': 8, 'num_leaves': 24, 'learning_rate': 0.0011170580511468313, 'n_estimators': 87, 'reg_alpha': 6.799857481928602, 'reg_lambda': 0.0004802739813387462}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:55,984]\u001b[0m Trial 17 finished with value: -2.6293838399413314 and parameters: {'max_depth': 11, 'num_leaves': 44, 'learning_rate': 0.003763445279659944, 'n_estimators': 110, 'reg_alpha': 4.1960806953462233e-07, 'reg_lambda': 0.032721345857568446}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:15:57,064]\u001b[0m Trial 18 finished with value: -2.6247181621409914 and parameters: {'max_depth': 16, 'num_leaves': 42, 'learning_rate': 0.0018536739696147055, 'n_estimators': 108, 'reg_alpha': 7.069474352234718e-07, 'reg_lambda': 0.0002989285428472078}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:02,166]\u001b[0m Trial 15 finished with value: -2.6616432011264974 and parameters: {'max_depth': 7, 'num_leaves': 40, 'learning_rate': 0.0022153026480380977, 'n_estimators': 327, 'reg_alpha': 96.6303398883478, 'reg_lambda': 0.0049237637875184}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:09,929]\u001b[0m Trial 22 finished with value: -2.6476900478678873 and parameters: {'max_depth': 5, 'num_leaves': 36, 'learning_rate': 0.00016236309040711084, 'n_estimators': 216, 'reg_alpha': 286.5928574795986, 'reg_lambda': 0.7797095797296008}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:11,448]\u001b[0m Trial 24 finished with value: -2.622261636164766 and parameters: {'max_depth': 19, 'num_leaves': 45, 'learning_rate': 0.031063063282321113, 'n_estimators': 8, 'reg_alpha': 1.5448175903134551, 'reg_lambda': 0.00018911753686496789}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:13,642]\u001b[0m Trial 25 finished with value: -2.637830964470302 and parameters: {'max_depth': 19, 'num_leaves': 46, 'learning_rate': 0.043615662114408225, 'n_estimators': 11, 'reg_alpha': 0.675308309691205, 'reg_lambda': 1.4841790423054909e-05}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:18,929]\u001b[0m Trial 26 finished with value: -2.802436257612914 and parameters: {'max_depth': 46, 'num_leaves': 36, 'learning_rate': 0.04772396276379345, 'n_estimators': 51, 'reg_alpha': 2.259861700399557, 'reg_lambda': 0.3513727958272369}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:16:20,999]\u001b[0m Trial 27 finished with value: -2.9595867578569712 and parameters: {'max_depth': 20, 'num_leaves': 44, 'learning_rate': 0.9784791985583937, 'n_estimators': 40, 'reg_alpha': 812.734798674719, 'reg_lambda': 0.001691923970265863}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:22,312]\u001b[0m Trial 20 finished with value: -2.777979289518599 and parameters: {'max_depth': 18, 'num_leaves': 43, 'learning_rate': 0.007575322816627391, 'n_estimators': 207, 'reg_alpha': 159.27374801873643, 'reg_lambda': 0.145015608945105}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:25,957]\u001b[0m Trial 23 finished with value: -2.649046741747508 and parameters: {'max_depth': 18, 'num_leaves': 35, 'learning_rate': 0.00016773685710341126, 'n_estimators': 216, 'reg_alpha': 1.4969244022265884, 'reg_lambda': 0.2615893649189705}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:27,932]\u001b[0m Trial 21 finished with value: -2.9137749284107652 and parameters: {'max_depth': 19, 'num_leaves': 37, 'learning_rate': 0.042056793104401524, 'n_estimators': 347, 'reg_alpha': 171.00529752813438, 'reg_lambda': 2.7240423339763007}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:36,466]\u001b[0m Trial 30 finished with value: -2.838821124791762 and parameters: {'max_depth': 14, 'num_leaves': 47, 'learning_rate': 0.03449090298651568, 'n_estimators': 71, 'reg_alpha': 6.433884436547927, 'reg_lambda': 0.0011847118165362177}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:37,355]\u001b[0m Trial 32 finished with value: -2.6591776441905903 and parameters: {'max_depth': -1, 'num_leaves': 26, 'learning_rate': 0.0005611097439900194, 'n_estimators': 4, 'reg_alpha': 2839.8704615088045, 'reg_lambda': 4.0018250824643826e-05}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:16:47,714]\u001b[0m Trial 28 finished with value: -2.790269135322672 and parameters: {'max_depth': 14, 'num_leaves': 47, 'learning_rate': 0.006907808771283404, 'n_estimators': 217, 'reg_alpha': 3.398114277968362, 'reg_lambda': 3.916274209458656e-05}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:10,323]\u001b[0m Trial 33 finished with value: -2.7053468846256656 and parameters: {'max_depth': 27, 'num_leaves': 21, 'learning_rate': 0.00485377581893395, 'n_estimators': 471, 'reg_alpha': 0.4107003416781765, 'reg_lambda': 0.00020142884466547574}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:17,749]\u001b[0m Trial 29 finished with value: -2.622933871305986 and parameters: {'max_depth': 0, 'num_leaves': 37, 'learning_rate': 0.0004914318036262046, 'n_estimators': 482, 'reg_alpha': 0.8351821872629193, 'reg_lambda': 6.233134409598927e-05}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:27,779]\u001b[0m Trial 31 finished with value: -2.620443226819951 and parameters: {'max_depth': 14, 'num_leaves': 48, 'learning_rate': 0.000518279793116771, 'n_estimators': 494, 'reg_alpha': 8.597420269014476, 'reg_lambda': 0.0015570317219225313}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:28,712]\u001b[0m Trial 35 finished with value: -2.623398545582986 and parameters: {'max_depth': 23, 'num_leaves': 41, 'learning_rate': 0.001851053217038204, 'n_estimators': 141, 'reg_alpha': 1.973916550562754e-05, 'reg_lambda': 0.0007959716917948288}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:28,842]\u001b[0m Trial 36 finished with value: -2.60754911520272 and parameters: {'max_depth': 4, 'num_leaves': 5, 'learning_rate': 0.0005964961483746408, 'n_estimators': 473, 'reg_alpha': 8.726175664525542, 'reg_lambda': 1.7683356378427132e-06}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:31,259]\u001b[0m Trial 37 finished with value: -2.626671473543508 and parameters: {'max_depth': 22, 'num_leaves': 6, 'learning_rate': 0.0012749800462182608, 'n_estimators': 126, 'reg_alpha': 13.164260180124273, 'reg_lambda': 2.7371895977431156e-06}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:39,514]\u001b[0m Trial 38 finished with value: -2.5933314849284663 and parameters: {'max_depth': 3, 'num_leaves': 50, 'learning_rate': 0.0008630810851719171, 'n_estimators': 375, 'reg_alpha': 11.743836620848379, 'reg_lambda': 4.608259986094465e-06}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:41,290]\u001b[0m Trial 39 finished with value: -2.6526389494885105 and parameters: {'max_depth': 5, 'num_leaves': 6, 'learning_rate': 6.039289428261114e-05, 'n_estimators': 428, 'reg_alpha': 26.73800671968055, 'reg_lambda': 2.942503606043556e-06}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:41,599]\u001b[0m Trial 34 finished with value: -2.7532698327013714 and parameters: {'max_depth': 28, 'num_leaves': 41, 'learning_rate': 0.0024110252129018895, 'n_estimators': 493, 'reg_alpha': 2.0661359165145258e-05, 'reg_lambda': 0.0004358856778968042}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:47,059]\u001b[0m Trial 40 finished with value: -2.6460048505604954 and parameters: {'max_depth': 5, 'num_leaves': 10, 'learning_rate': 8.92059631219156e-05, 'n_estimators': 447, 'reg_alpha': 16.188780939018706, 'reg_lambda': 1.0827772548961876e-07}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:51,384]\u001b[0m Trial 43 finished with value: -2.6510679745914656 and parameters: {'max_depth': 3, 'num_leaves': 11, 'learning_rate': 6.912669973420228e-05, 'n_estimators': 381, 'reg_alpha': 4846.4929991593235, 'reg_lambda': 1.421646992796085e-07}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:52,460]\u001b[0m Trial 42 finished with value: -2.651482201736942 and parameters: {'max_depth': 3, 'num_leaves': 15, 'learning_rate': 6.737714810894135e-05, 'n_estimators': 370, 'reg_alpha': 1501.874917292339, 'reg_lambda': 5.485856750103091e-07}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:53,496]\u001b[0m Trial 44 finished with value: -2.6097183718422743 and parameters: {'max_depth': 2, 'num_leaves': 13, 'learning_rate': 0.00040955646269034615, 'n_estimators': 368, 'reg_alpha': 1437.1342277848476, 'reg_lambda': 1.7480425123543902e-06}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:56,333]\u001b[0m Trial 47 finished with value: -2.659957639390577 and parameters: {'max_depth': 8, 'num_leaves': 30, 'learning_rate': 0.00033685951073819225, 'n_estimators': 307, 'reg_alpha': 199044.70874880717, 'reg_lambda': 3.6290848665901796e-06}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:17:56,420]\u001b[0m Trial 41 finished with value: -2.6493428214993378 and parameters: {'max_depth': 4, 'num_leaves': 11, 'learning_rate': 6.877743728591826e-05, 'n_estimators': 438, 'reg_alpha': 3766.022591759223, 'reg_lambda': 1.9897330736948066e-07}. Best is trial 14 with value: -2.5885062204159883.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:03,100]\u001b[0m Trial 48 finished with value: -2.5531612975233386 and parameters: {'max_depth': 2, 'num_leaves': 8, 'learning_rate': 0.0012081830766136027, 'n_estimators': 400, 'reg_alpha': 61.077863761163165, 'reg_lambda': 1.910841724911546e-06}. Best is trial 48 with value: -2.5531612975233386.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:03,757]\u001b[0m Trial 49 finished with value: -2.582612192004706 and parameters: {'max_depth': 2, 'num_leaves': 8, 'learning_rate': 0.0006824015172102293, 'n_estimators': 395, 'reg_alpha': 58.515269089537746, 'reg_lambda': 6.999244305065252e-07}. Best is trial 48 with value: -2.5531612975233386.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:10,588]\u001b[0m Trial 45 finished with value: -2.610910534863096 and parameters: {'max_depth': 8, 'num_leaves': 16, 'learning_rate': 0.0004638979205127943, 'n_estimators': 460, 'reg_alpha': 946.5205279930008, 'reg_lambda': 1.8511517897092314e-06}. Best is trial 48 with value: -2.5531612975233386.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:25,207]\u001b[0m Trial 46 finished with value: -2.6231579592011274 and parameters: {'max_depth': 8, 'num_leaves': 49, 'learning_rate': 0.0003462062974549769, 'n_estimators': 450, 'reg_alpha': 49.01574999953293, 'reg_lambda': 3.538828154767527e-06}. Best is trial 48 with value: -2.5531612975233386.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:18:27,699]\u001b[0m A new study created in memory with name: no-name-e45a6c03-623a-4842-9195-3d377e8f236e\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:30,073]\u001b[0m Trial 2 finished with value: -3.7367429265903933 and parameters: {'max_depth': 31, 'num_leaves': 5, 'learning_rate': 0.16717820757612967, 'n_estimators': 85, 'reg_alpha': 7.797669123044365e-05, 'reg_lambda': 0.0007468490864523218}. Best is trial 2 with value: -3.7367429265903933.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:36,940]\u001b[0m Trial 0 finished with value: -3.9069791297429672 and parameters: {'max_depth': 41, 'num_leaves': 16, 'learning_rate': 0.12514566379062383, 'n_estimators': 158, 'reg_alpha': 54.301966123655006, 'reg_lambda': 0.012397171423037399}. Best is trial 2 with value: -3.7367429265903933.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:40,315]\u001b[0m Trial 4 finished with value: -3.05340095779045 and parameters: {'max_depth': 5, 'num_leaves': 35, 'learning_rate': 0.0005371092208753612, 'n_estimators': 146, 'reg_alpha': 37.07607744355537, 'reg_lambda': 3.104283936861718e-07}. Best is trial 4 with value: -3.05340095779045.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:45,680]\u001b[0m Trial 3 finished with value: -3.990466532077982 and parameters: {'max_depth': 9, 'num_leaves': 41, 'learning_rate': 0.392438962514315, 'n_estimators': 175, 'reg_alpha': 0.0006650807851760626, 'reg_lambda': 1964.90336509226}. Best is trial 4 with value: -3.05340095779045.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:47,886]\u001b[0m Trial 6 finished with value: -3.03742512042197 and parameters: {'max_depth': 26, 'num_leaves': 50, 'learning_rate': 2.5047885161855382e-05, 'n_estimators': 121, 'reg_alpha': 268.49395829345696, 'reg_lambda': 4036704.5401519197}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:56,057]\u001b[0m Trial 7 finished with value: -4.104928076844703 and parameters: {'max_depth': 39, 'num_leaves': 14, 'learning_rate': 0.7845502582107018, 'n_estimators': 264, 'reg_alpha': 1.8085991510675156e-05, 'reg_lambda': 1.5755101441831899e-06}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:58,436]\u001b[0m Trial 8 finished with value: -3.0375323544735373 and parameters: {'max_depth': 19, 'num_leaves': 34, 'learning_rate': 1.1141591086319234e-05, 'n_estimators': 111, 'reg_alpha': 288.13391658492867, 'reg_lambda': 0.1257255016471651}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:18:59,902]\u001b[0m Trial 1 finished with value: -3.8814877380813204 and parameters: {'max_depth': 7, 'num_leaves': 30, 'learning_rate': 0.009900517345322437, 'n_estimators': 360, 'reg_alpha': 0.0005848931388348841, 'reg_lambda': 1.7442104424720776e-05}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:02,391]\u001b[0m Trial 10 finished with value: -3.042513507804604 and parameters: {'max_depth': 47, 'num_leaves': 28, 'learning_rate': 0.00032287405578254114, 'n_estimators': 139, 'reg_alpha': 49291.312689441176, 'reg_lambda': 1.5861359782087768e-05}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:04,813]\u001b[0m Trial 9 finished with value: -4.004041638720302 and parameters: {'max_depth': 3, 'num_leaves': 44, 'learning_rate': 0.46540553786510586, 'n_estimators': 350, 'reg_alpha': 0.023655126888517463, 'reg_lambda': 0.000606808777303213}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:05,466]\u001b[0m Trial 13 finished with value: -3.0374261779622254 and parameters: {'max_depth': 21, 'num_leaves': 49, 'learning_rate': 1.348642914389252e-07, 'n_estimators': 7, 'reg_alpha': 604718.2275952965, 'reg_lambda': 8169966.874714761}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:06,098]\u001b[0m Trial 14 finished with value: -3.0374261779622254 and parameters: {'max_depth': 21, 'num_leaves': 50, 'learning_rate': 2.6087856522257636e-07, 'n_estimators': 7, 'reg_alpha': 1026911.3765484329, 'reg_lambda': 4211386.2049304815}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:06,794]\u001b[0m Trial 15 finished with value: -3.0374261779622254 and parameters: {'max_depth': 28, 'num_leaves': 49, 'learning_rate': 1.1128628709326036e-07, 'n_estimators': 18, 'reg_alpha': 7643075.361018155, 'reg_lambda': 2136557.950303291}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:10,053]\u001b[0m Trial 5 finished with value: -3.8528810512147347 and parameters: {'max_depth': 8, 'num_leaves': 29, 'learning_rate': 0.013538779553297312, 'n_estimators': 371, 'reg_alpha': 19.688505783752895, 'reg_lambda': 558.0094132876933}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:14,315]\u001b[0m Trial 11 finished with value: -3.3401745828016622 and parameters: {'max_depth': 38, 'num_leaves': 31, 'learning_rate': 0.010784497648098443, 'n_estimators': 143, 'reg_alpha': 802.017861728341, 'reg_lambda': 7354.053118566962}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:15,737]\u001b[0m Trial 12 finished with value: -4.226556609727364 and parameters: {'max_depth': 42, 'num_leaves': 22, 'learning_rate': 0.6411866785613709, 'n_estimators': 231, 'reg_alpha': 0.10812754517816078, 'reg_lambda': 5.658799870178019e-05}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:18,368]\u001b[0m Trial 19 finished with value: -3.037426168381585 and parameters: {'max_depth': 18, 'num_leaves': 41, 'learning_rate': 1.5839100011482589e-06, 'n_estimators': 59, 'reg_alpha': 30762.135974976885, 'reg_lambda': 8241368.091489049}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:20,966]\u001b[0m Trial 17 finished with value: -3.0374900468512207 and parameters: {'max_depth': 15, 'num_leaves': 41, 'learning_rate': 2.613324568474679e-06, 'n_estimators': 476, 'reg_alpha': 51918.59365147469, 'reg_lambda': 82157.2365526718}. Best is trial 6 with value: -3.03742512042197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:21,688]\u001b[0m Trial 20 finished with value: -3.0374173970742575 and parameters: {'max_depth': 17, 'num_leaves': 40, 'learning_rate': 4.25630441646905e-06, 'n_estimators': 63, 'reg_alpha': 13263.505723064582, 'reg_lambda': 65755.08585065849}. Best is trial 20 with value: -3.0374173970742575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:25,820]\u001b[0m Trial 16 finished with value: -3.0374642964509606 and parameters: {'max_depth': 15, 'num_leaves': 41, 'learning_rate': 2.7332796899547112e-06, 'n_estimators': 249, 'reg_alpha': 4211.157601858575, 'reg_lambda': 4814.4558488450575}. Best is trial 20 with value: -3.0374173970742575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:27,673]\u001b[0m Trial 21 finished with value: -3.037494379495068 and parameters: {'max_depth': 28, 'num_leaves': 43, 'learning_rate': 1.4379747137025208e-05, 'n_estimators': 61, 'reg_alpha': 4462.499860107004, 'reg_lambda': 13.039777242828869}. Best is trial 20 with value: -3.0374173970742575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:33,996]\u001b[0m Trial 24 finished with value: -3.0374153716762513 and parameters: {'max_depth': 15, 'num_leaves': 36, 'learning_rate': 3.1043951489864546e-05, 'n_estimators': 61, 'reg_alpha': 3.8518396491414855, 'reg_lambda': 322210.65648353484}. Best is trial 24 with value: -3.0374153716762513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:34,793]\u001b[0m Trial 23 finished with value: -3.0377908930022905 and parameters: {'max_depth': 27, 'num_leaves': 45, 'learning_rate': 5.33286869430744e-05, 'n_estimators': 72, 'reg_alpha': 6.3215910975410825, 'reg_lambda': 9.748182814665348}. Best is trial 24 with value: -3.0374153716762513.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:39,969]\u001b[0m Trial 18 finished with value: -3.0374334830492082 and parameters: {'max_depth': 15, 'num_leaves': 41, 'learning_rate': 2.6620912537488998e-06, 'n_estimators': 486, 'reg_alpha': 15083.09497922447, 'reg_lambda': 15.221292636900904}. Best is trial 24 with value: -3.0374153716762513.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:19:42,496]\u001b[0m Trial 25 finished with value: -3.037383428825539 and parameters: {'max_depth': 11, 'num_leaves': 36, 'learning_rate': 5.360127405410708e-05, 'n_estimators': 84, 'reg_alpha': 3.0672838723758695, 'reg_lambda': 209953.3430854468}. Best is trial 25 with value: -3.037383428825539.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:45,615]\u001b[0m Trial 22 finished with value: -3.038107108347744 and parameters: {'max_depth': 26, 'num_leaves': 44, 'learning_rate': 4.5113636185183635e-05, 'n_estimators': 208, 'reg_alpha': 2.0962655653199573, 'reg_lambda': 88.30331760157992}. Best is trial 25 with value: -3.037383428825539.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:49,463]\u001b[0m Trial 29 finished with value: -3.037393707388432 and parameters: {'max_depth': -1, 'num_leaves': 35, 'learning_rate': 0.00011982833095567376, 'n_estimators': 39, 'reg_alpha': 0.3599879107913841, 'reg_lambda': 266129.8615686383}. Best is trial 25 with value: -3.037383428825539.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:19:52,599]\u001b[0m Trial 26 finished with value: -3.0373320159773214 and parameters: {'max_depth': 0, 'num_leaves': 36, 'learning_rate': 6.312926024480178e-05, 'n_estimators': 207, 'reg_alpha': 2.2123360911891745, 'reg_lambda': 257598.46315713352}. Best is trial 26 with value: -3.0373320159773214.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:00,676]\u001b[0m Trial 27 finished with value: -3.0370979414692645 and parameters: {'max_depth': 32, 'num_leaves': 37, 'learning_rate': 8.314269014666449e-05, 'n_estimators': 199, 'reg_alpha': 2.004006583144961, 'reg_lambda': 169580.7523917444}. Best is trial 27 with value: -3.0370979414692645.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:02,806]\u001b[0m Trial 28 finished with value: -3.036913090122081 and parameters: {'max_depth': 11, 'num_leaves': 36, 'learning_rate': 9.407303453107873e-05, 'n_estimators': 192, 'reg_alpha': 0.7365389967388105, 'reg_lambda': 116017.43751521569}. Best is trial 28 with value: -3.036913090122081.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:08,693]\u001b[0m Trial 30 finished with value: -3.0366803315080007 and parameters: {'max_depth': -1, 'num_leaves': 24, 'learning_rate': 9.598191396001826e-05, 'n_estimators': 298, 'reg_alpha': 0.19213672054674982, 'reg_lambda': 134155.6973233587}. Best is trial 30 with value: -3.0366803315080007.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:11,180]\u001b[0m Trial 31 finished with value: -3.035289360898261 and parameters: {'max_depth': -1, 'num_leaves': 24, 'learning_rate': 0.00019456132812797994, 'n_estimators': 295, 'reg_alpha': 0.5487184597401557, 'reg_lambda': 42960.68162429236}. Best is trial 31 with value: -3.035289360898261.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:16,194]\u001b[0m Trial 35 finished with value: -3.015383929009415 and parameters: {'max_depth': 2, 'num_leaves': 23, 'learning_rate': 0.0007969778494017047, 'n_estimators': 310, 'reg_alpha': 0.02815581723371062, 'reg_lambda': 18056.635504615915}. Best is trial 35 with value: -3.015383929009415.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:21,221]\u001b[0m Trial 36 finished with value: -3.01532569910073 and parameters: {'max_depth': 2, 'num_leaves': 22, 'learning_rate': 0.0007096135136834278, 'n_estimators': 302, 'reg_alpha': 0.017288807928317225, 'reg_lambda': 11131.311965760144}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:23,387]\u001b[0m Trial 32 finished with value: -3.0582619019233137 and parameters: {'max_depth': -1, 'num_leaves': 23, 'learning_rate': 0.0008692074825228606, 'n_estimators': 300, 'reg_alpha': 0.04195104578852045, 'reg_lambda': 13351.621519500099}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:26,328]\u001b[0m Trial 33 finished with value: -3.049355273608088 and parameters: {'max_depth': -1, 'num_leaves': 25, 'learning_rate': 0.0008265780220553538, 'n_estimators': 295, 'reg_alpha': 1.7366730730889885e-07, 'reg_lambda': 20619.75612110729}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:27,612]\u001b[0m Trial 34 finished with value: -3.0364147101498666 and parameters: {'max_depth': -1, 'num_leaves': 22, 'learning_rate': 0.00021277982135989613, 'n_estimators': 296, 'reg_alpha': 0.059380141457296226, 'reg_lambda': 21663.83396526525}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:28,021]\u001b[0m Trial 37 finished with value: -3.0155714903590347 and parameters: {'max_depth': 2, 'num_leaves': 24, 'learning_rate': 0.0009260997936603179, 'n_estimators': 302, 'reg_alpha': 0.017180393265163393, 'reg_lambda': 19347.107145158643}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:32,522]\u001b[0m Trial 38 finished with value: -3.066205668357932 and parameters: {'max_depth': 3, 'num_leaves': 24, 'learning_rate': 0.0015307747421790519, 'n_estimators': 300, 'reg_alpha': 0.007810795972867627, 'reg_lambda': 882.4935819635606}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:37,374]\u001b[0m Trial 39 finished with value: -3.1861475374697283 and parameters: {'max_depth': 3, 'num_leaves': 18, 'learning_rate': 0.0025691857994863203, 'n_estimators': 396, 'reg_alpha': 0.018010846883986353, 'reg_lambda': 862.3871329742914}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:41,595]\u001b[0m Trial 40 finished with value: -3.158496477798331 and parameters: {'max_depth': 4, 'num_leaves': 18, 'learning_rate': 0.001553397222924359, 'n_estimators': 376, 'reg_alpha': 0.006850939720195034, 'reg_lambda': 1731.863382234742}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:42,983]\u001b[0m Trial 41 finished with value: -3.233886105761563 and parameters: {'max_depth': 4, 'num_leaves': 18, 'learning_rate': 0.0021451847788936467, 'n_estimators': 399, 'reg_alpha': 0.0017548800255857936, 'reg_lambda': 957.9507827643191}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:53,843]\u001b[0m Trial 43 finished with value: -3.3335578288385426 and parameters: {'max_depth': 6, 'num_leaves': 13, 'learning_rate': 0.004068392765084187, 'n_estimators': 332, 'reg_alpha': 0.002459228621131087, 'reg_lambda': 2367.7116126680626}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:55,831]\u001b[0m Trial 42 finished with value: -3.3268347780466327 and parameters: {'max_depth': 6, 'num_leaves': 18, 'learning_rate': 0.0026071486613530406, 'n_estimators': 390, 'reg_alpha': 0.0035038672343157117, 'reg_lambda': 838.6081326007372}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:56,137]\u001b[0m Trial 44 finished with value: -3.0445182573394636 and parameters: {'max_depth': 6, 'num_leaves': 13, 'learning_rate': 0.0002898684684774267, 'n_estimators': 328, 'reg_alpha': 0.0015440917784145557, 'reg_lambda': 210.068665690648}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:20:59,168]\u001b[0m Trial 45 finished with value: -3.0519853485930732 and parameters: {'max_depth': 7, 'num_leaves': 15, 'learning_rate': 0.0002511049441104429, 'n_estimators': 331, 'reg_alpha': 0.08529738168425416, 'reg_lambda': 171.90723896807617}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:12,717]\u001b[0m Trial 46 finished with value: -3.036553713239475 and parameters: {'max_depth': 10, 'num_leaves': 21, 'learning_rate': 0.00018716518514145006, 'n_estimators': 266, 'reg_alpha': 0.05070174947511177, 'reg_lambda': 21303.872373601163}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:12,984]\u001b[0m Trial 48 finished with value: -3.0405938390981238 and parameters: {'max_depth': 9, 'num_leaves': 21, 'learning_rate': 0.00028699863936604134, 'n_estimators': 274, 'reg_alpha': 0.07976843958962694, 'reg_lambda': 15986.19022027851}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:14,573]\u001b[0m Trial 49 finished with value: -3.0379843015954666 and parameters: {'max_depth': 10, 'num_leaves': 21, 'learning_rate': 0.0005215085155141794, 'n_estimators': 255, 'reg_alpha': 0.00028893346244626933, 'reg_lambda': 22217.245321842965}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:17,597]\u001b[0m Trial 47 finished with value: -3.0424559053784233 and parameters: {'max_depth': 9, 'num_leaves': 26, 'learning_rate': 0.00025071859072573095, 'n_estimators': 335, 'reg_alpha': 0.06809647099725812, 'reg_lambda': 12851.706717415585}. Best is trial 36 with value: -3.01532569910073.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|                                        | 6/16 [1:11:43<1:47:12, 643.24s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:21:19,714]\u001b[0m A new study created in memory with name: no-name-f8c0a06b-b969-490b-9d4c-e0773c34cb0b\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:22,932]\u001b[0m Trial 0 finished with value: -2.2363690547587627 and parameters: {'max_depth': 31, 'num_leaves': 48, 'learning_rate': 0.005204425005015829, 'n_estimators': 386, 'reg_alpha': 1431369.8580573539, 'reg_lambda': 16120.477813805546}. Best is trial 0 with value: -2.2363690547587627.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:23,814]\u001b[0m Trial 2 finished with value: -2.215616735974507 and parameters: {'max_depth': 15, 'num_leaves': 13, 'learning_rate': 0.0005061978838694147, 'n_estimators': 89, 'reg_alpha': 6.004874463273366e-06, 'reg_lambda': 55.91758150936541}. Best is trial 2 with value: -2.215616735974507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:24,931]\u001b[0m Trial 3 finished with value: -2.162430260289256 and parameters: {'max_depth': 15, 'num_leaves': 6, 'learning_rate': 0.11114624721207104, 'n_estimators': 255, 'reg_alpha': 2.129916437104336e-07, 'reg_lambda': 2203506.294765992}. Best is trial 3 with value: -2.162430260289256.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:28,357]\u001b[0m Trial 4 finished with value: -2.0296028898892775 and parameters: {'max_depth': 46, 'num_leaves': 20, 'learning_rate': 0.010181702418080451, 'n_estimators': 106, 'reg_alpha': 699.6321635633556, 'reg_lambda': 6.226067245002464}. Best is trial 4 with value: -2.0296028898892775.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:29,428]\u001b[0m Trial 6 finished with value: -1.9953418953608781 and parameters: {'max_depth': 0, 'num_leaves': 18, 'learning_rate': 0.10959237607418391, 'n_estimators': 90, 'reg_alpha': 9.977462239282591, 'reg_lambda': 21269.261288025635}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:32,690]\u001b[0m Trial 8 finished with value: -2.2363690547587627 and parameters: {'max_depth': 15, 'num_leaves': 47, 'learning_rate': 0.00038485014325269167, 'n_estimators': 496, 'reg_alpha': 96664.28257456375, 'reg_lambda': 253.35271600014423}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:34,477]\u001b[0m Trial 5 finished with value: -2.234251191066675 and parameters: {'max_depth': 27, 'num_leaves': 41, 'learning_rate': 4.5698430551917654e-05, 'n_estimators': 90, 'reg_alpha': 0.48142752456111426, 'reg_lambda': 3.837548324096328e-05}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:42,193]\u001b[0m Trial 10 finished with value: -2.3169145393574944 and parameters: {'max_depth': 0, 'num_leaves': 8, 'learning_rate': 0.05578327204026336, 'n_estimators': 265, 'reg_alpha': 0.5068493065500601, 'reg_lambda': 6.139064961511294}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:43,193]\u001b[0m Trial 7 finished with value: -2.2355536116774557 and parameters: {'max_depth': 30, 'num_leaves': 18, 'learning_rate': 6.128513440010487e-06, 'n_estimators': 260, 'reg_alpha': 0.5665573447723213, 'reg_lambda': 0.07251753296502862}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:44,238]\u001b[0m Trial 11 finished with value: -2.2363666669313624 and parameters: {'max_depth': 19, 'num_leaves': 38, 'learning_rate': 1.8831682412688283e-06, 'n_estimators': 67, 'reg_alpha': 6.343034033014062e-05, 'reg_lambda': 381471.9426544701}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:44,772]\u001b[0m Trial 13 finished with value: -2.236368718152096 and parameters: {'max_depth': 1, 'num_leaves': 29, 'learning_rate': 1.342878386420616e-07, 'n_estimators': 9, 'reg_alpha': 248.7171148007703, 'reg_lambda': 2847.1581261541633}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:46,672]\u001b[0m Trial 14 finished with value: -2.087309301466351 and parameters: {'max_depth': 47, 'num_leaves': 23, 'learning_rate': 0.9482311377847318, 'n_estimators': 162, 'reg_alpha': 597.6360959597899, 'reg_lambda': 0.04656388551940504}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:56,242]\u001b[0m Trial 15 finished with value: -2.0023383634487053 and parameters: {'max_depth': 47, 'num_leaves': 27, 'learning_rate': 0.009919432110403702, 'n_estimators': 183, 'reg_alpha': 241.89323130883986, 'reg_lambda': 16639.999280064487}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:56,532]\u001b[0m Trial 1 finished with value: -2.2362694409417867 and parameters: {'max_depth': 44, 'num_leaves': 47, 'learning_rate': 6.073428507880911e-07, 'n_estimators': 319, 'reg_alpha': 3.768702923753853e-07, 'reg_lambda': 0.018408125874743827}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:21:59,730]\u001b[0m Trial 16 finished with value: -2.234785951103943 and parameters: {'max_depth': 39, 'num_leaves': 32, 'learning_rate': 0.004875101455021293, 'n_estimators': 170, 'reg_alpha': 0.006679712461711004, 'reg_lambda': 3871283.2737734145}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:00,095]\u001b[0m Trial 17 finished with value: -2.2353686213928663 and parameters: {'max_depth': 37, 'num_leaves': 31, 'learning_rate': 0.003627613923602016, 'n_estimators': 188, 'reg_alpha': 0.0019531329725926264, 'reg_lambda': 5065247.528861402}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:01,809]\u001b[0m Trial 19 finished with value: -2.079425723103555 and parameters: {'max_depth': 7, 'num_leaves': 24, 'learning_rate': 0.5052719359778067, 'n_estimators': 22, 'reg_alpha': 35.45733345736888, 'reg_lambda': 17358.77308103142}. Best is trial 6 with value: -1.9953418953608781.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:06,468]\u001b[0m Trial 20 finished with value: -1.9301792766948294 and parameters: {'max_depth': 6, 'num_leaves': 14, 'learning_rate': 0.06208513640629079, 'n_estimators': 191, 'reg_alpha': 5012.54116415397, 'reg_lambda': 89796.55290009106}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:08,983]\u001b[0m Trial 21 finished with value: -2.2363690547587627 and parameters: {'max_depth': 7, 'num_leaves': 12, 'learning_rate': 0.12885348758998855, 'n_estimators': 327, 'reg_alpha': 104164.08198346118, 'reg_lambda': 146662.44264769176}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:10,983]\u001b[0m Trial 22 finished with value: -2.0905282608503546 and parameters: {'max_depth': 7, 'num_leaves': 14, 'learning_rate': 0.04214340931181352, 'n_estimators': 148, 'reg_alpha': 24619.16126239831, 'reg_lambda': 767.3517513171042}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:12,599]\u001b[0m Trial 23 finished with value: -2.2363690547587627 and parameters: {'max_depth': 4, 'num_leaves': 17, 'learning_rate': 0.5582085250557068, 'n_estimators': 206, 'reg_alpha': 8428765.384909006, 'reg_lambda': 257029.34833409707}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:13,250]\u001b[0m Trial 18 finished with value: -2.168308317394183 and parameters: {'max_depth': 8, 'num_leaves': 25, 'learning_rate': 0.9646427654958449, 'n_estimators': 179, 'reg_alpha': 18.925909456219486, 'reg_lambda': 33559.48470468055}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:16,012]\u001b[0m Trial 25 finished with value: -1.9537341795740857 and parameters: {'max_depth': 21, 'num_leaves': 10, 'learning_rate': 0.023029983933201315, 'n_estimators': 123, 'reg_alpha': 5546.39594466301, 'reg_lambda': 1514.7843533515208}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:18,205]\u001b[0m Trial 26 finished with value: -1.9918672337903975 and parameters: {'max_depth': 23, 'num_leaves': 10, 'learning_rate': 0.029866045382208505, 'n_estimators': 127, 'reg_alpha': 15835.813425373653, 'reg_lambda': 1547.4072252062188}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:22:20,739]\u001b[0m Trial 9 finished with value: -2.1242988187234313 and parameters: {'max_depth': 47, 'num_leaves': 49, 'learning_rate': 0.0006877354784150425, 'n_estimators': 414, 'reg_alpha': 8.722713974500033, 'reg_lambda': 15.005000639524058}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:21,092]\u001b[0m Trial 27 finished with value: -2.198993957921375 and parameters: {'max_depth': 21, 'num_leaves': 10, 'learning_rate': 0.0007541363136013632, 'n_estimators': 123, 'reg_alpha': 8040.1760082123055, 'reg_lambda': 434.86577214814315}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:21,362]\u001b[0m Trial 12 finished with value: -2.236164172696314 and parameters: {'max_depth': 40, 'num_leaves': 32, 'learning_rate': 1.034129454486463e-06, 'n_estimators': 390, 'reg_alpha': 7.296158848162275e-06, 'reg_lambda': 0.0036555399836795967}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:22,452]\u001b[0m Trial 29 finished with value: -2.0472228869993505 and parameters: {'max_depth': 26, 'num_leaves': 5, 'learning_rate': 0.03923484554832218, 'n_estimators': 47, 'reg_alpha': 2843.791971287228, 'reg_lambda': 3092.801575585403}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:23,498]\u001b[0m Trial 28 finished with value: -1.9485175940864274 and parameters: {'max_depth': 21, 'num_leaves': 9, 'learning_rate': 0.021640915853882, 'n_estimators': 125, 'reg_alpha': 6416.954587183045, 'reg_lambda': 1772.1746625971932}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:24,748]\u001b[0m Trial 24 finished with value: -2.0308716167083425 and parameters: {'max_depth': -1, 'num_leaves': 25, 'learning_rate': 0.021162410299639844, 'n_estimators': 206, 'reg_alpha': 32.987691760203084, 'reg_lambda': 9244.554915156601}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:25,072]\u001b[0m Trial 31 finished with value: -2.2363690547587627 and parameters: {'max_depth': 11, 'num_leaves': 15, 'learning_rate': 0.0019010759907219566, 'n_estimators': 221, 'reg_alpha': 251065.57216262235, 'reg_lambda': 48.49379679083386}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:26,492]\u001b[0m Trial 34 finished with value: -2.2363690547587627 and parameters: {'max_depth': 24, 'num_leaves': 10, 'learning_rate': 0.014760472372115724, 'n_estimators': 123, 'reg_alpha': 802580.6073974892, 'reg_lambda': 728.8036832625302}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:26,574]\u001b[0m Trial 30 finished with value: -1.9423824286636828 and parameters: {'max_depth': 25, 'num_leaves': 8, 'learning_rate': 0.02269936352116434, 'n_estimators': 222, 'reg_alpha': 5679.191518564202, 'reg_lambda': 1973.1406927497906}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:26,804]\u001b[0m Trial 32 finished with value: -2.2363690547587627 and parameters: {'max_depth': 11, 'num_leaves': 15, 'learning_rate': 0.0017755932734458677, 'n_estimators': 237, 'reg_alpha': 622966.963317381, 'reg_lambda': 109.8317251786853}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:26,972]\u001b[0m Trial 33 finished with value: -2.2363690547587627 and parameters: {'max_depth': 18, 'num_leaves': 15, 'learning_rate': 0.002253029813749939, 'n_estimators': 229, 'reg_alpha': 785440.3780125348, 'reg_lambda': 89.6822794257351}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:28,732]\u001b[0m Trial 35 finished with value: -2.2261966413814402 and parameters: {'max_depth': 33, 'num_leaves': 9, 'learning_rate': 0.0025782641772435903, 'n_estimators': 143, 'reg_alpha': 15532.83355222715, 'reg_lambda': 193718.17092942866}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:31,154]\u001b[0m Trial 38 finished with value: -2.2119539650430045 and parameters: {'max_depth': 33, 'num_leaves': 7, 'learning_rate': 0.00885029991128745, 'n_estimators': 299, 'reg_alpha': 4317.426850642576, 'reg_lambda': 744938.7342321815}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:32,562]\u001b[0m Trial 37 finished with value: -1.9538047239539031 and parameters: {'max_depth': 31, 'num_leaves': 7, 'learning_rate': 0.2615893442747104, 'n_estimators': 297, 'reg_alpha': 5288.977722509791, 'reg_lambda': 122284.92620919326}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:33,569]\u001b[0m Trial 41 finished with value: -2.2363690547587627 and parameters: {'max_depth': 27, 'num_leaves': 5, 'learning_rate': 0.09252387196042369, 'n_estimators': 74, 'reg_alpha': 127222.74169746756, 'reg_lambda': 1.2745130800150342}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:33,571]\u001b[0m Trial 40 finished with value: -2.2363690547587627 and parameters: {'max_depth': 30, 'num_leaves': 5, 'learning_rate': 0.192306866058407, 'n_estimators': 286, 'reg_alpha': 5983706.237851951, 'reg_lambda': 65968.80799935656}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:33,708]\u001b[0m Trial 39 finished with value: -2.225744319871593 and parameters: {'max_depth': 30, 'num_leaves': 7, 'learning_rate': 0.006879845885723179, 'n_estimators': 295, 'reg_alpha': 2477.4455303449135, 'reg_lambda': 1255893.9212307706}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:33,780]\u001b[0m Trial 36 finished with value: -2.0548079778352086 and parameters: {'max_depth': 18, 'num_leaves': 7, 'learning_rate': 0.002756553989504944, 'n_estimators': 295, 'reg_alpha': 3048.3938616272444, 'reg_lambda': 115.10273605365568}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:35,534]\u001b[0m Trial 45 finished with value: -2.1722733752984658 and parameters: {'max_depth': 22, 'num_leaves': 12, 'learning_rate': 0.22046607063733736, 'n_estimators': 109, 'reg_alpha': 31643.316293524716, 'reg_lambda': 9905.51564126436}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:36,966]\u001b[0m Trial 44 finished with value: -2.2199097181675524 and parameters: {'max_depth': 17, 'num_leaves': 12, 'learning_rate': 0.01905281325366767, 'n_estimators': 344, 'reg_alpha': 38178.014865058685, 'reg_lambda': 4865.334531364669}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:40,161]\u001b[0m Trial 46 finished with value: -2.232906844428721 and parameters: {'max_depth': 14, 'num_leaves': 11, 'learning_rate': 0.016688526132098175, 'n_estimators': 255, 'reg_alpha': 749.2651677133268, 'reg_lambda': 8932284.506643455}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:44,855]\u001b[0m Trial 42 finished with value: -1.9686231763316153 and parameters: {'max_depth': 16, 'num_leaves': 12, 'learning_rate': 0.014591641594862509, 'n_estimators': 338, 'reg_alpha': 1443.6682675938569, 'reg_lambda': 4813.449021873709}. Best is trial 20 with value: -1.9301792766948294.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:48,298]\u001b[0m Trial 47 finished with value: -1.9148721881739148 and parameters: {'max_depth': 25, 'num_leaves': 21, 'learning_rate': 0.0666636485851081, 'n_estimators': 250, 'reg_alpha': 1022.6961951482349, 'reg_lambda': 57190.50935704107}. Best is trial 47 with value: -1.9148721881739148.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:48,404]\u001b[0m Trial 43 finished with value: -1.9943981440784615 and parameters: {'max_depth': 17, 'num_leaves': 21, 'learning_rate': 0.020084256386233523, 'n_estimators': 337, 'reg_alpha': 947.1956306659895, 'reg_lambda': 4363.450230595323}. Best is trial 47 with value: -1.9148721881739148.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:49,280]\u001b[0m Trial 48 finished with value: -1.8890233124944587 and parameters: {'max_depth': 25, 'num_leaves': 20, 'learning_rate': 0.06493847479614717, 'n_estimators': 204, 'reg_alpha': 189.67603261789557, 'reg_lambda': 120498.76611375672}. Best is trial 48 with value: -1.8890233124944587.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:22:54,145]\u001b[0m Trial 49 finished with value: -1.9046968270759883 and parameters: {'max_depth': 26, 'num_leaves': 17, 'learning_rate': 0.04458514273656449, 'n_estimators': 369, 'reg_alpha': 93.10619390635277, 'reg_lambda': 68697.07662595889}. Best is trial 48 with value: -1.8890233124944587.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:22:56,467]\u001b[0m A new study created in memory with name: no-name-500c9b93-6173-451c-a58a-6cc3b6cdaaaf\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:22:57,423]\u001b[0m Trial 2 finished with value: -3.3636582085197184 and parameters: {'max_depth': 7, 'num_leaves': 43, 'learning_rate': 0.0030559051231760577, 'n_estimators': 172, 'reg_alpha': 8545689.551067613, 'reg_lambda': 1.399792608522622e-07}. Best is trial 2 with value: -3.3636582085197184.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:22:57,959]\u001b[0m Trial 3 finished with value: -2.4274021582729444 and parameters: {'max_depth': 31, 'num_leaves': 41, 'learning_rate': 0.041870083555122964, 'n_estimators': 42, 'reg_alpha': 2206.757674018517, 'reg_lambda': 5.9683481467994275}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:22:58,999]\u001b[0m Trial 1 finished with value: -3.1490427908619267 and parameters: {'max_depth': 15, 'num_leaves': 5, 'learning_rate': 0.0008975313186521583, 'n_estimators': 186, 'reg_alpha': 0.26040108034015874, 'reg_lambda': 2203.006344794053}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:09,228]\u001b[0m Trial 0 finished with value: -2.8214783849895073 and parameters: {'max_depth': 39, 'num_leaves': 22, 'learning_rate': 0.24062389020679512, 'n_estimators': 219, 'reg_alpha': 0.0004838861573714578, 'reg_lambda': 45.282812224017114}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:23:09,340]\u001b[0m Trial 6 finished with value: -3.3636572613095477 and parameters: {'max_depth': 35, 'num_leaves': 28, 'learning_rate': 1.2240258434324754e-07, 'n_estimators': 336, 'reg_alpha': 3.9622130250315445e-07, 'reg_lambda': 648497.2103786686}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:09,883]\u001b[0m Trial 7 finished with value: -3.3636582085197184 and parameters: {'max_depth': 34, 'num_leaves': 44, 'learning_rate': 0.0013166276420988983, 'n_estimators': 74, 'reg_alpha': 78414.1249602073, 'reg_lambda': 4.731166253363514e-05}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:13,730]\u001b[0m Trial 5 finished with value: -3.36321662397656 and parameters: {'max_depth': 5, 'num_leaves': 21, 'learning_rate': 9.095469349950518e-07, 'n_estimators': 319, 'reg_alpha': 0.016548726941329795, 'reg_lambda': 0.32979372042740246}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:14,218]\u001b[0m Trial 10 finished with value: -3.3636582085197184 and parameters: {'max_depth': 12, 'num_leaves': 15, 'learning_rate': 1.400617337636911e-05, 'n_estimators': 73, 'reg_alpha': 108439.57056652091, 'reg_lambda': 69674.4508154228}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:23:14,653]\u001b[0m Trial 8 finished with value: -3.3588161181442087 and parameters: {'max_depth': 3, 'num_leaves': 49, 'learning_rate': 0.0002136116085211933, 'n_estimators': 453, 'reg_alpha': 15836.506835224833, 'reg_lambda': 67214.55796388982}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:16,769]\u001b[0m Trial 4 finished with value: -2.6808637231816514 and parameters: {'max_depth': 27, 'num_leaves': 35, 'learning_rate': 0.01780790444834951, 'n_estimators': 252, 'reg_alpha': 0.39924240977957737, 'reg_lambda': 18.140419427892116}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:17,322]\u001b[0m Trial 11 finished with value: -3.3636399330015165 and parameters: {'max_depth': 21, 'num_leaves': 8, 'learning_rate': 1.0455266122719873e-07, 'n_estimators': 114, 'reg_alpha': 6.881426008404075, 'reg_lambda': 0.03490182607703966}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:17,926]\u001b[0m Trial 13 finished with value: -2.4561817754429587 and parameters: {'max_depth': 47, 'num_leaves': 36, 'learning_rate': 0.30648494458680614, 'n_estimators': 15, 'reg_alpha': 442.7122340253115, 'reg_lambda': 0.18515086789422075}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:18,174]\u001b[0m Trial 15 finished with value: -3.126754390718954 and parameters: {'max_depth': 47, 'num_leaves': 34, 'learning_rate': 0.1659942377359788, 'n_estimators': 1, 'reg_alpha': 203.24270639854583, 'reg_lambda': 0.09212262051403443}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:19,028]\u001b[0m Trial 16 finished with value: -2.5216755094738432 and parameters: {'max_depth': 47, 'num_leaves': 36, 'learning_rate': 0.2916806269323083, 'n_estimators': 9, 'reg_alpha': 301.2954420097695, 'reg_lambda': 0.005190785505368989}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:21,791]\u001b[0m Trial 9 finished with value: -2.5094719610944685 and parameters: {'max_depth': 23, 'num_leaves': 9, 'learning_rate': 0.006687806059093297, 'n_estimators': 442, 'reg_alpha': 0.026768527910684774, 'reg_lambda': 0.00046047440131280785}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:24,258]\u001b[0m Trial 12 finished with value: -3.3589409452303713 and parameters: {'max_depth': 38, 'num_leaves': 33, 'learning_rate': 2.5749932689221564e-05, 'n_estimators': 119, 'reg_alpha': 9.286835021895756e-05, 'reg_lambda': 1.31266029892731e-07}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:23:25,025]\u001b[0m Trial 18 finished with value: -2.7259658540818776 and parameters: {'max_depth': 39, 'num_leaves': 41, 'learning_rate': 0.696271857936282, 'n_estimators': 102, 'reg_alpha': 102.33494640120202, 'reg_lambda': 6.758196294877117}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:26,302]\u001b[0m Trial 20 finished with value: -2.4858649991916764 and parameters: {'max_depth': 30, 'num_leaves': 48, 'learning_rate': 0.03908638231707039, 'n_estimators': 40, 'reg_alpha': 4024.8556727814803, 'reg_lambda': 654.7158544369308}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:27,638]\u001b[0m Trial 17 finished with value: -2.559512325705493 and parameters: {'max_depth': 26, 'num_leaves': 41, 'learning_rate': 0.026344057363897104, 'n_estimators': 110, 'reg_alpha': 211.2370615710092, 'reg_lambda': 35.48585021695115}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:23:28,677]\u001b[0m Trial 19 finished with value: -2.7908102399758477 and parameters: {'max_depth': 31, 'num_leaves': 40, 'learning_rate': 0.7379478077458168, 'n_estimators': 51, 'reg_alpha': 37.510820490281965, 'reg_lambda': 22.77170356885698}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:23:28,799]\u001b[0m Trial 14 finished with value: -2.596463617783414 and parameters: {'max_depth': 27, 'num_leaves': 36, 'learning_rate': 0.08106643973810546, 'n_estimators': 311, 'reg_alpha': 207.78751105289675, 'reg_lambda': 23.12175232158128}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:29,870]\u001b[0m Trial 24 finished with value: -2.521174927236933 and parameters: {'max_depth': 43, 'num_leaves': 48, 'learning_rate': 0.04499665673188019, 'n_estimators': 36, 'reg_alpha': 4894.544216156468, 'reg_lambda': 1058.8821766683252}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:34,024]\u001b[0m Trial 25 finished with value: -2.4293784811434396 and parameters: {'max_depth': 17, 'num_leaves': 46, 'learning_rate': 0.01183929081002941, 'n_estimators': 157, 'reg_alpha': 3836.9468081799337, 'reg_lambda': 0.4199587655131654}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:38,364]\u001b[0m Trial 21 finished with value: -2.666309362988994 and parameters: {'max_depth': 43, 'num_leaves': 28, 'learning_rate': 0.03401844670488444, 'n_estimators': 165, 'reg_alpha': 21.074639117043414, 'reg_lambda': 0.796804016935639}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:39,220]\u001b[0m Trial 27 finished with value: -3.3636582085197184 and parameters: {'max_depth': 19, 'num_leaves': 46, 'learning_rate': 0.015338867626992705, 'n_estimators': 151, 'reg_alpha': 1275999.3609117058, 'reg_lambda': 1.3770000779462734}. Best is trial 3 with value: -2.4274021582729444.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:41,408]\u001b[0m Trial 28 finished with value: -2.381374818180167 and parameters: {'max_depth': -1, 'num_leaves': 39, 'learning_rate': 0.13422880119073435, 'n_estimators': 210, 'reg_alpha': 2134.475062075515, 'reg_lambda': 0.015835583356054266}. Best is trial 28 with value: -2.381374818180167.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:23:41,707]\u001b[0m Trial 22 finished with value: -2.8701920587435503 and parameters: {'max_depth': 43, 'num_leaves': 28, 'learning_rate': 0.8386303633885588, 'n_estimators': 284, 'reg_alpha': 17.22878670388378, 'reg_lambda': 0.22531739464001946}. Best is trial 28 with value: -2.381374818180167.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:42,720]\u001b[0m Trial 29 finished with value: -3.3636582085197184 and parameters: {'max_depth': 10, 'num_leaves': 50, 'learning_rate': 0.003896177479609886, 'n_estimators': 251, 'reg_alpha': 400074.149437376, 'reg_lambda': 0.006015940237636372}. Best is trial 28 with value: -2.381374818180167.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:43,645]\u001b[0m Trial 26 finished with value: -2.619811541655363 and parameters: {'max_depth': 17, 'num_leaves': 28, 'learning_rate': 0.00884566697645562, 'n_estimators': 138, 'reg_alpha': 9.862575267082534, 'reg_lambda': 0.4663919205562259}. Best is trial 28 with value: -2.381374818180167.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:45,035]\u001b[0m Trial 23 finished with value: -2.756460347461909 and parameters: {'max_depth': 43, 'num_leaves': 29, 'learning_rate': 0.07011619783110942, 'n_estimators': 280, 'reg_alpha': 3.237266674803062, 'reg_lambda': 0.9196335006783036}. Best is trial 28 with value: -2.381374818180167.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:45,751]\u001b[0m Trial 32 finished with value: -2.352780657860192 and parameters: {'max_depth': -1, 'num_leaves': 39, 'learning_rate': 0.12097516583564287, 'n_estimators': 202, 'reg_alpha': 3582.4940008105696, 'reg_lambda': 2.153692639312028}. Best is trial 32 with value: -2.352780657860192.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:46,203]\u001b[0m Trial 31 finished with value: -2.3443971765723615 and parameters: {'max_depth': 16, 'num_leaves': 31, 'learning_rate': 0.09325098627483164, 'n_estimators': 371, 'reg_alpha': 2964.1832269175197, 'reg_lambda': 1.9207073022286194}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:46,910]\u001b[0m Trial 30 finished with value: -2.4986133230545424 and parameters: {'max_depth': 9, 'num_leaves': 39, 'learning_rate': 0.0063161831512529324, 'n_estimators': 214, 'reg_alpha': 3924.765340103559, 'reg_lambda': 0.005718275548351375}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:23:46,993]\u001b[0m Trial 33 finished with value: -2.3776991282073836 and parameters: {'max_depth': -1, 'num_leaves': 39, 'learning_rate': 0.18515115373124286, 'n_estimators': 210, 'reg_alpha': 2120.3674664698838, 'reg_lambda': 0.015819690751257304}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:47,955]\u001b[0m Trial 34 finished with value: -2.3828367446387593 and parameters: {'max_depth': -1, 'num_leaves': 39, 'learning_rate': 0.13655860872520004, 'n_estimators': 212, 'reg_alpha': 1814.2139653702375, 'reg_lambda': 3.4933711266757626}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:48,567]\u001b[0m Trial 35 finished with value: -3.740769370997898 and parameters: {'max_depth': -1, 'num_leaves': 32, 'learning_rate': 0.17669980787109113, 'n_estimators': 392, 'reg_alpha': 22900.624223828858, 'reg_lambda': 147.44971080101246}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:48,645]\u001b[0m Trial 36 finished with value: -3.3636582085197184 and parameters: {'max_depth': -1, 'num_leaves': 23, 'learning_rate': 0.11364218700675359, 'n_estimators': 380, 'reg_alpha': 50904.94183265369, 'reg_lambda': 337.9890572597877}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:49,314]\u001b[0m Trial 37 finished with value: -3.226711304605999 and parameters: {'max_depth': -1, 'num_leaves': 22, 'learning_rate': 0.14189216360290174, 'n_estimators': 377, 'reg_alpha': 19652.127036140377, 'reg_lambda': 324.50865842130565}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:49,726]\u001b[0m Trial 40 finished with value: -3.3636582085197184 and parameters: {'max_depth': 3, 'num_leaves': 24, 'learning_rate': 0.37872970587422167, 'n_estimators': 199, 'reg_alpha': 382654.414855698, 'reg_lambda': 0.02574450894134199}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:23:49,792]\u001b[0m Trial 39 finished with value: -3.3636582085197184 and parameters: {'max_depth': 1, 'num_leaves': 19, 'learning_rate': 0.08068385163117374, 'n_estimators': 196, 'reg_alpha': 1321436.677189072, 'reg_lambda': 0.01910277747859048}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:50,286]\u001b[0m Trial 41 finished with value: -3.3636582085197184 and parameters: {'max_depth': 4, 'num_leaves': 32, 'learning_rate': 0.02236437975992583, 'n_estimators': 191, 'reg_alpha': 1447880.0910204363, 'reg_lambda': 0.031287773689756514}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:23:50,294]\u001b[0m Trial 38 finished with value: -3.736661687268821 and parameters: {'max_depth': 0, 'num_leaves': 32, 'learning_rate': 0.2108507810834618, 'n_estimators': 425, 'reg_alpha': 28174.1251678714, 'reg_lambda': 164.8579639612331}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:50,821]\u001b[0m Trial 42 finished with value: -3.3636582085197184 and parameters: {'max_depth': 5, 'num_leaves': 31, 'learning_rate': 0.06859518382510732, 'n_estimators': 234, 'reg_alpha': 4773540.506693004, 'reg_lambda': 0.00038168735155772387}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:51,698]\u001b[0m Trial 45 finished with value: -2.413449192799496 and parameters: {'max_depth': 6, 'num_leaves': 38, 'learning_rate': 0.4327210448562153, 'n_estimators': 223, 'reg_alpha': 1621.103425169824, 'reg_lambda': 2.236864600483532}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:52,060]\u001b[0m Trial 44 finished with value: -2.5020987248471527 and parameters: {'max_depth': 7, 'num_leaves': 38, 'learning_rate': 0.4141499851587501, 'n_estimators': 245, 'reg_alpha': 479.6940954822749, 'reg_lambda': 2.356351769817772}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:23:52,362]\u001b[0m Trial 46 finished with value: -2.454304504089387 and parameters: {'max_depth': 7, 'num_leaves': 38, 'learning_rate': 0.437593799706179, 'n_estimators': 230, 'reg_alpha': 772.3667871966488, 'reg_lambda': 4.427679358337396}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:53,540]\u001b[0m Trial 48 finished with value: -2.4203057841084594 and parameters: {'max_depth': 2, 'num_leaves': 43, 'learning_rate': 0.9100905103018184, 'n_estimators': 297, 'reg_alpha': 1084.0136456471548, 'reg_lambda': 4.506897337354505}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:54,687]\u001b[0m Trial 49 finished with value: -2.9726872373952262 and parameters: {'max_depth': 2, 'num_leaves': 44, 'learning_rate': 0.0016809842865553029, 'n_estimators': 278, 'reg_alpha': 8007.244524449373, 'reg_lambda': 49.98016428371842}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:23:55,109]\u001b[0m Trial 47 finished with value: -2.4271186381535017 and parameters: {'max_depth': 8, 'num_leaves': 43, 'learning_rate': 0.16166533155321483, 'n_estimators': 494, 'reg_alpha': 900.9587436102196, 'reg_lambda': 2.514667683150783}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:56,098]\u001b[0m Trial 43 finished with value: -2.4116782609475065 and parameters: {'max_depth': 7, 'num_leaves': 44, 'learning_rate': 0.02022569679253584, 'n_estimators': 277, 'reg_alpha': 1082.160664007353, 'reg_lambda': 0.00021158247753727072}. Best is trial 31 with value: -2.3443971765723615.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:23:57,816]\u001b[0m A new study created in memory with name: no-name-d85fb492-f954-4f3b-9cb2-2ef3f763bb57\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:02,354]\u001b[0m Trial 3 finished with value: -3.0192812751575726 and parameters: {'max_depth': 4, 'num_leaves': 9, 'learning_rate': 1.1609855808834223e-06, 'n_estimators': 128, 'reg_alpha': 1.8535789020943964e-06, 'reg_lambda': 8.430357736247813e-06}. Best is trial 3 with value: -3.0192812751575726.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:02,589]\u001b[0m Trial 0 finished with value: -3.0173043375933872 and parameters: {'max_depth': 2, 'num_leaves': 33, 'learning_rate': 5.550264719246008e-06, 'n_estimators': 296, 'reg_alpha': 0.0011530297666905022, 'reg_lambda': 0.009912664278286297}. Best is trial 0 with value: -3.0173043375933872.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:07,687]\u001b[0m Trial 1 finished with value: -2.345507496308048 and parameters: {'max_depth': 3, 'num_leaves': 37, 'learning_rate': 0.2812440441146968, 'n_estimators': 387, 'reg_alpha': 41.657895536727935, 'reg_lambda': 1.3505957459085281e-06}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:10,282]\u001b[0m Trial 2 finished with value: -2.7801450932591694 and parameters: {'max_depth': 41, 'num_leaves': 49, 'learning_rate': 0.0015917466060928948, 'n_estimators': 118, 'reg_alpha': 846.9904705290277, 'reg_lambda': 7.930744763363514e-07}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:13,730]\u001b[0m Trial 4 finished with value: -3.0165472271629583 and parameters: {'max_depth': 30, 'num_leaves': 35, 'learning_rate': 1.6088378195385923e-05, 'n_estimators': 111, 'reg_alpha': 37.024856836149965, 'reg_lambda': 0.057868921519167865}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:23,912]\u001b[0m Trial 5 finished with value: -3.0191541083255533 and parameters: {'max_depth': 8, 'num_leaves': 30, 'learning_rate': 2.5887856596823438e-06, 'n_estimators': 486, 'reg_alpha': 3.463765600162717e-07, 'reg_lambda': 131775.23871138034}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:25,954]\u001b[0m Trial 9 finished with value: -3.0194874451653706 and parameters: {'max_depth': 20, 'num_leaves': 6, 'learning_rate': 4.819264641013081e-07, 'n_estimators': 86, 'reg_alpha': 3.231309914811185e-05, 'reg_lambda': 4097349.0173101914}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:29,305]\u001b[0m Trial 8 finished with value: -2.9428861362286716 and parameters: {'max_depth': 47, 'num_leaves': 33, 'learning_rate': 0.003844113551271548, 'n_estimators': 323, 'reg_alpha': 0.01982689353659556, 'reg_lambda': 633113.3017148428}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:31,887]\u001b[0m Trial 11 finished with value: -3.0194878727469945 and parameters: {'max_depth': 9, 'num_leaves': 16, 'learning_rate': 2.7582559507802973e-06, 'n_estimators': 331, 'reg_alpha': 786720.4408039976, 'reg_lambda': 246.60899183357463}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:41,005]\u001b[0m Trial 6 finished with value: -2.399541892112373 and parameters: {'max_depth': 35, 'num_leaves': 44, 'learning_rate': 0.05007406890966151, 'n_estimators': 281, 'reg_alpha': 1.7418283975245315e-06, 'reg_lambda': 0.04427052863398475}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:42,754]\u001b[0m Trial 12 finished with value: -2.529045233617139 and parameters: {'max_depth': 4, 'num_leaves': 6, 'learning_rate': 0.006585954407109965, 'n_estimators': 486, 'reg_alpha': 0.0025877982962758312, 'reg_lambda': 108352.31339059027}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:45,257]\u001b[0m Trial 7 finished with value: -2.4314858650150493 and parameters: {'max_depth': 10, 'num_leaves': 45, 'learning_rate': 0.4716019526576505, 'n_estimators': 387, 'reg_alpha': 0.00028109005682435, 'reg_lambda': 0.12656361613098227}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:24:51,577]\u001b[0m Trial 10 finished with value: -2.360483984756497 and parameters: {'max_depth': 12, 'num_leaves': 27, 'learning_rate': 0.01147750290025935, 'n_estimators': 410, 'reg_alpha': 0.000146983179672019, 'reg_lambda': 50971.21786029576}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:06,925]\u001b[0m Trial 13 finished with value: -2.499125447594262 and parameters: {'max_depth': 18, 'num_leaves': 20, 'learning_rate': 0.7078692772081768, 'n_estimators': 472, 'reg_alpha': 0.4309333402702708, 'reg_lambda': 1.613496128323363e-07}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:12,361]\u001b[0m Trial 16 finished with value: -2.446073096020188 and parameters: {'max_depth': 18, 'num_leaves': 21, 'learning_rate': 0.7082082783790534, 'n_estimators': 410, 'reg_alpha': 0.08154220939570468, 'reg_lambda': 82.3193770380781}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:20,414]\u001b[0m Trial 15 finished with value: -2.464416444907442 and parameters: {'max_depth': 30, 'num_leaves': 41, 'learning_rate': 0.5502376582849159, 'n_estimators': 409, 'reg_alpha': 0.5507201397421739, 'reg_lambda': 0.00010244494749804565}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:21,714]\u001b[0m Trial 17 finished with value: -2.370078519234202 and parameters: {'max_depth': 14, 'num_leaves': 24, 'learning_rate': 0.03924782934490824, 'n_estimators': 203, 'reg_alpha': 0.8720835168800335, 'reg_lambda': 172.90432432154864}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:25:27,865]\u001b[0m Trial 14 finished with value: -2.455498493630519 and parameters: {'max_depth': 30, 'num_leaves': 46, 'learning_rate': 0.4602913514442357, 'n_estimators': 392, 'reg_alpha': 0.5271906794311161, 'reg_lambda': 0.00010748055175452385}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:31,200]\u001b[0m Trial 18 finished with value: -2.392733838004885 and parameters: {'max_depth': 13, 'num_leaves': 38, 'learning_rate': 0.043041645047948496, 'n_estimators': 208, 'reg_alpha': 11.500959930121896, 'reg_lambda': 0.00040209194237269565}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:33,740]\u001b[0m Trial 19 finished with value: -2.3964090814756975 and parameters: {'max_depth': 13, 'num_leaves': 25, 'learning_rate': 0.030253481287759905, 'n_estimators': 203, 'reg_alpha': 15.213798553142928, 'reg_lambda': 0.0003824324748947121}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:34,656]\u001b[0m Trial 22 finished with value: -2.9576792623107835 and parameters: {'max_depth': 1, 'num_leaves': 28, 'learning_rate': 0.0001836925747020356, 'n_estimators': 362, 'reg_alpha': 3.7377858723316886e-05, 'reg_lambda': 2.2612596898922193}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:35,222]\u001b[0m Trial 24 finished with value: -2.962169731631976 and parameters: {'max_depth': 24, 'num_leaves': 23, 'learning_rate': 0.05533103751563232, 'n_estimators': 1, 'reg_alpha': 0.012755866400502747, 'reg_lambda': 7338.30940209087}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:37,174]\u001b[0m Trial 23 finished with value: -3.0063304395329853 and parameters: {'max_depth': -1, 'num_leaves': 29, 'learning_rate': 0.00020850250399176028, 'n_estimators': 39, 'reg_alpha': 2.4260751914156364e-05, 'reg_lambda': 2.450432934526734}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:41,229]\u001b[0m Trial 25 finished with value: -2.3901765702785904 and parameters: {'max_depth': 15, 'num_leaves': 15, 'learning_rate': 0.11941544352251589, 'n_estimators': 236, 'reg_alpha': 618.0403497333327, 'reg_lambda': 2216.829935899158}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:41,744]\u001b[0m Trial 26 finished with value: -2.390010595529906 and parameters: {'max_depth': 14, 'num_leaves': 16, 'learning_rate': 0.1403979153392755, 'n_estimators': 208, 'reg_alpha': 1302.1175542769552, 'reg_lambda': 1725.9060216130292}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:25:48,527]\u001b[0m Trial 21 finished with value: -2.9608422904942344 and parameters: {'max_depth': -1, 'num_leaves': 39, 'learning_rate': 0.00020390467830282857, 'n_estimators': 191, 'reg_alpha': 477.6008256281727, 'reg_lambda': 1.7270458582857344}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:26:01,464]\u001b[0m Trial 20 finished with value: -2.950456642512261 and parameters: {'max_depth': -1, 'num_leaves': 37, 'learning_rate': 0.00011747225977165074, 'n_estimators': 379, 'reg_alpha': 83.10742514088946, 'reg_lambda': 2.9969964429184506}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:26:17,402]\u001b[0m Trial 28 finished with value: -2.3774532013736818 and parameters: {'max_depth': 7, 'num_leaves': 38, 'learning_rate': 0.01113887274898154, 'n_estimators': 439, 'reg_alpha': 0.03952100188951211, 'reg_lambda': 11.14703006845392}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:26:17,748]\u001b[0m Trial 27 finished with value: -2.3483053830814895 and parameters: {'max_depth': 7, 'num_leaves': 38, 'learning_rate': 0.014180223291811605, 'n_estimators': 450, 'reg_alpha': 1.1741120526855301e-07, 'reg_lambda': 89.56777749832044}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:26:21,917]\u001b[0m Trial 29 finished with value: -2.376216076781244 and parameters: {'max_depth': 23, 'num_leaves': 25, 'learning_rate': 0.014139857147962077, 'n_estimators': 434, 'reg_alpha': 0.04389124203270048, 'reg_lambda': 104.67304986610641}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:26:30,484]\u001b[0m Trial 30 finished with value: -2.3878110618247446 and parameters: {'max_depth': 6, 'num_leaves': 24, 'learning_rate': 0.013414845347435611, 'n_estimators': 448, 'reg_alpha': 2.6627672015621657, 'reg_lambda': 62.45170815870542}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:26:41,233]\u001b[0m Trial 31 finished with value: -2.386428176050684 and parameters: {'max_depth': 23, 'num_leaves': 26, 'learning_rate': 0.015154986986867937, 'n_estimators': 338, 'reg_alpha': 2.2716388570657906, 'reg_lambda': 33.69201025624433}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:26:44,527]\u001b[0m Trial 32 finished with value: -2.4811130367092544 and parameters: {'max_depth': 5, 'num_leaves': 32, 'learning_rate': 0.00126670264596138, 'n_estimators': 441, 'reg_alpha': 4.815545938447632e-07, 'reg_lambda': 0.015983834639027764}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:26:53,969]\u001b[0m Trial 33 finished with value: -2.4124579611496575 and parameters: {'max_depth': 5, 'num_leaves': 32, 'learning_rate': 0.0017686165350100115, 'n_estimators': 448, 'reg_alpha': 1.5292776080836558e-07, 'reg_lambda': 0.004913044001495387}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:04,330]\u001b[0m Trial 34 finished with value: -2.4151352562841057 and parameters: {'max_depth': 11, 'num_leaves': 32, 'learning_rate': 0.0020537914319233006, 'n_estimators': 344, 'reg_alpha': 1.2339154585997285e-07, 'reg_lambda': 0.006822979839967998}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:04,633]\u001b[0m Trial 35 finished with value: -2.3862917492350166 and parameters: {'max_depth': 11, 'num_leaves': 32, 'learning_rate': 0.0028640701546530285, 'n_estimators': 282, 'reg_alpha': 1.00015439823534e-07, 'reg_lambda': 0.2849490920519722}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:08,700]\u001b[0m Trial 38 finished with value: -2.4517355530753426 and parameters: {'max_depth': 2, 'num_leaves': 42, 'learning_rate': 0.14880639948033628, 'n_estimators': 282, 'reg_alpha': 0.0009364391652182921, 'reg_lambda': 2.76728805273371e-06}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:08,913]\u001b[0m Trial 39 finished with value: -2.462076085014968 and parameters: {'max_depth': 2, 'num_leaves': 42, 'learning_rate': 0.16642331640111618, 'n_estimators': 303, 'reg_alpha': 4.077404155011174e-06, 'reg_lambda': 1.2246622783943875e-06}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:17,733]\u001b[0m Trial 36 finished with value: -2.3901651646882867 and parameters: {'max_depth': 11, 'num_leaves': 49, 'learning_rate': 0.0031019977384246183, 'n_estimators': 290, 'reg_alpha': 0.0007631936576909479, 'reg_lambda': 728.8558027618418}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:24,594]\u001b[0m Trial 37 finished with value: -2.423644389286344 and parameters: {'max_depth': 11, 'num_leaves': 41, 'learning_rate': 0.1309135340612555, 'n_estimators': 282, 'reg_alpha': 0.0016239311441212912, 'reg_lambda': 0.33095983999370365}. Best is trial 1 with value: -2.345507496308048.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:25,415]\u001b[0m Trial 40 finished with value: -2.3216157415938437 and parameters: {'max_depth': 16, 'num_leaves': 35, 'learning_rate': 0.22094610440590842, 'n_estimators': 160, 'reg_alpha': 1.3117407745727483e-05, 'reg_lambda': 18192.865307543267}. Best is trial 40 with value: -2.3216157415938437.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:29,942]\u001b[0m Trial 41 finished with value: -2.8176838688853176 and parameters: {'max_depth': 16, 'num_leaves': 35, 'learning_rate': 0.0006426616476199776, 'n_estimators': 247, 'reg_alpha': 2.5890591991997035e-06, 'reg_lambda': 608.6487575415989}. Best is trial 40 with value: -2.3216157415938437.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:31,691]\u001b[0m Trial 42 finished with value: -2.340855579400534 and parameters: {'max_depth': 17, 'num_leaves': 36, 'learning_rate': 0.027536132543541047, 'n_estimators': 166, 'reg_alpha': 5.374356724978254e-06, 'reg_lambda': 23496.537609848634}. Best is trial 40 with value: -2.3216157415938437.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:27:39,469]\u001b[0m Trial 44 finished with value: -2.2982226901176346 and parameters: {'max_depth': 16, 'num_leaves': 34, 'learning_rate': 0.05340667988582308, 'n_estimators': 139, 'reg_alpha': 2.2835479101174925e-06, 'reg_lambda': 17710.6836388134}. Best is trial 44 with value: -2.2982226901176346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:40,718]\u001b[0m Trial 43 finished with value: -2.327561930170842 and parameters: {'max_depth': 8, 'num_leaves': 35, 'learning_rate': 0.030964965605197174, 'n_estimators': 164, 'reg_alpha': 5.658036734820387e-06, 'reg_lambda': 20934.76836759772}. Best is trial 44 with value: -2.2982226901176346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:41,784]\u001b[0m Trial 45 finished with value: -2.3108642044997123 and parameters: {'max_depth': 20, 'num_leaves': 35, 'learning_rate': 0.027578425263575814, 'n_estimators': 137, 'reg_alpha': 0.00011091777699810363, 'reg_lambda': 13104.679636431563}. Best is trial 44 with value: -2.2982226901176346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:44,437]\u001b[0m Trial 46 finished with value: -2.586231628801321 and parameters: {'max_depth': 19, 'num_leaves': 36, 'learning_rate': 0.006002216592601196, 'n_estimators': 149, 'reg_alpha': 0.00011347199127718546, 'reg_lambda': 17104.344485770645}. Best is trial 44 with value: -2.2982226901176346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:53,999]\u001b[0m Trial 47 finished with value: -2.325130495762622 and parameters: {'max_depth': 20, 'num_leaves': 36, 'learning_rate': 0.3029089438511889, 'n_estimators': 148, 'reg_alpha': 9.386834586505362e-07, 'reg_lambda': 10420.911377081793}. Best is trial 44 with value: -2.2982226901176346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:54,109]\u001b[0m Trial 48 finished with value: -2.338748317873672 and parameters: {'max_depth': 26, 'num_leaves': 35, 'learning_rate': 0.352164865745306, 'n_estimators': 150, 'reg_alpha': 1.0317089710141035e-05, 'reg_lambda': 29467.65769696275}. Best is trial 44 with value: -2.2982226901176346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:54,230]\u001b[0m Trial 49 finished with value: -2.3700024302494276 and parameters: {'max_depth': 20, 'num_leaves': 35, 'learning_rate': 0.29533160547297277, 'n_estimators': 151, 'reg_alpha': 4.801477807974327e-06, 'reg_lambda': 21478.677571390966}. Best is trial 44 with value: -2.2982226901176346.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:27:56,981]\u001b[0m A new study created in memory with name: no-name-445701fc-b876-46cb-b246-e725abd99ca9\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:27:59,898]\u001b[0m Trial 2 finished with value: -3.423719852980378 and parameters: {'max_depth': 5, 'num_leaves': 33, 'learning_rate': 2.477315143627008e-07, 'n_estimators': 30, 'reg_alpha': 0.006125466375063247, 'reg_lambda': 1.8090413580827857e-05}. Best is trial 2 with value: -3.423719852980378.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:00,293]\u001b[0m Trial 0 finished with value: -3.423734638411184 and parameters: {'max_depth': 16, 'num_leaves': 43, 'learning_rate': 0.01592480061639797, 'n_estimators': 348, 'reg_alpha': 1796271.750684318, 'reg_lambda': 3368.9482355488576}. Best is trial 2 with value: -3.423719852980378.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:01,965]\u001b[0m Trial 3 finished with value: -2.666083140464198 and parameters: {'max_depth': 22, 'num_leaves': 31, 'learning_rate': 0.017731784926385934, 'n_estimators': 93, 'reg_alpha': 10006.958366425803, 'reg_lambda': 4372.222929083421}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:02,439]\u001b[0m Trial 5 finished with value: -3.423734638411184 and parameters: {'max_depth': 15, 'num_leaves': 20, 'learning_rate': 1.0050544287764824e-05, 'n_estimators': 232, 'reg_alpha': 1930737.2199664211, 'reg_lambda': 1.1434594325359198e-07}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:18,604]\u001b[0m Trial 6 finished with value: -3.4236788869513615 and parameters: {'max_depth': 28, 'num_leaves': 32, 'learning_rate': 1.6846949673357778e-07, 'n_estimators': 168, 'reg_alpha': 5.999503093305396e-07, 'reg_lambda': 0.3219369829687759}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:20,201]\u001b[0m Trial 7 finished with value: -3.1396380321282957 and parameters: {'max_depth': 22, 'num_leaves': 46, 'learning_rate': 0.0038444733786368876, 'n_estimators': 160, 'reg_alpha': 1.9350640262509857e-06, 'reg_lambda': 47883.80232565602}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:23,844]\u001b[0m Trial 9 finished with value: -3.2770035265002924 and parameters: {'max_depth': 26, 'num_leaves': 7, 'learning_rate': 0.001359992256730463, 'n_estimators': 137, 'reg_alpha': 6873.363440048508, 'reg_lambda': 17058.44679402316}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:25,308]\u001b[0m Trial 1 finished with value: -3.4236352893726774 and parameters: {'max_depth': 7, 'num_leaves': 28, 'learning_rate': 1.2616887229401846e-07, 'n_estimators': 401, 'reg_alpha': 4.57457336692609e-05, 'reg_lambda': 1.2391596793302375}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:27,192]\u001b[0m Trial 10 finished with value: -3.5424082590857404 and parameters: {'max_depth': 43, 'num_leaves': 5, 'learning_rate': 0.022692034056121715, 'n_estimators': 204, 'reg_alpha': 90378.83573583493, 'reg_lambda': 0.0016872241212953095}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:28,986]\u001b[0m Trial 11 finished with value: -2.687243104847237 and parameters: {'max_depth': 1, 'num_leaves': 47, 'learning_rate': 0.004041770603785183, 'n_estimators': 262, 'reg_alpha': 3.6319033066923323, 'reg_lambda': 0.0004823655727206505}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:30,448]\u001b[0m Trial 12 finished with value: -3.4236853907227314 and parameters: {'max_depth': 11, 'num_leaves': 33, 'learning_rate': 9.0051596828186e-07, 'n_estimators': 28, 'reg_alpha': 8.559874623926547, 'reg_lambda': 225.37414793256093}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:30,767]\u001b[0m Trial 13 finished with value: -3.143445164232585 and parameters: {'max_depth': 39, 'num_leaves': 16, 'learning_rate': 0.584333448935843, 'n_estimators': 32, 'reg_alpha': 127.74541538105264, 'reg_lambda': 2057427.3177573055}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:53,574]\u001b[0m Trial 8 finished with value: -3.375718517876565 and parameters: {'max_depth': 17, 'num_leaves': 33, 'learning_rate': 6.584772976280307e-05, 'n_estimators': 368, 'reg_alpha': 140.59493055831481, 'reg_lambda': 0.005895177473076848}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:58,502]\u001b[0m Trial 4 finished with value: -3.423105779001587 and parameters: {'max_depth': 0, 'num_leaves': 50, 'learning_rate': 6.324122140181764e-07, 'n_estimators': 497, 'reg_alpha': 7.512901540083376, 'reg_lambda': 27.4899660559828}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:28:58,566]\u001b[0m Trial 16 finished with value: -3.215489638005086 and parameters: {'max_depth': 1, 'num_leaves': 50, 'learning_rate': 0.00031711167854875464, 'n_estimators': 498, 'reg_alpha': 0.2319500858391154, 'reg_lambda': 96.47203950713039}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:08,683]\u001b[0m Trial 18 finished with value: -3.187996072005199 and parameters: {'max_depth': 39, 'num_leaves': 40, 'learning_rate': 0.1397715411223411, 'n_estimators': 293, 'reg_alpha': 4027.7531339028947, 'reg_lambda': 5324356.791588603}. Best is trial 3 with value: -2.666083140464198.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:09,396]\u001b[0m Trial 14 finished with value: -2.536609664673527 and parameters: {'max_depth': 39, 'num_leaves': 50, 'learning_rate': 0.21910421787679865, 'n_estimators': 499, 'reg_alpha': 187.28759835882403, 'reg_lambda': 1178084.3118756989}. Best is trial 14 with value: -2.536609664673527.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:29:12,014]\u001b[0m Trial 20 finished with value: -2.5735890404304804 and parameters: {'max_depth': 34, 'num_leaves': 39, 'learning_rate': 0.8971891820933637, 'n_estimators': 104, 'reg_alpha': 13561.860568606877, 'reg_lambda': 255947.4866689609}. Best is trial 14 with value: -2.536609664673527.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:13,687]\u001b[0m Trial 17 finished with value: -3.4232768160686504 and parameters: {'max_depth': 31, 'num_leaves': 39, 'learning_rate': 0.0003193111583394787, 'n_estimators': 289, 'reg_alpha': 0.3318784023775744, 'reg_lambda': 7923746.420898113}. Best is trial 14 with value: -2.536609664673527.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:15,164]\u001b[0m Trial 19 finished with value: -2.4106257637108284 and parameters: {'max_depth': 32, 'num_leaves': 21, 'learning_rate': 0.023456926003829454, 'n_estimators': 84, 'reg_alpha': 0.1247644357424773, 'reg_lambda': 0.3277280744260674}. Best is trial 19 with value: -2.4106257637108284.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:17,115]\u001b[0m Trial 22 finished with value: -3.423734638411184 and parameters: {'max_depth': 35, 'num_leaves': 39, 'learning_rate': 0.9227330894350049, 'n_estimators': 439, 'reg_alpha': 9928746.61366259, 'reg_lambda': 224594.2503894438}. Best is trial 19 with value: -2.4106257637108284.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:22,287]\u001b[0m Trial 24 finished with value: -2.679910273980993 and parameters: {'max_depth': 47, 'num_leaves': 21, 'learning_rate': 0.16309885477728478, 'n_estimators': 92, 'reg_alpha': 0.011845672980681326, 'reg_lambda': 333746.2116932696}. Best is trial 19 with value: -2.4106257637108284.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:23,634]\u001b[0m Trial 25 finished with value: -3.6675496757705375 and parameters: {'max_depth': 33, 'num_leaves': 24, 'learning_rate': 0.13875356797822266, 'n_estimators': 87, 'reg_alpha': 122661.28584770599, 'reg_lambda': 165523.98009531744}. Best is trial 19 with value: -2.4106257637108284.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:27,991]\u001b[0m Trial 26 finished with value: -2.4679753318662514 and parameters: {'max_depth': 38, 'num_leaves': 12, 'learning_rate': 0.4174401864748574, 'n_estimators': 114, 'reg_alpha': 131.88537948839752, 'reg_lambda': 1273.7168289351346}. Best is trial 19 with value: -2.4106257637108284.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:30,291]\u001b[0m Trial 15 finished with value: -3.293880042551538 and parameters: {'max_depth': -1, 'num_leaves': 50, 'learning_rate': 0.00013374397747119925, 'n_estimators': 497, 'reg_alpha': 0.06482047472198298, 'reg_lambda': 11.343138382822511}. Best is trial 19 with value: -2.4106257637108284.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:32,932]\u001b[0m Trial 28 finished with value: -2.412146688759692 and parameters: {'max_depth': 39, 'num_leaves': 14, 'learning_rate': 0.05970563805449328, 'n_estimators': 57, 'reg_alpha': 689.3136080749132, 'reg_lambda': 1726.6798933038378}. Best is trial 19 with value: -2.4106257637108284.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:34,971]\u001b[0m Trial 27 finished with value: -2.4052140540282414 and parameters: {'max_depth': 39, 'num_leaves': 11, 'learning_rate': 0.056152837898320936, 'n_estimators': 199, 'reg_alpha': 206.97721001124427, 'reg_lambda': 1111.337387324843}. Best is trial 27 with value: -2.4052140540282414.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:35,581]\u001b[0m Trial 29 finished with value: -2.400736795961722 and parameters: {'max_depth': 42, 'num_leaves': 10, 'learning_rate': 0.05285404120970495, 'n_estimators': 65, 'reg_alpha': 33.28606322402609, 'reg_lambda': 867.9833551860137}. Best is trial 29 with value: -2.400736795961722.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:37,730]\u001b[0m Trial 30 finished with value: -2.403433606777188 and parameters: {'max_depth': 45, 'num_leaves': 13, 'learning_rate': 0.05157231850010347, 'n_estimators': 59, 'reg_alpha': 877.9241060095518, 'reg_lambda': 577.7392679279644}. Best is trial 29 with value: -2.400736795961722.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:38,362]\u001b[0m Trial 32 finished with value: -3.0531014861482215 and parameters: {'max_depth': 47, 'num_leaves': 9, 'learning_rate': 0.0585952101533404, 'n_estimators': 6, 'reg_alpha': 20.796736234099804, 'reg_lambda': 9230.72151982692}. Best is trial 29 with value: -2.400736795961722.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:39,825]\u001b[0m Trial 23 finished with value: -2.5202248677425336 and parameters: {'max_depth': 47, 'num_leaves': 21, 'learning_rate': 0.10721570119598106, 'n_estimators': 428, 'reg_alpha': 0.00017760693857197502, 'reg_lambda': 2.278739784881654}. Best is trial 29 with value: -2.400736795961722.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:41,374]\u001b[0m Trial 31 finished with value: -2.3976664092455575 and parameters: {'max_depth': 46, 'num_leaves': 9, 'learning_rate': 0.03767044023580811, 'n_estimators': 201, 'reg_alpha': 2.255420784009074, 'reg_lambda': 2.8978563108392303}. Best is trial 31 with value: -2.3976664092455575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:42,841]\u001b[0m Trial 34 finished with value: -2.4062742902050567 and parameters: {'max_depth': 43, 'num_leaves': 11, 'learning_rate': 0.03313805958904325, 'n_estimators': 63, 'reg_alpha': 0.9817769575771473, 'reg_lambda': 494.7180266474205}. Best is trial 31 with value: -2.3976664092455575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:44,724]\u001b[0m Trial 33 finished with value: -2.4098760735946296 and parameters: {'max_depth': 44, 'num_leaves': 10, 'learning_rate': 0.009281675983897874, 'n_estimators': 193, 'reg_alpha': 1120.4589838471816, 'reg_lambda': 402.5921393322079}. Best is trial 31 with value: -2.3976664092455575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:47,879]\u001b[0m Trial 35 finished with value: -2.4467195474459076 and parameters: {'max_depth': 43, 'num_leaves': 10, 'learning_rate': 0.006148939577148986, 'n_estimators': 202, 'reg_alpha': 1.7584854526630609, 'reg_lambda': 425.5422513002261}. Best is trial 31 with value: -2.3976664092455575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:50,990]\u001b[0m Trial 37 finished with value: -2.572062635756417 and parameters: {'max_depth': 43, 'num_leaves': 17, 'learning_rate': 0.008371579776604158, 'n_estimators': 131, 'reg_alpha': 1.5109967146857426, 'reg_lambda': 4016.1005704648446}. Best is trial 31 with value: -2.3976664092455575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:52,419]\u001b[0m Trial 36 finished with value: -2.402128286474099 and parameters: {'max_depth': 43, 'num_leaves': 16, 'learning_rate': 0.008241006090684412, 'n_estimators': 187, 'reg_alpha': 28.91368514423008, 'reg_lambda': 99.9386970473571}. Best is trial 31 with value: -2.3976664092455575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:54,925]\u001b[0m Trial 38 finished with value: -2.43118350365682 and parameters: {'max_depth': 36, 'num_leaves': 17, 'learning_rate': 0.03611305833916188, 'n_estimators': 140, 'reg_alpha': 26.33440375632315, 'reg_lambda': 17.664359459717346}. Best is trial 31 with value: -2.3976664092455575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:55,559]\u001b[0m Trial 39 finished with value: -2.5286871747063344 and parameters: {'max_depth': 36, 'num_leaves': 5, 'learning_rate': 0.3391201591092501, 'n_estimators': 249, 'reg_alpha': 43.913686687463176, 'reg_lambda': 86.50138770355277}. Best is trial 31 with value: -2.3976664092455575.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:57,731]\u001b[0m Trial 40 finished with value: -2.3785155679896497 and parameters: {'max_depth': 45, 'num_leaves': 5, 'learning_rate': 0.014885636191154912, 'n_estimators': 240, 'reg_alpha': 992.7138838051667, 'reg_lambda': 40.63039493987918}. Best is trial 40 with value: -2.3785155679896497.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:29:57,893]\u001b[0m Trial 21 finished with value: -2.4654817792216894 and parameters: {'max_depth': 33, 'num_leaves': 39, 'learning_rate': 0.9165523010854444, 'n_estimators': 431, 'reg_alpha': 451.1995571406495, 'reg_lambda': 465538.8877412032}. Best is trial 40 with value: -2.3785155679896497.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:01,435]\u001b[0m Trial 41 finished with value: -2.3615555269973263 and parameters: {'max_depth': 45, 'num_leaves': 5, 'learning_rate': 0.01177793795684129, 'n_estimators': 329, 'reg_alpha': 32.31658879702112, 'reg_lambda': 32.61210251903372}. Best is trial 41 with value: -2.3615555269973263.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:06,403]\u001b[0m Trial 44 finished with value: -2.374071979389586 and parameters: {'max_depth': 45, 'num_leaves': 7, 'learning_rate': 0.017531543151560875, 'n_estimators': 294, 'reg_alpha': 6.178557330562432, 'reg_lambda': 4.827464792743631}. Best is trial 41 with value: -2.3615555269973263.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:30:07,739]\u001b[0m Trial 43 finished with value: -2.611226788020972 and parameters: {'max_depth': 30, 'num_leaves': 7, 'learning_rate': 0.0021609895174809005, 'n_estimators': 331, 'reg_alpha': 9.970612192460907, 'reg_lambda': 7.719212363624832}. Best is trial 41 with value: -2.3615555269973263.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:09,052]\u001b[0m Trial 42 finished with value: -2.417566106510215 and parameters: {'max_depth': 45, 'num_leaves': 14, 'learning_rate': 0.013257870433373524, 'n_estimators': 304, 'reg_alpha': 6.185697851569008, 'reg_lambda': 3.159292119896592}. Best is trial 41 with value: -2.3615555269973263.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:09,762]\u001b[0m Trial 45 finished with value: -2.3741927225911263 and parameters: {'max_depth': 41, 'num_leaves': 7, 'learning_rate': 0.011752888821793284, 'n_estimators': 307, 'reg_alpha': 8.798736383030688, 'reg_lambda': 4.338402630543493}. Best is trial 41 with value: -2.3615555269973263.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:15,899]\u001b[0m Trial 46 finished with value: -2.36900158800697 and parameters: {'max_depth': 45, 'num_leaves': 7, 'learning_rate': 0.01814278505548645, 'n_estimators': 339, 'reg_alpha': 11.713816876166662, 'reg_lambda': 3.8583243340009403}. Best is trial 41 with value: -2.3615555269973263.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:17,499]\u001b[0m Trial 47 finished with value: -2.3756875141526743 and parameters: {'max_depth': 46, 'num_leaves': 7, 'learning_rate': 0.017989266767820148, 'n_estimators': 355, 'reg_alpha': 4.439123539053911, 'reg_lambda': 1.461422586576109}. Best is trial 41 with value: -2.3615555269973263.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:17,989]\u001b[0m Trial 48 finished with value: -2.3770029759290052 and parameters: {'max_depth': 41, 'num_leaves': 7, 'learning_rate': 0.017873955824792485, 'n_estimators': 364, 'reg_alpha': 2.4520643287342483, 'reg_lambda': 0.7233107998858136}. Best is trial 41 with value: -2.3615555269973263.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:18,154]\u001b[0m Trial 49 finished with value: -2.382739837400189 and parameters: {'max_depth': 41, 'num_leaves': 7, 'learning_rate': 0.016770350466179886, 'n_estimators': 351, 'reg_alpha': 2.8941554066008823, 'reg_lambda': 0.5878484328643027}. Best is trial 41 with value: -2.3615555269973263.\u001b[0m\n",
      " 44%|                                    | 7/16 [1:20:44<1:31:27, 609.71s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "\u001b[32m[I 2023-04-25 18:30:21,218]\u001b[0m A new study created in memory with name: no-name-bbd96185-06f2-4eee-9b05-e0a782c67def\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:30,210]\u001b[0m Trial 2 finished with value: -1.8114860365159335 and parameters: {'max_depth': 22, 'num_leaves': 20, 'learning_rate': 0.0047908214932575145, 'n_estimators': 242, 'reg_alpha': 385511.3393245965, 'reg_lambda': 15629.659160464365}. Best is trial 2 with value: -1.8114860365159335.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:33,638]\u001b[0m Trial 3 finished with value: -1.3639203954624324 and parameters: {'max_depth': 26, 'num_leaves': 33, 'learning_rate': 0.0560295415595074, 'n_estimators': 123, 'reg_alpha': 5305.475559516407, 'reg_lambda': 0.18481401333025538}. Best is trial 3 with value: -1.3639203954624324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:53,415]\u001b[0m Trial 0 finished with value: -1.6110531979690947 and parameters: {'max_depth': 10, 'num_leaves': 17, 'learning_rate': 8.211576545953226e-05, 'n_estimators': 323, 'reg_alpha': 0.026615231648723627, 'reg_lambda': 5.699578876645995e-06}. Best is trial 3 with value: -1.3639203954624324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:55,328]\u001b[0m Trial 5 finished with value: -1.4986812913781702 and parameters: {'max_depth': 45, 'num_leaves': 32, 'learning_rate': 0.10917923836388742, 'n_estimators': 161, 'reg_alpha': 4.05492797488925, 'reg_lambda': 4.2451018729480126}. Best is trial 3 with value: -1.3639203954624324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:30:58,718]\u001b[0m Trial 7 finished with value: -1.6111156966303786 and parameters: {'max_depth': 30, 'num_leaves': 34, 'learning_rate': 0.0022563716721971847, 'n_estimators': 55, 'reg_alpha': 186700.90099211445, 'reg_lambda': 1.720844516789962e-05}. Best is trial 3 with value: -1.3639203954624324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:02,627]\u001b[0m Trial 4 finished with value: -1.5223175612900142 and parameters: {'max_depth': 12, 'num_leaves': 39, 'learning_rate': 0.2805674752539484, 'n_estimators': 225, 'reg_alpha': 0.0013376185983578124, 'reg_lambda': 1.3046762564869745}. Best is trial 3 with value: -1.3639203954624324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:02,974]\u001b[0m Trial 6 finished with value: -1.6288929533946446 and parameters: {'max_depth': 44, 'num_leaves': 27, 'learning_rate': 0.00034522411738916657, 'n_estimators': 190, 'reg_alpha': 0.021389148461297785, 'reg_lambda': 2339931.934383693}. Best is trial 3 with value: -1.3639203954624324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:05,686]\u001b[0m Trial 10 finished with value: -1.6301751236745359 and parameters: {'max_depth': 19, 'num_leaves': 5, 'learning_rate': 0.0001552790186238766, 'n_estimators': 4, 'reg_alpha': 0.0013839561588999119, 'reg_lambda': 42718.34823729814}. Best is trial 3 with value: -1.3639203954624324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:08,642]\u001b[0m Trial 8 finished with value: -1.630215437179037 and parameters: {'max_depth': 31, 'num_leaves': 30, 'learning_rate': 1.5964945591182725e-05, 'n_estimators': 151, 'reg_alpha': 120893.15201716113, 'reg_lambda': 619.3623879411117}. Best is trial 3 with value: -1.3639203954624324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:21,246]\u001b[0m Trial 1 finished with value: -1.6302944888245636 and parameters: {'max_depth': 47, 'num_leaves': 42, 'learning_rate': 5.531159281839315e-07, 'n_estimators': 291, 'reg_alpha': 0.00035453389182809057, 'reg_lambda': 0.09766644742172262}. Best is trial 3 with value: -1.3639203954624324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:21,581]\u001b[0m Trial 9 finished with value: -1.3228486189506108 and parameters: {'max_depth': 5, 'num_leaves': 38, 'learning_rate': 0.19654286217916422, 'n_estimators': 241, 'reg_alpha': 1.3336687495641452e-06, 'reg_lambda': 2296739.673795511}. Best is trial 9 with value: -1.3228486189506108.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:31,553]\u001b[0m Trial 12 finished with value: -1.630262027464872 and parameters: {'max_depth': 27, 'num_leaves': 6, 'learning_rate': 6.158678522978974e-07, 'n_estimators': 401, 'reg_alpha': 10.55177567992204, 'reg_lambda': 0.00011382090211181066}. Best is trial 9 with value: -1.3228486189506108.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:34,235]\u001b[0m Trial 11 finished with value: -1.6302234261164692 and parameters: {'max_depth': 14, 'num_leaves': 45, 'learning_rate': 1.9245286259784183e-06, 'n_estimators': 134, 'reg_alpha': 1.407974198471463, 'reg_lambda': 8.424016345447671e-06}. Best is trial 9 with value: -1.3228486189506108.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:39,738]\u001b[0m Trial 15 finished with value: -1.3146845454021188 and parameters: {'max_depth': -1, 'num_leaves': 49, 'learning_rate': 0.7909437941892936, 'n_estimators': 105, 'reg_alpha': 2.813405887360663e-06, 'reg_lambda': 5112084.908046677}. Best is trial 15 with value: -1.3146845454021188.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:43,197]\u001b[0m Trial 14 finished with value: -1.3333492824511144 and parameters: {'max_depth': 3, 'num_leaves': 50, 'learning_rate': 0.7443606236864982, 'n_estimators': 467, 'reg_alpha': 1.6790482514702162e-07, 'reg_lambda': 7888890.520518126}. Best is trial 15 with value: -1.3146845454021188.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:52,855]\u001b[0m Trial 17 finished with value: -1.268156898041379 and parameters: {'max_depth': 1, 'num_leaves': 50, 'learning_rate': 0.7554398229388725, 'n_estimators': 486, 'reg_alpha': 7.407004541849516e-07, 'reg_lambda': 7277448.675339906}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:31:57,011]\u001b[0m Trial 18 finished with value: -1.4442759915533756 and parameters: {'max_depth': -1, 'num_leaves': 50, 'learning_rate': 0.91665889217948, 'n_estimators': 67, 'reg_alpha': 2.537233726714075e-06, 'reg_lambda': 240991.65396560452}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:32:12,596]\u001b[0m Trial 16 finished with value: -1.3591722099822867 and parameters: {'max_depth': -1, 'num_leaves': 49, 'learning_rate': 0.8414690657910107, 'n_estimators': 437, 'reg_alpha': 1.6746861221386777e-07, 'reg_lambda': 5914195.9783693245}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:32:33,984]\u001b[0m Trial 13 finished with value: -1.57141403602234 and parameters: {'max_depth': 31, 'num_leaves': 50, 'learning_rate': 0.9707967022220498, 'n_estimators': 487, 'reg_alpha': 4.260812561662495e-07, 'reg_lambda': 0.002439854080403951}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:32:58,198]\u001b[0m Trial 21 finished with value: -1.4681512092441105 and parameters: {'max_depth': 6, 'num_leaves': 44, 'learning_rate': 0.026061156294925534, 'n_estimators': 369, 'reg_alpha': 4.46386115147761e-06, 'reg_lambda': 1262.3023627100913}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:33:10,541]\u001b[0m Trial 22 finished with value: -1.5050400086661444 and parameters: {'max_depth': 5, 'num_leaves': 43, 'learning_rate': 0.02261244400133208, 'n_estimators': 363, 'reg_alpha': 1.9154869419516676e-05, 'reg_lambda': 928.4694746235228}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:33:24,655]\u001b[0m Trial 20 finished with value: -1.4941268024503265 and parameters: {'max_depth': 0, 'num_leaves': 44, 'learning_rate': 0.03121606325603256, 'n_estimators': 499, 'reg_alpha': 8.063174898627345e-06, 'reg_lambda': 1116.8190601410424}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:33:26,063]\u001b[0m Trial 19 finished with value: -1.4532988330426027 and parameters: {'max_depth': -1, 'num_leaves': 49, 'learning_rate': 0.023069062861150083, 'n_estimators': 482, 'reg_alpha': 5.65651064837186e-06, 'reg_lambda': 19956.440523370125}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:33:34,809]\u001b[0m Trial 23 finished with value: -1.4555941445091696 and parameters: {'max_depth': 38, 'num_leaves': 23, 'learning_rate': 0.01883073987713266, 'n_estimators': 319, 'reg_alpha': 2.784842767305627e-05, 'reg_lambda': 113.37890786745976}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:33:39,834]\u001b[0m Trial 24 finished with value: -1.3906787999033443 and parameters: {'max_depth': 8, 'num_leaves': 38, 'learning_rate': 0.16673072874968944, 'n_estimators': 311, 'reg_alpha': 2.913344363628415e-05, 'reg_lambda': 992955.7238658426}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:33:52,601]\u001b[0m Trial 28 finished with value: -1.3547336249110435 and parameters: {'max_depth': 16, 'num_leaves': 36, 'learning_rate': 0.2088126391511069, 'n_estimators': 89, 'reg_alpha': 1.284639396968769e-07, 'reg_lambda': 251932.95884842926}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:03,244]\u001b[0m Trial 25 finished with value: -1.411609865293483 and parameters: {'max_depth': 7, 'num_leaves': 37, 'learning_rate': 0.15320667038380972, 'n_estimators': 286, 'reg_alpha': 4.5448959918342956e-05, 'reg_lambda': 246716.45464240902}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:04,002]\u001b[0m Trial 26 finished with value: -1.423847876707344 and parameters: {'max_depth': 8, 'num_leaves': 39, 'learning_rate': 0.14052528353540578, 'n_estimators': 304, 'reg_alpha': 4.3449366043421726e-05, 'reg_lambda': 488904.5866918366}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:04,882]\u001b[0m Trial 29 finished with value: -1.4051077651348125 and parameters: {'max_depth': 3, 'num_leaves': 40, 'learning_rate': 0.22712823582819125, 'n_estimators': 203, 'reg_alpha': 2.0590251538930914e-06, 'reg_lambda': 7218097.775704957}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:08,027]\u001b[0m Trial 27 finished with value: -1.43068932811709 and parameters: {'max_depth': 8, 'num_leaves': 37, 'learning_rate': 0.1800310138731898, 'n_estimators': 270, 'reg_alpha': 1.8868628857788027e-07, 'reg_lambda': 600456.3210437618}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:09,089]\u001b[0m Trial 32 finished with value: -1.5794516275717478 and parameters: {'max_depth': 11, 'num_leaves': 46, 'learning_rate': 0.00799055609669906, 'n_estimators': 15, 'reg_alpha': 7.563531193423242e-07, 'reg_lambda': 27874.95594481507}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:10,612]\u001b[0m Trial 33 finished with value: -1.614783530621343 and parameters: {'max_depth': 12, 'num_leaves': 46, 'learning_rate': 0.009904127598758168, 'n_estimators': 4, 'reg_alpha': 0.0003735943487791833, 'reg_lambda': 39440.47864984844}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:15,920]\u001b[0m Trial 30 finished with value: -1.3571000907684538 and parameters: {'max_depth': 3, 'num_leaves': 46, 'learning_rate': 0.3189528267785067, 'n_estimators': 205, 'reg_alpha': 7.047460192074327e-07, 'reg_lambda': 6922933.649695827}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:16,935]\u001b[0m Trial 31 finished with value: -1.3630695033925861 and parameters: {'max_depth': 3, 'num_leaves': 47, 'learning_rate': 0.3778303910409995, 'n_estimators': 210, 'reg_alpha': 1.3759366165188884e-06, 'reg_lambda': 8986896.140875932}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:31,429]\u001b[0m Trial 34 finished with value: -1.3373843741660218 and parameters: {'max_depth': 3, 'num_leaves': 47, 'learning_rate': 0.47503507250111865, 'n_estimators': 402, 'reg_alpha': 1.0639781452794171e-07, 'reg_lambda': 4802183.849494147}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:34,266]\u001b[0m Trial 35 finished with value: -1.3227958451440014 and parameters: {'max_depth': 3, 'num_leaves': 47, 'learning_rate': 0.5464556446623846, 'n_estimators': 455, 'reg_alpha': 1.1826698514624427e-07, 'reg_lambda': 8980584.503520947}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:39,805]\u001b[0m Trial 36 finished with value: -1.3186431622768888 and parameters: {'max_depth': 3, 'num_leaves': 41, 'learning_rate': 0.5399897761149282, 'n_estimators': 430, 'reg_alpha': 1.414935818973529e-06, 'reg_lambda': 9357952.289195156}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:43,066]\u001b[0m Trial 37 finished with value: -1.3229562284031458 and parameters: {'max_depth': 3, 'num_leaves': 41, 'learning_rate': 0.06574967513404634, 'n_estimators': 447, 'reg_alpha': 1.7322907069121868e-07, 'reg_lambda': 1188329.451174703}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:49,277]\u001b[0m Trial 39 finished with value: -1.3078295008040082 and parameters: {'max_depth': 1, 'num_leaves': 12, 'learning_rate': 0.06239827292030808, 'n_estimators': 445, 'reg_alpha': 0.00019016641688638833, 'reg_lambda': 990625.4694109671}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:34:51,668]\u001b[0m Trial 38 finished with value: -1.3069059995270285 and parameters: {'max_depth': 2, 'num_leaves': 42, 'learning_rate': 0.07290224484861771, 'n_estimators': 454, 'reg_alpha': 0.00019184811022947209, 'reg_lambda': 935356.698239949}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:35:20,332]\u001b[0m Trial 41 finished with value: -1.4250721161458118 and parameters: {'max_depth': 16, 'num_leaves': 12, 'learning_rate': 0.0660399049299677, 'n_estimators': 416, 'reg_alpha': 0.00020362421578516186, 'reg_lambda': 137111.82249404004}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:35:25,045]\u001b[0m Trial 43 finished with value: -1.4250519559366581 and parameters: {'max_depth': 15, 'num_leaves': 13, 'learning_rate': 0.08856701512366047, 'n_estimators': 412, 'reg_alpha': 0.00022871282400060793, 'reg_lambda': 6762.666587265559}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:35:27,696]\u001b[0m Trial 42 finished with value: -1.4153461279932797 and parameters: {'max_depth': 17, 'num_leaves': 14, 'learning_rate': 0.05877310763805536, 'n_estimators': 412, 'reg_alpha': 0.00023772743843206832, 'reg_lambda': 105005.74737118505}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:35:32,719]\u001b[0m Trial 44 finished with value: -1.5834146087915537 and parameters: {'max_depth': 1, 'num_leaves': 15, 'learning_rate': 0.0032536100250022083, 'n_estimators': 417, 'reg_alpha': 0.0007754725067413749, 'reg_lambda': 1319228.7962747857}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:35:36,163]\u001b[0m Trial 45 finished with value: -1.3472004835312468 and parameters: {'max_depth': 1, 'num_leaves': 28, 'learning_rate': 0.054974344555156734, 'n_estimators': 343, 'reg_alpha': 0.0026788240412916786, 'reg_lambda': 1125607.0218889688}. Best is trial 17 with value: -1.268156898041379.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:35:39,062]\u001b[0m Trial 46 finished with value: -1.2459655952589392 and parameters: {'max_depth': 1, 'num_leaves': 29, 'learning_rate': 0.43572816812895027, 'n_estimators': 370, 'reg_alpha': 0.007110334521026679, 'reg_lambda': 993917.4699507509}. Best is trial 46 with value: -1.2459655952589392.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:36:01,821]\u001b[0m Trial 48 finished with value: -1.4520399334602092 and parameters: {'max_depth': 10, 'num_leaves': 10, 'learning_rate': 0.3959361214035366, 'n_estimators': 385, 'reg_alpha': 0.02541153542242916, 'reg_lambda': 7376.190007001169}. Best is trial 46 with value: -1.2459655952589392.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:36:05,555]\u001b[0m Trial 40 finished with value: -1.42644976397128 and parameters: {'max_depth': 17, 'num_leaves': 41, 'learning_rate': 0.0710662717503927, 'n_estimators': 447, 'reg_alpha': 0.0001509539715041357, 'reg_lambda': 103047.9499828439}. Best is trial 46 with value: -1.2459655952589392.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:36:10,477]\u001b[0m Trial 47 finished with value: -1.4420447053066983 and parameters: {'max_depth': 10, 'num_leaves': 26, 'learning_rate': 0.39342474218693785, 'n_estimators': 345, 'reg_alpha': 0.00894241689753007, 'reg_lambda': 1186468.4557336203}. Best is trial 46 with value: -1.2459655952589392.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:36:11,005]\u001b[0m Trial 49 finished with value: -1.4306897897475443 and parameters: {'max_depth': 10, 'num_leaves': 20, 'learning_rate': 0.36309394972837983, 'n_estimators': 376, 'reg_alpha': 0.006762035317816182, 'reg_lambda': 4513.080005055259}. Best is trial 46 with value: -1.2459655952589392.\u001b[0m\n",
      " 50%|                                | 8/16 [1:26:38<1:10:26, 528.31s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:36:16,281]\u001b[0m A new study created in memory with name: no-name-3152e0bf-b768-4d8e-a516-55980f48a102\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:36:36,963]\u001b[0m Trial 0 finished with value: -1.558726268756938 and parameters: {'max_depth': 1, 'num_leaves': 28, 'learning_rate': 1.8024534377787377e-05, 'n_estimators': 371, 'reg_alpha': 1.976808188636853e-07, 'reg_lambda': 78.77569489876441}. Best is trial 0 with value: -1.558726268756938.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:36:49,156]\u001b[0m Trial 3 finished with value: -1.2702489905394359 and parameters: {'max_depth': -1, 'num_leaves': 21, 'learning_rate': 0.012790737406647821, 'n_estimators': 149, 'reg_alpha': 0.2335101899628077, 'reg_lambda': 0.006635344635963774}. Best is trial 3 with value: -1.2702489905394359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:37:33,005]\u001b[0m Trial 2 finished with value: -1.219904850597622 and parameters: {'max_depth': 23, 'num_leaves': 32, 'learning_rate': 0.021903684590521128, 'n_estimators': 312, 'reg_alpha': 2.0667764652319852e-07, 'reg_lambda': 0.217084722436099}. Best is trial 2 with value: -1.219904850597622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:37:42,556]\u001b[0m Trial 6 finished with value: -1.5622875229688216 and parameters: {'max_depth': 45, 'num_leaves': 50, 'learning_rate': 0.0016948365719916122, 'n_estimators': 137, 'reg_alpha': 621046.6588855351, 'reg_lambda': 20042.706380808755}. Best is trial 2 with value: -1.219904850597622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:38:01,564]\u001b[0m Trial 1 finished with value: -1.2736715173777207 and parameters: {'max_depth': 41, 'num_leaves': 22, 'learning_rate': 0.0035086772216055685, 'n_estimators': 473, 'reg_alpha': 4.232536615096236e-05, 'reg_lambda': 769.2168944055472}. Best is trial 2 with value: -1.219904850597622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:38:09,050]\u001b[0m Trial 5 finished with value: -1.5622073927759494 and parameters: {'max_depth': 41, 'num_leaves': 12, 'learning_rate': 2.448099201434834e-07, 'n_estimators': 477, 'reg_alpha': 7.880544407155455e-07, 'reg_lambda': 2.2883489380641957}. Best is trial 2 with value: -1.219904850597622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:38:22,347]\u001b[0m Trial 4 finished with value: -1.2554630389537125 and parameters: {'max_depth': 36, 'num_leaves': 46, 'learning_rate': 0.008576752044908929, 'n_estimators': 306, 'reg_alpha': 1768.3395007016943, 'reg_lambda': 0.00023654788417947674}. Best is trial 2 with value: -1.219904850597622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:38:25,768]\u001b[0m Trial 10 finished with value: -1.5600536990504212 and parameters: {'max_depth': 23, 'num_leaves': 28, 'learning_rate': 0.001969747523891391, 'n_estimators': 2, 'reg_alpha': 9.106301923782375, 'reg_lambda': 10180.958956782557}. Best is trial 2 with value: -1.219904850597622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:38:50,510]\u001b[0m Trial 9 finished with value: -1.2163085189346547 and parameters: {'max_depth': 4, 'num_leaves': 9, 'learning_rate': 0.04749124094264785, 'n_estimators': 329, 'reg_alpha': 1.1810280286332937e-06, 'reg_lambda': 0.037608298852823366}. Best is trial 9 with value: -1.2163085189346547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:38:53,967]\u001b[0m Trial 11 finished with value: -1.3627617581620903 and parameters: {'max_depth': 47, 'num_leaves': 7, 'learning_rate': 0.002501757787481012, 'n_estimators': 201, 'reg_alpha': 0.004021320747019298, 'reg_lambda': 4.4663295194419445e-06}. Best is trial 9 with value: -1.2163085189346547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:39:01,046]\u001b[0m Trial 8 finished with value: -1.3839223929503826 and parameters: {'max_depth': 35, 'num_leaves': 34, 'learning_rate': 0.0025537651233497835, 'n_estimators': 166, 'reg_alpha': 3.360566166795283e-05, 'reg_lambda': 8.174578157252233}. Best is trial 9 with value: -1.2163085189346547.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:39:25,568]\u001b[0m Trial 13 finished with value: -1.1939214461766217 and parameters: {'max_depth': 9, 'num_leaves': 5, 'learning_rate': 0.7835388429414804, 'n_estimators': 365, 'reg_alpha': 0.000670081734131171, 'reg_lambda': 5549650.9247774}. Best is trial 13 with value: -1.1939214461766217.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:40:07,413]\u001b[0m Trial 7 finished with value: -1.5619291112400806 and parameters: {'max_depth': 15, 'num_leaves': 39, 'learning_rate': 1.1479918144795805e-06, 'n_estimators': 460, 'reg_alpha': 0.012998755587282204, 'reg_lambda': 616.6305574521272}. Best is trial 13 with value: -1.1939214461766217.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:40:09,806]\u001b[0m Trial 14 finished with value: -1.28976933413643 and parameters: {'max_depth': 11, 'num_leaves': 37, 'learning_rate': 0.4536060321700534, 'n_estimators': 335, 'reg_alpha': 1.8133581793497127e-07, 'reg_lambda': 0.024777742183496643}. Best is trial 13 with value: -1.1939214461766217.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:40:14,600]\u001b[0m Trial 15 finished with value: -1.2008397316120316 and parameters: {'max_depth': 11, 'num_leaves': 5, 'learning_rate': 0.20642852636570505, 'n_estimators': 387, 'reg_alpha': 0.0007531206336838139, 'reg_lambda': 1127581.1858784289}. Best is trial 13 with value: -1.1939214461766217.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:40:42,713]\u001b[0m Trial 16 finished with value: -1.1997769929933582 and parameters: {'max_depth': 9, 'num_leaves': 5, 'learning_rate': 0.7387931183275193, 'n_estimators': 373, 'reg_alpha': 0.0002023985020571524, 'reg_lambda': 2708354.1546488157}. Best is trial 13 with value: -1.1939214461766217.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:40:47,194]\u001b[0m Trial 17 finished with value: -1.1949839826612103 and parameters: {'max_depth': 9, 'num_leaves': 5, 'learning_rate': 0.5341813025166082, 'n_estimators': 395, 'reg_alpha': 0.00015062971283416628, 'reg_lambda': 5528743.67943276}. Best is trial 13 with value: -1.1939214461766217.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:41:15,447]\u001b[0m Trial 12 finished with value: -1.561749650882958 and parameters: {'max_depth': 38, 'num_leaves': 48, 'learning_rate': 1.9127738264157444e-06, 'n_estimators': 412, 'reg_alpha': 0.0007611381912156783, 'reg_lambda': 462.51572477383695}. Best is trial 13 with value: -1.1939214461766217.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:41:17,049]\u001b[0m Trial 18 finished with value: -1.185734254443516 and parameters: {'max_depth': 11, 'num_leaves': 15, 'learning_rate': 0.5943309105735923, 'n_estimators': 390, 'reg_alpha': 0.0005708508077628812, 'reg_lambda': 6740123.727633285}. Best is trial 18 with value: -1.185734254443516.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:41:48,087]\u001b[0m Trial 19 finished with value: -1.18851735795803 and parameters: {'max_depth': 17, 'num_leaves': 15, 'learning_rate': 0.5281933043556769, 'n_estimators': 420, 'reg_alpha': 0.29280888397018645, 'reg_lambda': 6985874.35497011}. Best is trial 18 with value: -1.185734254443516.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:41:50,022]\u001b[0m Trial 21 finished with value: -1.365148106515584 and parameters: {'max_depth': 22, 'num_leaves': 15, 'learning_rate': 0.07896620079945979, 'n_estimators': 245, 'reg_alpha': 0.4361796941153761, 'reg_lambda': 9951593.113324419}. Best is trial 18 with value: -1.185734254443516.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:42:00,270]\u001b[0m Trial 20 finished with value: -1.1760464342918011 and parameters: {'max_depth': 17, 'num_leaves': 16, 'learning_rate': 0.9847440224954299, 'n_estimators': 429, 'reg_alpha': 0.0804018637238501, 'reg_lambda': 5193914.858447885}. Best is trial 20 with value: -1.1760464342918011.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:42:03,010]\u001b[0m Trial 22 finished with value: -1.1734601916702678 and parameters: {'max_depth': 20, 'num_leaves': 14, 'learning_rate': 0.08652570394968508, 'n_estimators': 243, 'reg_alpha': 0.038720409748166845, 'reg_lambda': 97714.53592312773}. Best is trial 22 with value: -1.1734601916702678.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:42:34,166]\u001b[0m Trial 23 finished with value: -1.18141803827113 and parameters: {'max_depth': 29, 'num_leaves': 16, 'learning_rate': 0.10101445806456875, 'n_estimators': 247, 'reg_alpha': 0.29679520062487785, 'reg_lambda': 35246.5993050717}. Best is trial 22 with value: -1.1734601916702678.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:42:56,314]\u001b[0m Trial 26 finished with value: -1.1793767775002124 and parameters: {'max_depth': 29, 'num_leaves': 21, 'learning_rate': 0.09829377303614344, 'n_estimators': 252, 'reg_alpha': 10.360016895166078, 'reg_lambda': 214211.8413663693}. Best is trial 22 with value: -1.1734601916702678.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:43:13,231]\u001b[0m Trial 24 finished with value: -1.1826342772951235 and parameters: {'max_depth': 17, 'num_leaves': 17, 'learning_rate': 0.11476639098290049, 'n_estimators': 436, 'reg_alpha': 0.022045732888526782, 'reg_lambda': 113476.01969134001}. Best is trial 22 with value: -1.1734601916702678.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:43:19,586]\u001b[0m Trial 25 finished with value: -1.1837854253907096 and parameters: {'max_depth': 17, 'num_leaves': 17, 'learning_rate': 0.12089511733841617, 'n_estimators': 422, 'reg_alpha': 0.05202699299828871, 'reg_lambda': 121201.84062205485}. Best is trial 22 with value: -1.1734601916702678.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:43:23,187]\u001b[0m Trial 28 finished with value: -1.1911666686651716 and parameters: {'max_depth': 29, 'num_leaves': 23, 'learning_rate': 0.10080070933614588, 'n_estimators': 103, 'reg_alpha': 64.82144875226193, 'reg_lambda': 184953.0469269991}. Best is trial 22 with value: -1.1734601916702678.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:43:29,841]\u001b[0m Trial 27 finished with value: -1.1666511452793769 and parameters: {'max_depth': 30, 'num_leaves': 21, 'learning_rate': 0.13831846894596644, 'n_estimators': 256, 'reg_alpha': 11.034656115406406, 'reg_lambda': 196663.35406297585}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:43:31,523]\u001b[0m Trial 29 finished with value: -1.2593547428854783 and parameters: {'max_depth': 29, 'num_leaves': 21, 'learning_rate': 0.03421948338653156, 'n_estimators': 78, 'reg_alpha': 12.349439336146512, 'reg_lambda': 253389.52254275527}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:43:40,019]\u001b[0m Trial 30 finished with value: -1.2620161070489284 and parameters: {'max_depth': 29, 'num_leaves': 22, 'learning_rate': 0.03159147241123428, 'n_estimators': 95, 'reg_alpha': 6.5129408961338795, 'reg_lambda': 333991.4578171253}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:43:52,591]\u001b[0m Trial 32 finished with value: -1.5485603561996237 and parameters: {'max_depth': 25, 'num_leaves': 24, 'learning_rate': 0.0002626327755919858, 'n_estimators': 90, 'reg_alpha': 4.17171124278862, 'reg_lambda': 6810.3210211746655}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:44:04,418]\u001b[0m Trial 31 finished with value: -1.2121052117958722 and parameters: {'max_depth': 28, 'num_leaves': 10, 'learning_rate': 0.02736132783312268, 'n_estimators': 278, 'reg_alpha': 2.40110228728006, 'reg_lambda': 298153.8268705347}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:44:42,956]\u001b[0m Trial 33 finished with value: -1.5158918489393818 and parameters: {'max_depth': 26, 'num_leaves': 25, 'learning_rate': 0.00029255783809598366, 'n_estimators': 280, 'reg_alpha': 321.10319677969966, 'reg_lambda': 3331.7695787565244}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:44:46,405]\u001b[0m Trial 34 finished with value: -1.4944660375114491 and parameters: {'max_depth': 33, 'num_leaves': 25, 'learning_rate': 0.00045920646841379585, 'n_estimators': 277, 'reg_alpha': 176.90771411340967, 'reg_lambda': 7193.738236439795}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:44:49,899]\u001b[0m Trial 35 finished with value: -1.2460684218762195 and parameters: {'max_depth': 33, 'num_leaves': 28, 'learning_rate': 0.19036583152156433, 'n_estimators': 271, 'reg_alpha': 176.2964824808021, 'reg_lambda': 1232.9058001134838}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:44:55,983]\u001b[0m Trial 36 finished with value: -1.2337742863816077 and parameters: {'max_depth': 33, 'num_leaves': 27, 'learning_rate': 0.23025177773854577, 'n_estimators': 216, 'reg_alpha': 110.23194628462036, 'reg_lambda': 10126.485330877736}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:45:16,496]\u001b[0m Trial 37 finished with value: -1.26422527422646 and parameters: {'max_depth': 33, 'num_leaves': 19, 'learning_rate': 0.27835353870802887, 'n_estimators': 215, 'reg_alpha': 0.09968225369607714, 'reg_lambda': 67.12659798558452}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:45:17,603]\u001b[0m Trial 39 finished with value: -1.3573461888634855 and parameters: {'max_depth': 20, 'num_leaves': 19, 'learning_rate': 0.01087698634423653, 'n_estimators': 203, 'reg_alpha': 0.07071292474797392, 'reg_lambda': 835330.2196591744}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:45:20,720]\u001b[0m Trial 38 finished with value: -1.2573419269928414 and parameters: {'max_depth': 19, 'num_leaves': 19, 'learning_rate': 0.2316102037956323, 'n_estimators': 212, 'reg_alpha': 0.9308964625221128, 'reg_lambda': 86.50682760892326}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:45:41,418]\u001b[0m Trial 40 finished with value: -1.236282161903605 and parameters: {'max_depth': 20, 'num_leaves': 19, 'learning_rate': 0.012819015909081351, 'n_estimators': 221, 'reg_alpha': 0.0868378383365442, 'reg_lambda': 141.84036581085826}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:45:46,733]\u001b[0m Trial 42 finished with value: -1.2514361443511697 and parameters: {'max_depth': 21, 'num_leaves': 12, 'learning_rate': 0.009165742679382425, 'n_estimators': 175, 'reg_alpha': 0.5971860742235685, 'reg_lambda': 43623.23399363123}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:45:50,891]\u001b[0m Trial 43 finished with value: -1.225727014579084 and parameters: {'max_depth': 14, 'num_leaves': 12, 'learning_rate': 0.0164453065621378, 'n_estimators': 174, 'reg_alpha': 2038.6088575048536, 'reg_lambda': 43644.50232258424}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:46:12,535]\u001b[0m Trial 44 finished with value: -1.166892944267958 and parameters: {'max_depth': 26, 'num_leaves': 13, 'learning_rate': 0.06332852790073719, 'n_estimators': 176, 'reg_alpha': 0.7437224728233407, 'reg_lambda': 44624.13757995357}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:46:28,957]\u001b[0m Trial 41 finished with value: -1.2587905335949718 and parameters: {'max_depth': 20, 'num_leaves': 13, 'learning_rate': 0.010792145650406105, 'n_estimators': 498, 'reg_alpha': 1.3196632218168742, 'reg_lambda': 730011.1648957559}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:46:33,452]\u001b[0m Trial 47 finished with value: -1.2543352918970672 and parameters: {'max_depth': 25, 'num_leaves': 13, 'learning_rate': 0.050746064613520034, 'n_estimators': 137, 'reg_alpha': 0.005496676842763184, 'reg_lambda': 940635.6796596114}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:46:58,123]\u001b[0m Trial 45 finished with value: -1.184626078792602 and parameters: {'max_depth': 25, 'num_leaves': 12, 'learning_rate': 0.10670241271064662, 'n_estimators': 500, 'reg_alpha': 0.011339659234341075, 'reg_lambda': 808390.3476291588}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:46:59,182]\u001b[0m Trial 48 finished with value: -1.1700155237918395 and parameters: {'max_depth': 25, 'num_leaves': 31, 'learning_rate': 0.8589712584096769, 'n_estimators': 128, 'reg_alpha': 0.011546453498625998, 'reg_lambda': 858625.1431760271}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:47:23,136]\u001b[0m Trial 46 finished with value: -1.1975060192710203 and parameters: {'max_depth': 26, 'num_leaves': 31, 'learning_rate': 0.05287833129231083, 'n_estimators': 498, 'reg_alpha': 0.009653093632455074, 'reg_lambda': 930874.4199350958}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:47:26,634]\u001b[0m Trial 49 finished with value: -1.1852000651960035 and parameters: {'max_depth': 38, 'num_leaves': 33, 'learning_rate': 0.061624338353217185, 'n_estimators': 314, 'reg_alpha': 0.015884427053216, 'reg_lambda': 40619.79042993585}. Best is trial 27 with value: -1.1666511452793769.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:47:37,536]\u001b[0m A new study created in memory with name: no-name-606a19d1-efd2-4743-87d3-490b715d5baf\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:47:45,691]\u001b[0m Trial 1 finished with value: -1.7439574252370424 and parameters: {'max_depth': 29, 'num_leaves': 5, 'learning_rate': 1.0663580936886663e-07, 'n_estimators': 58, 'reg_alpha': 7778.414022965084, 'reg_lambda': 2539022.4092724104}. Best is trial 1 with value: -1.7439574252370424.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:47:46,036]\u001b[0m Trial 2 finished with value: -1.7439575879749671 and parameters: {'max_depth': 9, 'num_leaves': 24, 'learning_rate': 4.0378461441729135e-07, 'n_estimators': 131, 'reg_alpha': 5663690.809404832, 'reg_lambda': 0.0004312716936183912}. Best is trial 1 with value: -1.7439574252370424.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:47:53,228]\u001b[0m Trial 5 finished with value: -1.74395687349583 and parameters: {'max_depth': 12, 'num_leaves': 37, 'learning_rate': 1.0422539673161416e-07, 'n_estimators': 27, 'reg_alpha': 0.0001424755327749867, 'reg_lambda': 98166.07310556827}. Best is trial 5 with value: -1.74395687349583.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:47:54,096]\u001b[0m Trial 0 finished with value: -1.7041731246359244 and parameters: {'max_depth': 23, 'num_leaves': 24, 'learning_rate': 0.0011466994659766817, 'n_estimators': 71, 'reg_alpha': 1.0510741035967431e-07, 'reg_lambda': 0.000665298815930104}. Best is trial 0 with value: -1.7041731246359244.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:48:09,898]\u001b[0m Trial 3 finished with value: -1.7337378943038568 and parameters: {'max_depth': 7, 'num_leaves': 50, 'learning_rate': 0.007147046629213849, 'n_estimators': 175, 'reg_alpha': 0.0172320074258435, 'reg_lambda': 8874071.750241218}. Best is trial 0 with value: -1.7041731246359244.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:48:27,073]\u001b[0m Trial 4 finished with value: -1.7424396332118581 and parameters: {'max_depth': 4, 'num_leaves': 15, 'learning_rate': 9.065682824981713e-06, 'n_estimators': 392, 'reg_alpha': 0.6029141519768985, 'reg_lambda': 0.0002422918028971086}. Best is trial 0 with value: -1.7041731246359244.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:48:30,824]\u001b[0m Trial 7 finished with value: -1.7435333441417509 and parameters: {'max_depth': 4, 'num_leaves': 46, 'learning_rate': 7.771023981252308e-06, 'n_estimators': 382, 'reg_alpha': 8800.990011523289, 'reg_lambda': 299045.3199166233}. Best is trial 0 with value: -1.7041731246359244.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:48:56,940]\u001b[0m Trial 8 finished with value: -1.7414385033085755 and parameters: {'max_depth': 24, 'num_leaves': 45, 'learning_rate': 2.506188420487039e-05, 'n_estimators': 173, 'reg_alpha': 1.2097934228828002e-07, 'reg_lambda': 122.84080032776855}. Best is trial 0 with value: -1.7041731246359244.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:49:00,641]\u001b[0m Trial 10 finished with value: -1.7433684738302024 and parameters: {'max_depth': 13, 'num_leaves': 31, 'learning_rate': 6.762444191741404e-06, 'n_estimators': 257, 'reg_alpha': 26361.48211850881, 'reg_lambda': 4.025566439088348e-06}. Best is trial 0 with value: -1.7041731246359244.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:49:04,260]\u001b[0m Trial 6 finished with value: -1.7409788347416049 and parameters: {'max_depth': 23, 'num_leaves': 29, 'learning_rate': 1.5033047666520626e-05, 'n_estimators': 360, 'reg_alpha': 6.861997056139521, 'reg_lambda': 2.0460672230695727e-06}. Best is trial 0 with value: -1.7041731246359244.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:49:14,623]\u001b[0m Trial 12 finished with value: -1.7439575879749671 and parameters: {'max_depth': 43, 'num_leaves': 9, 'learning_rate': 1.9341811049488478e-05, 'n_estimators': 383, 'reg_alpha': 6510402.421496273, 'reg_lambda': 32905.4370992503}. Best is trial 0 with value: -1.7041731246359244.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:49:19,238]\u001b[0m Trial 11 finished with value: -1.6971118753774104 and parameters: {'max_depth': 41, 'num_leaves': 13, 'learning_rate': 0.0006909206773680704, 'n_estimators': 164, 'reg_alpha': 2.9359488201913157e-06, 'reg_lambda': 1.8726614673473423e-05}. Best is trial 11 with value: -1.6971118753774104.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:49:32,334]\u001b[0m Trial 9 finished with value: -1.7439512802621375 and parameters: {'max_depth': 28, 'num_leaves': 45, 'learning_rate': 4.831239282637566e-07, 'n_estimators': 373, 'reg_alpha': 0.0002533938688603238, 'reg_lambda': 1960553.9576180198}. Best is trial 11 with value: -1.6971118753774104.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:49:47,914]\u001b[0m Trial 16 finished with value: -1.6302171998236685 and parameters: {'max_depth': 47, 'num_leaves': 19, 'learning_rate': 0.0029677534874651074, 'n_estimators': 98, 'reg_alpha': 6.277137635783902e-07, 'reg_lambda': 0.03185949589801473}. Best is trial 16 with value: -1.6302171998236685.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:49:49,289]\u001b[0m Trial 14 finished with value: -1.3991594014296238 and parameters: {'max_depth': 36, 'num_leaves': 20, 'learning_rate': 0.017991380749233062, 'n_estimators': 219, 'reg_alpha': 3.769769337492737e-07, 'reg_lambda': 0.14999283851264433}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:49:59,513]\u001b[0m Trial 15 finished with value: -1.5471403764973446 and parameters: {'max_depth': 41, 'num_leaves': 18, 'learning_rate': 0.0029325895101213677, 'n_estimators': 261, 'reg_alpha': 1.1709155742658777e-07, 'reg_lambda': 0.030080885623016963}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:50:00,454]\u001b[0m Trial 13 finished with value: -1.5615749884392118 and parameters: {'max_depth': 47, 'num_leaves': 18, 'learning_rate': 0.8145540282330807, 'n_estimators': 499, 'reg_alpha': 2.0202825691955545e-07, 'reg_lambda': 0.44862617964053403}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:50:17,043]\u001b[0m Trial 17 finished with value: -1.4560010622822213 and parameters: {'max_depth': 47, 'num_leaves': 16, 'learning_rate': 0.12327009831794723, 'n_estimators': 274, 'reg_alpha': 9.818822544307792e-06, 'reg_lambda': 0.13308368177779814}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:50:19,950]\u001b[0m Trial 18 finished with value: -1.5142997718154243 and parameters: {'max_depth': 47, 'num_leaves': 18, 'learning_rate': 0.22022105900477584, 'n_estimators': 253, 'reg_alpha': 2.231071204104521e-05, 'reg_lambda': 0.1881035815030962}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:50:34,751]\u001b[0m Trial 19 finished with value: -1.5024419493243335 and parameters: {'max_depth': 36, 'num_leaves': 18, 'learning_rate': 0.17095228756385925, 'n_estimators': 284, 'reg_alpha': 1.9722111806471418e-05, 'reg_lambda': 0.9338738335682566}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:50:40,266]\u001b[0m Trial 20 finished with value: -1.4099005034823993 and parameters: {'max_depth': 37, 'num_leaves': 20, 'learning_rate': 0.026333657194142428, 'n_estimators': 261, 'reg_alpha': 1.4507660888119799e-05, 'reg_lambda': 1.4780971684782897e-07}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:51:10,034]\u001b[0m Trial 21 finished with value: -1.4690858278344194 and parameters: {'max_depth': 34, 'num_leaves': 34, 'learning_rate': 0.09229872198717057, 'n_estimators': 323, 'reg_alpha': 1.677311925687443e-05, 'reg_lambda': 50.30898840874566}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:51:21,711]\u001b[0m Trial 22 finished with value: -1.4521421909565648 and parameters: {'max_depth': 36, 'num_leaves': 34, 'learning_rate': 0.04157406914467685, 'n_estimators': 309, 'reg_alpha': 0.0010188832260508295, 'reg_lambda': 3.5924239698781437}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:51:35,276]\u001b[0m Trial 24 finished with value: -1.405726521589529 and parameters: {'max_depth': 34, 'num_leaves': 25, 'learning_rate': 0.01488667456681626, 'n_estimators': 304, 'reg_alpha': 0.0008919528811271846, 'reg_lambda': 2.3213211179914423e-07}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:51:41,589]\u001b[0m Trial 25 finished with value: -1.4084485852648085 and parameters: {'max_depth': 36, 'num_leaves': 24, 'learning_rate': 0.02276622363182442, 'n_estimators': 209, 'reg_alpha': 0.00040923576549130265, 'reg_lambda': 0.004174540367772471}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:51:41,632]\u001b[0m Trial 23 finished with value: -1.4176179323943272 and parameters: {'max_depth': 36, 'num_leaves': 33, 'learning_rate': 0.02043615265572547, 'n_estimators': 317, 'reg_alpha': 0.0014431443202626846, 'reg_lambda': 43.92510824844308}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:52:02,937]\u001b[0m Trial 26 finished with value: -1.415533975526203 and parameters: {'max_depth': 35, 'num_leaves': 24, 'learning_rate': 0.018120279473134004, 'n_estimators': 227, 'reg_alpha': 0.0010761759414309015, 'reg_lambda': 2.614407756723445e-07}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:52:11,733]\u001b[0m Trial 27 finished with value: -1.4165973955411713 and parameters: {'max_depth': 31, 'num_leaves': 23, 'learning_rate': 0.013549107703145921, 'n_estimators': 205, 'reg_alpha': 0.00197894198290838, 'reg_lambda': 1.3573249670077406e-06}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:52:16,886]\u001b[0m Trial 28 finished with value: -1.4046034973918755 and parameters: {'max_depth': 31, 'num_leaves': 24, 'learning_rate': 0.018418557871878898, 'n_estimators': 209, 'reg_alpha': 0.004611417441610769, 'reg_lambda': 0.005662240508845211}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:52:23,799]\u001b[0m Trial 29 finished with value: -1.440322257300545 and parameters: {'max_depth': 30, 'num_leaves': 25, 'learning_rate': 0.008894576298958864, 'n_estimators': 210, 'reg_alpha': 0.012245587229396143, 'reg_lambda': 1.2291242823602774e-07}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:52:46,813]\u001b[0m Trial 30 finished with value: -1.4432820128244002 and parameters: {'max_depth': 31, 'num_leaves': 27, 'learning_rate': 0.008031920832528093, 'n_estimators': 213, 'reg_alpha': 1.972341303899526e-06, 'reg_lambda': 0.002683563607000304}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:53:10,359]\u001b[0m Trial 34 finished with value: -1.6387866299442364 and parameters: {'max_depth': 25, 'num_leaves': 22, 'learning_rate': 0.001939214364827391, 'n_estimators': 132, 'reg_alpha': 0.03277121313311783, 'reg_lambda': 0.0001192824969734035}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:53:31,164]\u001b[0m Trial 32 finished with value: -1.4342149202472565 and parameters: {'max_depth': 20, 'num_leaves': 27, 'learning_rate': 0.004181337501992784, 'n_estimators': 441, 'reg_alpha': 0.02458436691124544, 'reg_lambda': 6.911278024206383e-05}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:53:36,206]\u001b[0m Trial 35 finished with value: -1.412961318846377 and parameters: {'max_depth': 19, 'num_leaves': 27, 'learning_rate': 0.05030761999650372, 'n_estimators': 132, 'reg_alpha': 9.118496911202254e-05, 'reg_lambda': 0.0015455174337606432}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:53:39,779]\u001b[0m Trial 31 finished with value: -1.4717793569252526 and parameters: {'max_depth': 19, 'num_leaves': 28, 'learning_rate': 0.0029870055535559273, 'n_estimators': 431, 'reg_alpha': 2.2597840101460257e-06, 'reg_lambda': 0.00011036113662317527}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:53:45,690]\u001b[0m Trial 36 finished with value: -1.7148935141548434 and parameters: {'max_depth': 19, 'num_leaves': 9, 'learning_rate': 0.000561126151916018, 'n_estimators': 129, 'reg_alpha': 0.00012370360563782203, 'reg_lambda': 0.0022367161550044742}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:53:51,878]\u001b[0m Trial 38 finished with value: -1.7145793920581398 and parameters: {'max_depth': 39, 'num_leaves': 12, 'learning_rate': 0.0008198324959701942, 'n_estimators': 84, 'reg_alpha': 0.00014239586450234817, 'reg_lambda': 0.004279053570935317}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:53:53,336]\u001b[0m Trial 33 finished with value: -1.6334512879085492 and parameters: {'max_depth': 18, 'num_leaves': 28, 'learning_rate': 0.0005911399793187527, 'n_estimators': 441, 'reg_alpha': 1.618238425323106e-06, 'reg_lambda': 3.9977077841263925e-05}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:53:53,586]\u001b[0m Trial 37 finished with value: -1.707413930146275 and parameters: {'max_depth': 39, 'num_leaves': 21, 'learning_rate': 0.0009013423937734821, 'n_estimators': 86, 'reg_alpha': 1.9737171793348563e-06, 'reg_lambda': 0.003845666413634245}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:53:57,897]\u001b[0m Trial 39 finished with value: -1.4152310257463006 and parameters: {'max_depth': 39, 'num_leaves': 21, 'learning_rate': 0.04906243545486236, 'n_estimators': 72, 'reg_alpha': 0.25896813434608174, 'reg_lambda': 1.4704274984831897e-05}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:54:19,481]\u001b[0m Trial 40 finished with value: -1.43041152185425 and parameters: {'max_depth': 27, 'num_leaves': 21, 'learning_rate': 0.047040304437161375, 'n_estimators': 180, 'reg_alpha': 0.21090885088305492, 'reg_lambda': 2.837774019872959e-05}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:54:41,543]\u001b[0m Trial 42 finished with value: -1.4577468244180698 and parameters: {'max_depth': 32, 'num_leaves': 41, 'learning_rate': 0.006834022871413601, 'n_estimators': 192, 'reg_alpha': 0.3529696548094405, 'reg_lambda': 0.0003082319126709881}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:54:49,014]\u001b[0m Trial 43 finished with value: -1.4184581398015326 and parameters: {'max_depth': 33, 'num_leaves': 25, 'learning_rate': 0.007098578178061117, 'n_estimators': 339, 'reg_alpha': 0.15243750216552535, 'reg_lambda': 0.0004332896803321104}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:55:00,972]\u001b[0m Trial 44 finished with value: -1.414274860622647 and parameters: {'max_depth': 33, 'num_leaves': 25, 'learning_rate': 0.01696520336182883, 'n_estimators': 235, 'reg_alpha': 5.42487333610077e-05, 'reg_lambda': 4.548854156129643e-07}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:55:04,496]\u001b[0m Trial 41 finished with value: -1.4681680728933875 and parameters: {'max_depth': 33, 'num_leaves': 38, 'learning_rate': 0.05000383328654327, 'n_estimators': 346, 'reg_alpha': 0.41624910562065215, 'reg_lambda': 1.269464005108086e-05}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:55:22,276]\u001b[0m Trial 45 finished with value: -1.4225012061737798 and parameters: {'max_depth': 33, 'num_leaves': 25, 'learning_rate': 0.018244295485256114, 'n_estimators': 235, 'reg_alpha': 4.991748460605562e-05, 'reg_lambda': 5.910744446491866e-07}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:55:28,625]\u001b[0m Trial 46 finished with value: -1.4123277287753055 and parameters: {'max_depth': 28, 'num_leaves': 31, 'learning_rate': 0.022507874462503512, 'n_estimators': 228, 'reg_alpha': 0.004223978386899307, 'reg_lambda': 6.936927138403386e-07}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:55:49,179]\u001b[0m Trial 47 finished with value: -1.4259572560409153 and parameters: {'max_depth': 43, 'num_leaves': 30, 'learning_rate': 0.029763265302826334, 'n_estimators': 288, 'reg_alpha': 3.075184115439057, 'reg_lambda': 1.2706243274346465e-06}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:55:54,122]\u001b[0m Trial 48 finished with value: -1.4306007064631185 and parameters: {'max_depth': 44, 'num_leaves': 31, 'learning_rate': 0.02363621768395301, 'n_estimators': 302, 'reg_alpha': 0.0004396190450251965, 'reg_lambda': 1.4566353520328935e-06}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:55:56,228]\u001b[0m Trial 49 finished with value: -1.5582410320348055 and parameters: {'max_depth': 43, 'num_leaves': 31, 'learning_rate': 0.4332699433067134, 'n_estimators': 294, 'reg_alpha': 0.00031835554373934195, 'reg_lambda': 6.694823386888783e-06}. Best is trial 14 with value: -1.3991594014296238.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 18:56:04,563]\u001b[0m A new study created in memory with name: no-name-be5b98b6-35e2-4326-b87d-9f2d889c8260\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:56:13,315]\u001b[0m Trial 0 finished with value: -1.8666454224734004 and parameters: {'max_depth': 40, 'num_leaves': 48, 'learning_rate': 1.6337847295411095e-07, 'n_estimators': 187, 'reg_alpha': 4638181.387028456, 'reg_lambda': 0.004547384715632983}. Best is trial 0 with value: -1.8666454224734004.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:56:31,820]\u001b[0m Trial 1 finished with value: -1.8193580090681962 and parameters: {'max_depth': 6, 'num_leaves': 8, 'learning_rate': 0.0005106229404401186, 'n_estimators': 283, 'reg_alpha': 26.991544153437214, 'reg_lambda': 3982.036677066819}. Best is trial 1 with value: -1.8193580090681962.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:56:34,911]\u001b[0m Trial 5 finished with value: -1.8666383873892247 and parameters: {'max_depth': 5, 'num_leaves': 20, 'learning_rate': 3.157555375135363e-05, 'n_estimators': 3, 'reg_alpha': 1.698380617007251e-07, 'reg_lambda': 679623.1202751453}. Best is trial 1 with value: -1.8193580090681962.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:56:45,035]\u001b[0m Trial 6 finished with value: -1.7570845312781038 and parameters: {'max_depth': 41, 'num_leaves': 8, 'learning_rate': 0.005035129105454128, 'n_estimators': 77, 'reg_alpha': 1.4498349880748995, 'reg_lambda': 1.8693236936523898e-06}. Best is trial 6 with value: -1.7570845312781038.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:56:59,315]\u001b[0m Trial 4 finished with value: -1.7938443445014147 and parameters: {'max_depth': 28, 'num_leaves': 49, 'learning_rate': 0.3818641548068049, 'n_estimators': 474, 'reg_alpha': 264.4935405949325, 'reg_lambda': 6.751951116129326}. Best is trial 6 with value: -1.7570845312781038.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:57:13,550]\u001b[0m Trial 7 finished with value: -1.7514014500969795 and parameters: {'max_depth': 8, 'num_leaves': 23, 'learning_rate': 0.0786180826784033, 'n_estimators': 174, 'reg_alpha': 8.203709478847629e-06, 'reg_lambda': 1.1030190439354781e-05}. Best is trial 7 with value: -1.7514014500969795.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:57:15,196]\u001b[0m Trial 2 finished with value: -1.698890708615285 and parameters: {'max_depth': 20, 'num_leaves': 22, 'learning_rate': 0.005787540941138211, 'n_estimators': 404, 'reg_alpha': 0.00019581507065348014, 'reg_lambda': 0.006902719758575594}. Best is trial 2 with value: -1.698890708615285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:57:32,985]\u001b[0m Trial 8 finished with value: -1.8661566979163704 and parameters: {'max_depth': 30, 'num_leaves': 9, 'learning_rate': 5.867417132855304e-06, 'n_estimators': 414, 'reg_alpha': 70263.70948907599, 'reg_lambda': 0.005269955330109513}. Best is trial 2 with value: -1.698890708615285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:57:37,570]\u001b[0m Trial 3 finished with value: -1.7191391469246853 and parameters: {'max_depth': 30, 'num_leaves': 41, 'learning_rate': 0.006648819723604824, 'n_estimators': 385, 'reg_alpha': 0.0011394837818869416, 'reg_lambda': 248.27390157121013}. Best is trial 2 with value: -1.698890708615285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:57:49,871]\u001b[0m Trial 9 finished with value: -1.8418422356706026 and parameters: {'max_depth': 10, 'num_leaves': 38, 'learning_rate': 0.0003676707571380934, 'n_estimators': 154, 'reg_alpha': 0.3015731426968541, 'reg_lambda': 9.019489415318825}. Best is trial 2 with value: -1.698890708615285.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:57:59,704]\u001b[0m Trial 12 finished with value: -1.6883589811842228 and parameters: {'max_depth': 35, 'num_leaves': 33, 'learning_rate': 0.031411238034384656, 'n_estimators': 124, 'reg_alpha': 2.1677450735474435e-07, 'reg_lambda': 59630.02549760223}. Best is trial 12 with value: -1.6883589811842228.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:58:01,642]\u001b[0m Trial 11 finished with value: -1.6981965233155356 and parameters: {'max_depth': 40, 'num_leaves': 47, 'learning_rate': 0.011468202431351287, 'n_estimators': 105, 'reg_alpha': 114.94479926564702, 'reg_lambda': 0.000922001502031238}. Best is trial 12 with value: -1.6883589811842228.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:58:03,005]\u001b[0m Trial 10 finished with value: -1.8652114598750327 and parameters: {'max_depth': 8, 'num_leaves': 32, 'learning_rate': 3.0111856776301466e-05, 'n_estimators': 294, 'reg_alpha': 4.549962631071492e-06, 'reg_lambda': 190139.64264261062}. Best is trial 12 with value: -1.6883589811842228.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:58:17,863]\u001b[0m Trial 15 finished with value: -1.7077352182999246 and parameters: {'max_depth': 42, 'num_leaves': 33, 'learning_rate': 0.8544775552372483, 'n_estimators': 69, 'reg_alpha': 0.01754204675889366, 'reg_lambda': 288600.03354691045}. Best is trial 12 with value: -1.6883589811842228.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:58:22,508]\u001b[0m Trial 16 finished with value: -1.6800399342391616 and parameters: {'max_depth': 47, 'num_leaves': 34, 'learning_rate': 0.6682070771906956, 'n_estimators': 94, 'reg_alpha': 0.0059320887781227965, 'reg_lambda': 5694090.184881815}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:58:26,858]\u001b[0m Trial 18 finished with value: -1.8539478025771166 and parameters: {'max_depth': 33, 'num_leaves': 28, 'learning_rate': 0.10794156171637913, 'n_estimators': 17, 'reg_alpha': 1.4338530861718075e-07, 'reg_lambda': 8838055.17757713}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:58:31,329]\u001b[0m Trial 17 finished with value: -1.831718562298551 and parameters: {'max_depth': 47, 'num_leaves': 42, 'learning_rate': 0.05396296045009139, 'n_estimators': 96, 'reg_alpha': 615.3442402054916, 'reg_lambda': 8380539.166745721}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:58:37,665]\u001b[0m Trial 14 finished with value: -1.8176736459252496 and parameters: {'max_depth': 18, 'num_leaves': 31, 'learning_rate': 0.02825324383163347, 'n_estimators': 285, 'reg_alpha': 1.1310711801703881e-07, 'reg_lambda': 8856155.06620521}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 18:58:41,871]\u001b[0m Trial 13 finished with value: -1.7400432846634055 and parameters: {'max_depth': 19, 'num_leaves': 28, 'learning_rate': 0.03539898686184155, 'n_estimators': 311, 'reg_alpha': 0.0015147287293568385, 'reg_lambda': 0.025828426008002527}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:07,609]\u001b[0m Trial 22 finished with value: -1.7930543133511532 and parameters: {'max_depth': 46, 'num_leaves': 16, 'learning_rate': 0.37982857425353134, 'n_estimators': 221, 'reg_alpha': 2.9936147320825087e-05, 'reg_lambda': 8355.748773571457}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:14,988]\u001b[0m Trial 20 finished with value: -1.8115698064721748 and parameters: {'max_depth': 21, 'num_leaves': 35, 'learning_rate': 0.7045530999734098, 'n_estimators': 216, 'reg_alpha': 0.0011403797583974314, 'reg_lambda': 9673.432380450251}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:17,390]\u001b[0m Trial 21 finished with value: -1.7889451765517022 and parameters: {'max_depth': 47, 'num_leaves': 36, 'learning_rate': 0.4150695646634516, 'n_estimators': 234, 'reg_alpha': 0.0027611396422665777, 'reg_lambda': 3828.939934675745}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:18,304]\u001b[0m Trial 19 finished with value: -1.8428846209083258 and parameters: {'max_depth': 46, 'num_leaves': 38, 'learning_rate': 0.9032812638230916, 'n_estimators': 239, 'reg_alpha': 0.0009134614205896288, 'reg_lambda': 8453.002027114226}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:35,953]\u001b[0m Trial 23 finished with value: -1.8094159606576494 and parameters: {'max_depth': 36, 'num_leaves': 37, 'learning_rate': 0.9724608823057505, 'n_estimators': 135, 'reg_alpha': 0.01717662023705349, 'reg_lambda': 2858.9380596957208}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:41,584]\u001b[0m Trial 24 finished with value: -1.783365682160818 and parameters: {'max_depth': 35, 'num_leaves': 45, 'learning_rate': 0.16455636191097753, 'n_estimators': 116, 'reg_alpha': 0.3767502883258395, 'reg_lambda': 8.39109526998029e-05}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:47,447]\u001b[0m Trial 25 finished with value: -1.713503487692858 and parameters: {'max_depth': 37, 'num_leaves': 45, 'learning_rate': 0.016347345778208688, 'n_estimators': 128, 'reg_alpha': 0.20678320594408672, 'reg_lambda': 8.580363078924997e-05}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:50,835]\u001b[0m Trial 26 finished with value: -1.7112816301074778 and parameters: {'max_depth': 35, 'num_leaves': 43, 'learning_rate': 0.017416106217175764, 'n_estimators': 126, 'reg_alpha': 0.11272717521288164, 'reg_lambda': 8.273419926894059e-05}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:54,808]\u001b[0m Trial 28 finished with value: -1.7141486717038181 and parameters: {'max_depth': 39, 'num_leaves': 43, 'learning_rate': 0.015913356623019972, 'n_estimators': 44, 'reg_alpha': 2.128122967971224e-06, 'reg_lambda': 84.57358186753893}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 18:59:55,637]\u001b[0m Trial 29 finished with value: -1.7159348326362158 and parameters: {'max_depth': 27, 'num_leaves': 25, 'learning_rate': 0.14466925440113876, 'n_estimators': 42, 'reg_alpha': 4.183531219214642e-05, 'reg_lambda': 0.11655485347782203}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:00:02,941]\u001b[0m Trial 30 finished with value: -1.8292471058581836 and parameters: {'max_depth': 25, 'num_leaves': 26, 'learning_rate': 0.0018094951004089665, 'n_estimators': 50, 'reg_alpha': 4.772155413128778, 'reg_lambda': 0.29826474566459366}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:00:08,514]\u001b[0m Trial 31 finished with value: -1.7145441287861265 and parameters: {'max_depth': 0, 'num_leaves': 25, 'learning_rate': 0.15181438360590727, 'n_estimators': 47, 'reg_alpha': 7.552940034898904, 'reg_lambda': 1.53399873367529e-07}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:00:09,442]\u001b[0m Trial 27 finished with value: -1.7027243846624727 and parameters: {'max_depth': 37, 'num_leaves': 47, 'learning_rate': 0.013904459682332152, 'n_estimators': 113, 'reg_alpha': 0.1816116079027586, 'reg_lambda': 191.32911619318472}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:00:29,370]\u001b[0m Trial 33 finished with value: -1.7096153179965068 and parameters: {'max_depth': 43, 'num_leaves': 16, 'learning_rate': 0.1446196388640852, 'n_estimators': 167, 'reg_alpha': 0.0001173054987868627, 'reg_lambda': 80422.25546960674}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:00:54,910]\u001b[0m Trial 32 finished with value: -1.739532627679374 and parameters: {'max_depth': 43, 'num_leaves': 50, 'learning_rate': 0.0022936004112051748, 'n_estimators': 201, 'reg_alpha': 5.11881752948938, 'reg_lambda': 0.0006250193803758364}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:01:03,822]\u001b[0m Trial 34 finished with value: -1.683911525311473 and parameters: {'max_depth': 14, 'num_leaves': 16, 'learning_rate': 0.0035787197184966833, 'n_estimators': 369, 'reg_alpha': 0.00011762885860028576, 'reg_lambda': 0.001603488230062909}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:01:06,330]\u001b[0m Trial 35 finished with value: -1.717192328914833 and parameters: {'max_depth': 15, 'num_leaves': 18, 'learning_rate': 0.001708729902735194, 'n_estimators': 349, 'reg_alpha': 4.5266641722756616e-05, 'reg_lambda': 0.0019576706525722774}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:01:28,066]\u001b[0m Trial 36 finished with value: -1.6954070289811831 and parameters: {'max_depth': 12, 'num_leaves': 19, 'learning_rate': 0.002571853129112493, 'n_estimators': 357, 'reg_alpha': 0.00020619937253462853, 'reg_lambda': 0.0008517807285191276}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:01:31,371]\u001b[0m Trial 38 finished with value: -1.7307806714396068 and parameters: {'max_depth': 15, 'num_leaves': 5, 'learning_rate': 0.0017629326108124193, 'n_estimators': 355, 'reg_alpha': 2.542453216179671e-06, 'reg_lambda': 0.0258691136016417}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:01:45,616]\u001b[0m Trial 37 finished with value: -1.6900672937309416 and parameters: {'max_depth': 16, 'num_leaves': 19, 'learning_rate': 0.005898512558730839, 'n_estimators': 343, 'reg_alpha': 1.1543028138709458e-06, 'reg_lambda': 0.003786555800159832}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:02:18,111]\u001b[0m Trial 41 finished with value: -1.7769171034090245 and parameters: {'max_depth': 16, 'num_leaves': 12, 'learning_rate': 0.006286853636975564, 'n_estimators': 434, 'reg_alpha': 0.00015507573671219482, 'reg_lambda': 1202141.6664922023}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:02:23,420]\u001b[0m Trial 40 finished with value: -1.750070915823398 and parameters: {'max_depth': 14, 'num_leaves': 11, 'learning_rate': 0.0007890834083784826, 'n_estimators': 474, 'reg_alpha': 1.5745047537497083e-06, 'reg_lambda': 0.018042971872890612}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:02:29,476]\u001b[0m Trial 39 finished with value: -1.7624677308020598 and parameters: {'max_depth': 31, 'num_leaves': 30, 'learning_rate': 0.03869439634604854, 'n_estimators': 455, 'reg_alpha': 1.292422565329745e-06, 'reg_lambda': 0.03304639261883182}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:02:39,387]\u001b[0m Trial 42 finished with value: -1.6812682032839192 and parameters: {'max_depth': 23, 'num_leaves': 14, 'learning_rate': 0.041558443680627534, 'n_estimators': 462, 'reg_alpha': 7.613630167512551e-07, 'reg_lambda': 1250130.111785934}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:02:54,604]\u001b[0m Trial 43 finished with value: -1.7205326982917684 and parameters: {'max_depth': 23, 'num_leaves': 12, 'learning_rate': 0.044609841153050396, 'n_estimators': 327, 'reg_alpha': 7.589299912160925e-07, 'reg_lambda': 2.07508835024871}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:03:23,116]\u001b[0m Trial 46 finished with value: -1.6810017835494078 and parameters: {'max_depth': 24, 'num_leaves': 14, 'learning_rate': 0.05891150514135684, 'n_estimators': 385, 'reg_alpha': 6.523090671128612e-07, 'reg_lambda': 1553016.3165907522}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:03:27,137]\u001b[0m Trial 44 finished with value: -1.690046148137345 and parameters: {'max_depth': 12, 'num_leaves': 22, 'learning_rate': 0.005316675442323313, 'n_estimators': 340, 'reg_alpha': 1.2651225310966971e-05, 'reg_lambda': 0.416432588508683}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:03:37,309]\u001b[0m Trial 45 finished with value: -1.6918781926359676 and parameters: {'max_depth': 12, 'num_leaves': 22, 'learning_rate': 0.0033019526953536257, 'n_estimators': 375, 'reg_alpha': 1.1815837538654048e-05, 'reg_lambda': 2.1437254695008603}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:03:46,832]\u001b[0m Trial 47 finished with value: -1.8068539982931382 and parameters: {'max_depth': 22, 'num_leaves': 22, 'learning_rate': 0.004888171522403181, 'n_estimators': 397, 'reg_alpha': 8.921770413541955e-06, 'reg_lambda': 1520188.1226353056}. Best is trial 16 with value: -1.6800399342391616.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:03:59,464]\u001b[0m Trial 49 finished with value: -1.67929988799962 and parameters: {'max_depth': 27, 'num_leaves': 15, 'learning_rate': 0.07273255888516933, 'n_estimators': 384, 'reg_alpha': 3.8742375516488314e-07, 'reg_lambda': 1687864.0426449447}. Best is trial 49 with value: -1.67929988799962.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:04:02,510]\u001b[0m Trial 48 finished with value: -1.67815334320745 and parameters: {'max_depth': 28, 'num_leaves': 22, 'learning_rate': 0.0718468650172372, 'n_estimators': 387, 'reg_alpha': 1.202087180572465e-05, 'reg_lambda': 994596.377124944}. Best is trial 48 with value: -1.67815334320745.\u001b[0m\n",
      " 56%|                            | 9/16 [1:54:36<1:43:33, 887.57s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:04:13,510]\u001b[0m A new study created in memory with name: no-name-a1667427-a79e-4c45-bc11-a4b16a964977\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:04:17,317]\u001b[0m Trial 3 finished with value: -1.0662541622492399 and parameters: {'max_depth': 3, 'num_leaves': 31, 'learning_rate': 1.0756086680370636e-06, 'n_estimators': 62, 'reg_alpha': 67.33437969296027, 'reg_lambda': 0.1550201344640773}. Best is trial 3 with value: -1.0662541622492399.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:04:17,697]\u001b[0m Trial 1 finished with value: -1.0661638016179804 and parameters: {'max_depth': 28, 'num_leaves': 17, 'learning_rate': 9.411890757993069e-06, 'n_estimators': 28, 'reg_alpha': 9.62629641954201e-07, 'reg_lambda': 0.00026350944548508696}. Best is trial 1 with value: -1.0661638016179804.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:04:21,854]\u001b[0m Trial 4 finished with value: -1.0662846717516938 and parameters: {'max_depth': 43, 'num_leaves': 32, 'learning_rate': 0.8482866840659093, 'n_estimators': 290, 'reg_alpha': 127632.02889955108, 'reg_lambda': 0.05428827969718757}. Best is trial 1 with value: -1.0661638016179804.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:04:28,984]\u001b[0m Trial 6 finished with value: -1.0378574394360414 and parameters: {'max_depth': 32, 'num_leaves': 8, 'learning_rate': 0.7756122854362345, 'n_estimators': 174, 'reg_alpha': 7.808936335696553, 'reg_lambda': 1991.469834554474}. Best is trial 6 with value: -1.0378574394360414.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:04:32,989]\u001b[0m Trial 2 finished with value: -1.1277062908916828 and parameters: {'max_depth': 21, 'num_leaves': 45, 'learning_rate': 0.5521794178950629, 'n_estimators': 123, 'reg_alpha': 0.0016174812545575721, 'reg_lambda': 1.6563184835426352e-07}. Best is trial 6 with value: -1.0378574394360414.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:04:41,515]\u001b[0m Trial 8 finished with value: -1.0043660416633609 and parameters: {'max_depth': 21, 'num_leaves': 7, 'learning_rate': 0.0008626808225431252, 'n_estimators': 192, 'reg_alpha': 0.1944908485665302, 'reg_lambda': 2699.154266942191}. Best is trial 8 with value: -1.0043660416633609.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:04:46,706]\u001b[0m Trial 9 finished with value: -0.9190534972135151 and parameters: {'max_depth': 19, 'num_leaves': 29, 'learning_rate': 0.023448279422619893, 'n_estimators': 40, 'reg_alpha': 670.1623730185793, 'reg_lambda': 5.986719069971446}. Best is trial 9 with value: -0.9190534972135151.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:01,225]\u001b[0m Trial 0 finished with value: -1.0662581360597363 and parameters: {'max_depth': 9, 'num_leaves': 23, 'learning_rate': 1.199255763784745e-07, 'n_estimators': 463, 'reg_alpha': 1.1619120967002788e-07, 'reg_lambda': 1.4247911168595267e-05}. Best is trial 9 with value: -0.9190534972135151.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:02,592]\u001b[0m Trial 11 finished with value: -1.0633758379137728 and parameters: {'max_depth': 25, 'num_leaves': 49, 'learning_rate': 0.12782474330160024, 'n_estimators': 7, 'reg_alpha': 11759.145107098599, 'reg_lambda': 9117522.264958763}. Best is trial 9 with value: -0.9190534972135151.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:03,960]\u001b[0m Trial 7 finished with value: -0.8897170000302304 and parameters: {'max_depth': 18, 'num_leaves': 45, 'learning_rate': 0.787830444151566, 'n_estimators': 349, 'reg_alpha': 520.3354490568545, 'reg_lambda': 995205.8466105065}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:08,833]\u001b[0m Trial 13 finished with value: -1.0662846717516938 and parameters: {'max_depth': 10, 'num_leaves': 41, 'learning_rate': 0.004760532023580016, 'n_estimators': 365, 'reg_alpha': 3743642.7910707733, 'reg_lambda': 7804676.391421471}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:15,883]\u001b[0m Trial 5 finished with value: -1.0662153123359646 and parameters: {'max_depth': 46, 'num_leaves': 35, 'learning_rate': 4.027672862074154e-07, 'n_estimators': 370, 'reg_alpha': 1.189293379397465e-07, 'reg_lambda': 24.81688921648228}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:28,048]\u001b[0m Trial 12 finished with value: -1.0635828764806106 and parameters: {'max_depth': 11, 'num_leaves': 21, 'learning_rate': 2.231779388896492e-05, 'n_estimators': 270, 'reg_alpha': 0.00024265528325190683, 'reg_lambda': 4.732150299817149}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:34,819]\u001b[0m Trial 14 finished with value: -0.9758885210709867 and parameters: {'max_depth': 17, 'num_leaves': 38, 'learning_rate': 0.015500226861978713, 'n_estimators': 308, 'reg_alpha': 1134.6851717542208, 'reg_lambda': 97.53860754916134}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:39,608]\u001b[0m Trial 15 finished with value: -0.9228032480303034 and parameters: {'max_depth': 14, 'num_leaves': 20, 'learning_rate': 0.015666953052207146, 'n_estimators': 309, 'reg_alpha': 889.4809564709932, 'reg_lambda': 12280.84108846334}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:51,408]\u001b[0m Trial 10 finished with value: -1.0662126254402677 and parameters: {'max_depth': 22, 'num_leaves': 37, 'learning_rate': 3.173105341937392e-07, 'n_estimators': 475, 'reg_alpha': 0.32234669884503997, 'reg_lambda': 121.2926893671263}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:05:56,608]\u001b[0m Trial 19 finished with value: -1.0662846717516938 and parameters: {'max_depth': 35, 'num_leaves': 26, 'learning_rate': 0.10489874869183735, 'n_estimators': 399, 'reg_alpha': 87021.87825467555, 'reg_lambda': 113165.56770073275}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:06:12,540]\u001b[0m Trial 16 finished with value: -0.894168075010077 and parameters: {'max_depth': 15, 'num_leaves': 39, 'learning_rate': 0.018911783120026646, 'n_estimators': 472, 'reg_alpha': 1087.0186823019078, 'reg_lambda': 41470.317471661765}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:06:19,618]\u001b[0m Trial 21 finished with value: -1.002619387048172 and parameters: {'max_depth': 1, 'num_leaves': 49, 'learning_rate': 0.0012673346191880808, 'n_estimators': 415, 'reg_alpha': 17.582998177666404, 'reg_lambda': 179283.361691578}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:06:26,180]\u001b[0m Trial 22 finished with value: -1.0662846717516938 and parameters: {'max_depth': 6, 'num_leaves': 40, 'learning_rate': 0.09960464626776597, 'n_estimators': 500, 'reg_alpha': 4942133.455174807, 'reg_lambda': 323623.14347384917}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:06:28,888]\u001b[0m Trial 18 finished with value: -0.9169310848153277 and parameters: {'max_depth': 35, 'num_leaves': 27, 'learning_rate': 0.0628272334321985, 'n_estimators': 500, 'reg_alpha': 1.1248711944432062, 'reg_lambda': 120250.25748278937}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:06:32,034]\u001b[0m Trial 20 finished with value: -1.069933274150194 and parameters: {'max_depth': -1, 'num_leaves': 49, 'learning_rate': 0.06051098255779096, 'n_estimators': 213, 'reg_alpha': 44.74406541040058, 'reg_lambda': 0.30610643354956096}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:06:33,684]\u001b[0m Trial 17 finished with value: -0.9503819543075108 and parameters: {'max_depth': 34, 'num_leaves': 50, 'learning_rate': 0.04994655927486992, 'n_estimators': 440, 'reg_alpha': 192.4906783136062, 'reg_lambda': 40507.93004296955}. Best is trial 7 with value: -0.8897170000302304.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:13,462]\u001b[0m Trial 26 finished with value: -0.8528976077717149 and parameters: {'max_depth': 39, 'num_leaves': 44, 'learning_rate': 0.27826243097288295, 'n_estimators': 371, 'reg_alpha': 1.314695640261788, 'reg_lambda': 947527.0652704184}. Best is trial 26 with value: -0.8528976077717149.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:22,534]\u001b[0m Trial 23 finished with value: -1.0244611969418536 and parameters: {'max_depth': 15, 'num_leaves': 45, 'learning_rate': 0.00023671486424121346, 'n_estimators': 437, 'reg_alpha': 2.2452473157205386, 'reg_lambda': 1741.8150728402911}. Best is trial 26 with value: -0.8528976077717149.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:23,954]\u001b[0m Trial 24 finished with value: -0.8488578983551565 and parameters: {'max_depth': 38, 'num_leaves': 44, 'learning_rate': 0.18195515131737552, 'n_estimators': 445, 'reg_alpha': 2.00643039210099, 'reg_lambda': 833245.9311606378}. Best is trial 24 with value: -0.8488578983551565.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:24,290]\u001b[0m Trial 27 finished with value: -0.8417576403778211 and parameters: {'max_depth': 41, 'num_leaves': 43, 'learning_rate': 0.39353043853047465, 'n_estimators': 346, 'reg_alpha': 7024.574600436542, 'reg_lambda': 2503477.81881923}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:29,864]\u001b[0m Trial 25 finished with value: -0.860922235242633 and parameters: {'max_depth': 38, 'num_leaves': 44, 'learning_rate': 0.26967060742651794, 'n_estimators': 430, 'reg_alpha': 1.5794669012489972, 'reg_lambda': 809458.7099643858}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:35,274]\u001b[0m Trial 28 finished with value: -0.8429179172795278 and parameters: {'max_depth': 40, 'num_leaves': 44, 'learning_rate': 0.3096667251616519, 'n_estimators': 349, 'reg_alpha': 7667.9368307567, 'reg_lambda': 2096197.1290482332}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:42,530]\u001b[0m Trial 31 finished with value: -0.9123070696402964 and parameters: {'max_depth': 41, 'num_leaves': 35, 'learning_rate': 0.17380459152972616, 'n_estimators': 333, 'reg_alpha': 0.040004164610122205, 'reg_lambda': 7586187.167534509}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:42,904]\u001b[0m Trial 32 finished with value: -0.938846075026252 and parameters: {'max_depth': 47, 'num_leaves': 35, 'learning_rate': 0.2762674685443174, 'n_estimators': 236, 'reg_alpha': 12585.663154844855, 'reg_lambda': 9033204.281958636}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:48,333]\u001b[0m Trial 33 finished with value: -0.8524400336779289 and parameters: {'max_depth': 46, 'num_leaves': 15, 'learning_rate': 0.25266786487953274, 'n_estimators': 236, 'reg_alpha': 9438.12566406563, 'reg_lambda': 9142.19612981489}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:50,791]\u001b[0m Trial 30 finished with value: -0.8452953295316799 and parameters: {'max_depth': 40, 'num_leaves': 43, 'learning_rate': 0.23620267110862028, 'n_estimators': 337, 'reg_alpha': 0.07335007878281756, 'reg_lambda': 2109662.5836252244}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:07:52,653]\u001b[0m Trial 35 finished with value: -0.8659538230789998 and parameters: {'max_depth': 44, 'num_leaves': 11, 'learning_rate': 0.9900476885796792, 'n_estimators': 257, 'reg_alpha': 5248.708946371614, 'reg_lambda': 12835.605839533924}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:08:08,020]\u001b[0m Trial 29 finished with value: -0.8482779236823932 and parameters: {'max_depth': 39, 'num_leaves': 45, 'learning_rate': 0.31114667072853164, 'n_estimators': 349, 'reg_alpha': 0.05148980517858728, 'reg_lambda': 1214596.7318648598}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:08:24,947]\u001b[0m Trial 34 finished with value: -0.8439927898388497 and parameters: {'max_depth': 41, 'num_leaves': 43, 'learning_rate': 0.30386396813875094, 'n_estimators': 381, 'reg_alpha': 26.85076319792411, 'reg_lambda': 1483181.6165960992}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:08:38,129]\u001b[0m Trial 36 finished with value: -0.886347168586473 and parameters: {'max_depth': 30, 'num_leaves': 47, 'learning_rate': 0.9880747767728474, 'n_estimators': 392, 'reg_alpha': 0.04150852025938558, 'reg_lambda': 1736358.4023181985}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:08:41,185]\u001b[0m Trial 37 finished with value: -0.855737358407191 and parameters: {'max_depth': 29, 'num_leaves': 42, 'learning_rate': 0.37468873515358353, 'n_estimators': 395, 'reg_alpha': 0.01367457590224378, 'reg_lambda': 1217875.0296813657}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:08:50,548]\u001b[0m Trial 38 finished with value: -0.8683026857708508 and parameters: {'max_depth': 30, 'num_leaves': 42, 'learning_rate': 0.5297211802692483, 'n_estimators': 335, 'reg_alpha': 0.05244473096876378, 'reg_lambda': 1171464.8521930606}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:01,298]\u001b[0m Trial 39 finished with value: -0.8460945941233777 and parameters: {'max_depth': 30, 'num_leaves': 41, 'learning_rate': 0.4615259844943704, 'n_estimators': 393, 'reg_alpha': 136.73205033056075, 'reg_lambda': 2118332.005301269}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:11,098]\u001b[0m Trial 40 finished with value: -0.8873458341210825 and parameters: {'max_depth': 27, 'num_leaves': 42, 'learning_rate': 0.0404090304821628, 'n_estimators': 309, 'reg_alpha': 17.32484194375184, 'reg_lambda': 114942.18158542513}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:17,388]\u001b[0m Trial 41 finished with value: -1.0643814878134805 and parameters: {'max_depth': 42, 'num_leaves': 32, 'learning_rate': 0.055371091689238365, 'n_estimators': 309, 'reg_alpha': 19.420042697424044, 'reg_lambda': 0.005146878659447021}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:18,619]\u001b[0m Trial 44 finished with value: -1.0492643241621138 and parameters: {'max_depth': 42, 'num_leaves': 33, 'learning_rate': 0.46686604019093375, 'n_estimators': 285, 'reg_alpha': 139.1023652411799, 'reg_lambda': 0.003333496049903402}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:18,964]\u001b[0m Trial 42 finished with value: -0.8879090319839736 and parameters: {'max_depth': 42, 'num_leaves': 32, 'learning_rate': 0.038604709651701576, 'n_estimators': 282, 'reg_alpha': 119.2236934850849, 'reg_lambda': 98976.21918155222}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:09:29,705]\u001b[0m Trial 46 finished with value: -0.8498923336566487 and parameters: {'max_depth': 33, 'num_leaves': 37, 'learning_rate': 0.10565623895149209, 'n_estimators': 132, 'reg_alpha': 90.72942893241041, 'reg_lambda': 261203.508406701}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:31,234]\u001b[0m Trial 43 finished with value: -0.871296766396203 and parameters: {'max_depth': 42, 'num_leaves': 31, 'learning_rate': 0.03823354898829442, 'n_estimators': 293, 'reg_alpha': 13.57189449174119, 'reg_lambda': 132422.40490656882}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:35,541]\u001b[0m Trial 47 finished with value: -0.8706595073641876 and parameters: {'max_depth': 33, 'num_leaves': 47, 'learning_rate': 0.14132964140319673, 'n_estimators': 388, 'reg_alpha': 7.783471698016294, 'reg_lambda': 3751369.9400914833}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:36,332]\u001b[0m Trial 45 finished with value: -0.9013339345893144 and parameters: {'max_depth': 44, 'num_leaves': 47, 'learning_rate': 0.5810797553559098, 'n_estimators': 130, 'reg_alpha': 119.05219138161854, 'reg_lambda': 244819.89309109672}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:36,405]\u001b[0m Trial 49 finished with value: -1.0662846717516938 and parameters: {'max_depth': 37, 'num_leaves': 47, 'learning_rate': 0.7694351165507431, 'n_estimators': 378, 'reg_alpha': 91218.65490612414, 'reg_lambda': 4087962.0028417315}. Best is trial 27 with value: -0.8417576403778211.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:48,788]\u001b[0m Trial 48 finished with value: -0.8415051401227425 and parameters: {'max_depth': 37, 'num_leaves': 46, 'learning_rate': 0.6091945850040581, 'n_estimators': 374, 'reg_alpha': 6.174442677810856, 'reg_lambda': 3702082.2822541357}. Best is trial 48 with value: -0.8415051401227425.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:09:56,010]\u001b[0m A new study created in memory with name: no-name-5f4a5098-49be-4833-bee2-76c7a8779d5b\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:09:57,055]\u001b[0m Trial 3 finished with value: -3.23955406339788 and parameters: {'max_depth': 2, 'num_leaves': 43, 'learning_rate': 1.3196547490541142e-05, 'n_estimators': 47, 'reg_alpha': 0.15414119371966542, 'reg_lambda': 1078759.891643392}. Best is trial 3 with value: -3.23955406339788.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:04,885]\u001b[0m Trial 1 finished with value: -2.88057206453028 and parameters: {'max_depth': 30, 'num_leaves': 8, 'learning_rate': 0.002142889919115833, 'n_estimators': 318, 'reg_alpha': 1195.2371246828593, 'reg_lambda': 8350.345208936711}. Best is trial 1 with value: -2.88057206453028.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:13,435]\u001b[0m Trial 5 finished with value: -3.2395631088733112 and parameters: {'max_depth': 25, 'num_leaves': 12, 'learning_rate': 7.896444315179238e-07, 'n_estimators': 287, 'reg_alpha': 9.721646663430297e-06, 'reg_lambda': 6447563.928171238}. Best is trial 1 with value: -2.88057206453028.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:16,840]\u001b[0m Trial 2 finished with value: -2.7780204355978078 and parameters: {'max_depth': 18, 'num_leaves': 21, 'learning_rate': 0.040657480020748704, 'n_estimators': 328, 'reg_alpha': 0.5153373233530102, 'reg_lambda': 0.1075879155501323}. Best is trial 2 with value: -2.7780204355978078.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:25,151]\u001b[0m Trial 6 finished with value: -3.2274185150364967 and parameters: {'max_depth': 0, 'num_leaves': 38, 'learning_rate': 6.68981807096395e-05, 'n_estimators': 124, 'reg_alpha': 0.30614636773545967, 'reg_lambda': 0.0005502819405006203}. Best is trial 2 with value: -2.7780204355978078.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:28,035]\u001b[0m Trial 8 finished with value: -3.2395636887760384 and parameters: {'max_depth': -1, 'num_leaves': 27, 'learning_rate': 0.004273344725707268, 'n_estimators': 496, 'reg_alpha': 379106.90584454744, 'reg_lambda': 2.9831336044495937e-07}. Best is trial 2 with value: -2.7780204355978078.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:28,137]\u001b[0m Trial 7 finished with value: -2.644852450557234 and parameters: {'max_depth': 10, 'num_leaves': 46, 'learning_rate': 0.06047307591475817, 'n_estimators': 324, 'reg_alpha': 952.710113699428, 'reg_lambda': 24.516444437883383}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:30,263]\u001b[0m Trial 4 finished with value: -2.86928729424654 and parameters: {'max_depth': 38, 'num_leaves': 26, 'learning_rate': 0.0769920545639995, 'n_estimators': 473, 'reg_alpha': 0.018954174274024984, 'reg_lambda': 0.13840399836322403}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:31,254]\u001b[0m Trial 9 finished with value: -3.192058450628041 and parameters: {'max_depth': 9, 'num_leaves': 18, 'learning_rate': 0.14856817743225106, 'n_estimators': 155, 'reg_alpha': 17922.7205883141, 'reg_lambda': 4518984.738968609}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:33,761]\u001b[0m Trial 11 finished with value: -3.185500080142151 and parameters: {'max_depth': 34, 'num_leaves': 23, 'learning_rate': 0.0008720895823302387, 'n_estimators': 44, 'reg_alpha': 7.577233021457649e-06, 'reg_lambda': 3.343539885649579e-05}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:34,444]\u001b[0m Trial 0 finished with value: -3.239084643243441 and parameters: {'max_depth': 36, 'num_leaves': 31, 'learning_rate': 7.99633449173825e-07, 'n_estimators': 407, 'reg_alpha': 6.238465360800244e-05, 'reg_lambda': 0.017937814299360547}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:36,512]\u001b[0m Trial 12 finished with value: -3.239500959898682 and parameters: {'max_depth': 35, 'num_leaves': 11, 'learning_rate': 2.902103078921153e-07, 'n_estimators': 161, 'reg_alpha': 1992.8534101374512, 'reg_lambda': 6.398033852769502}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:40,277]\u001b[0m Trial 13 finished with value: -2.7545187538789837 and parameters: {'max_depth': 16, 'num_leaves': 50, 'learning_rate': 0.34906107055464536, 'n_estimators': 400, 'reg_alpha': 334.0726564755198, 'reg_lambda': 82.82026341214552}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:43,118]\u001b[0m Trial 14 finished with value: -2.8896654689293704 and parameters: {'max_depth': 15, 'num_leaves': 48, 'learning_rate': 0.6040375747052973, 'n_estimators': 362, 'reg_alpha': 136.99922187997524, 'reg_lambda': 30.065439198770918}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:44,818]\u001b[0m Trial 17 finished with value: -3.2395636887760384 and parameters: {'max_depth': 47, 'num_leaves': 49, 'learning_rate': 0.9133579214384793, 'n_estimators': 221, 'reg_alpha': 4214792.4159866385, 'reg_lambda': 248.5463026199325}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:49,783]\u001b[0m Trial 16 finished with value: -2.8949219755446762 and parameters: {'max_depth': 15, 'num_leaves': 50, 'learning_rate': 0.8529319723984654, 'n_estimators': 368, 'reg_alpha': 131.81187302014058, 'reg_lambda': 189.57521211636885}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:10:59,034]\u001b[0m Trial 15 finished with value: -2.954618268309289 and parameters: {'max_depth': 15, 'num_leaves': 49, 'learning_rate': 0.5332838973540461, 'n_estimators': 349, 'reg_alpha': 47.08607888807411, 'reg_lambda': 43.42596390164813}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:03,690]\u001b[0m Trial 20 finished with value: -3.270424074220905 and parameters: {'max_depth': 8, 'num_leaves': 37, 'learning_rate': 0.015803538681554492, 'n_estimators': 431, 'reg_alpha': 113232.47669822758, 'reg_lambda': 6042.174534399393}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:11:05,890]\u001b[0m Trial 10 finished with value: -2.8945660070387347 and parameters: {'max_depth': 43, 'num_leaves': 33, 'learning_rate': 0.13425740862048058, 'n_estimators': 414, 'reg_alpha': 9.061879919685056, 'reg_lambda': 141.29796610805334}. Best is trial 7 with value: -2.644852450557234.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:12,212]\u001b[0m Trial 21 finished with value: -2.5686864762387507 and parameters: {'max_depth': 8, 'num_leaves': 42, 'learning_rate': 0.011664279325951089, 'n_estimators': 249, 'reg_alpha': 7025.207896072947, 'reg_lambda': 1.3609201647363403}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:13,087]\u001b[0m Trial 22 finished with value: -2.592171344127009 and parameters: {'max_depth': 22, 'num_leaves': 43, 'learning_rate': 0.01803989650301319, 'n_estimators': 246, 'reg_alpha': 9392.084990530722, 'reg_lambda': 3.258737655004976}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:13,847]\u001b[0m Trial 23 finished with value: -3.2395636887760384 and parameters: {'max_depth': 8, 'num_leaves': 42, 'learning_rate': 0.010256970545018026, 'n_estimators': 255, 'reg_alpha': 9997789.753666257, 'reg_lambda': 1.1256696654075593}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:19,124]\u001b[0m Trial 25 finished with value: -2.6562277923598474 and parameters: {'max_depth': 23, 'num_leaves': 43, 'learning_rate': 0.017038250339683345, 'n_estimators': 223, 'reg_alpha': 12583.749602048276, 'reg_lambda': 1.0168555801760513}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:21,022]\u001b[0m Trial 24 finished with value: -2.6103279978307645 and parameters: {'max_depth': 8, 'num_leaves': 42, 'learning_rate': 0.015343016096944988, 'n_estimators': 239, 'reg_alpha': 10080.705904760967, 'reg_lambda': 1.3631169342511986}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:22,562]\u001b[0m Trial 27 finished with value: -3.2395636887760384 and parameters: {'max_depth': 4, 'num_leaves': 38, 'learning_rate': 0.003961173063250027, 'n_estimators': 193, 'reg_alpha': 259139.16152686466, 'reg_lambda': 0.00420104695795305}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:25,172]\u001b[0m Trial 28 finished with value: -3.202349139197368 and parameters: {'max_depth': 21, 'num_leaves': 35, 'learning_rate': 0.0006216214764909662, 'n_estimators': 98, 'reg_alpha': 20161.402556265977, 'reg_lambda': 2.1144477192744446}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:26,600]\u001b[0m Trial 18 finished with value: -2.6811726849793294 and parameters: {'max_depth': 9, 'num_leaves': 36, 'learning_rate': 0.012633898176624076, 'n_estimators': 415, 'reg_alpha': 74.46713242782815, 'reg_lambda': 1174.91306835303}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:27,413]\u001b[0m Trial 29 finished with value: -3.2395636887760384 and parameters: {'max_depth': 5, 'num_leaves': 42, 'learning_rate': 0.020743746170932317, 'n_estimators': 281, 'reg_alpha': 576450.2104162258, 'reg_lambda': 0.07465552447794702}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:27,976]\u001b[0m Trial 26 finished with value: -2.765440253911189 and parameters: {'max_depth': 10, 'num_leaves': 38, 'learning_rate': 0.003495213670406878, 'n_estimators': 274, 'reg_alpha': 8138.54988207157, 'reg_lambda': 0.019137176275383343}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:30,737]\u001b[0m Trial 19 finished with value: -2.5939961278508665 and parameters: {'max_depth': 8, 'num_leaves': 37, 'learning_rate': 0.017738806180706865, 'n_estimators': 420, 'reg_alpha': 5.0190883409337, 'reg_lambda': 16456.517947914574}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:37,261]\u001b[0m Trial 31 finished with value: -2.8172221265076565 and parameters: {'max_depth': 20, 'num_leaves': 31, 'learning_rate': 0.002491577898704635, 'n_estimators': 254, 'reg_alpha': 6118.325054048532, 'reg_lambda': 0.4119071986375587}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:37,643]\u001b[0m Trial 30 finished with value: -3.175610437194578 and parameters: {'max_depth': 28, 'num_leaves': 42, 'learning_rate': 0.00021447696406038752, 'n_estimators': 266, 'reg_alpha': 4713.9652610433195, 'reg_lambda': 0.11654135229867443}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:45,235]\u001b[0m Trial 32 finished with value: -3.1679166994677335 and parameters: {'max_depth': 28, 'num_leaves': 31, 'learning_rate': 0.00023693501083971508, 'n_estimators': 216, 'reg_alpha': 7.143430032349377, 'reg_lambda': 0.4344240790088304}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:45,650]\u001b[0m Trial 33 finished with value: -3.227395868474141 and parameters: {'max_depth': 28, 'num_leaves': 33, 'learning_rate': 0.00022633881103083713, 'n_estimators': 184, 'reg_alpha': 11.205735354139081, 'reg_lambda': 44157.485249370584}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:56,622]\u001b[0m Trial 36 finished with value: -2.6698695491025974 and parameters: {'max_depth': 12, 'num_leaves': 45, 'learning_rate': 0.06252530795070435, 'n_estimators': 299, 'reg_alpha': 745.6015011045938, 'reg_lambda': 6.003010500775179}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:11:59,510]\u001b[0m Trial 37 finished with value: -2.645845778847688 and parameters: {'max_depth': 12, 'num_leaves': 45, 'learning_rate': 0.04538215209905061, 'n_estimators': 307, 'reg_alpha': 1012.6686218593522, 'reg_lambda': 6.350782847249196}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:03,293]\u001b[0m Trial 34 finished with value: -2.824004226584159 and parameters: {'max_depth': 27, 'num_leaves': 45, 'learning_rate': 0.03490347530425882, 'n_estimators': 210, 'reg_alpha': 5.398934736332756, 'reg_lambda': 4.23216404134559}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:04,306]\u001b[0m Trial 35 finished with value: -2.827899605654001 and parameters: {'max_depth': 12, 'num_leaves': 45, 'learning_rate': 0.03901287970748259, 'n_estimators': 212, 'reg_alpha': 6.400884186256756, 'reg_lambda': 4.720286022677763}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:08,553]\u001b[0m Trial 40 finished with value: -3.056850071104847 and parameters: {'max_depth': 5, 'num_leaves': 40, 'learning_rate': 0.007472673304933307, 'n_estimators': 106, 'reg_alpha': 0.0035068215222189476, 'reg_lambda': 49041.68938809477}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:09,142]\u001b[0m Trial 41 finished with value: -3.1149481282274114 and parameters: {'max_depth': 5, 'num_leaves': 39, 'learning_rate': 0.009811148368437946, 'n_estimators': 102, 'reg_alpha': 0.00092001068970668, 'reg_lambda': 113994.05627574783}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:09,817]\u001b[0m Trial 38 finished with value: -2.6482059782214207 and parameters: {'max_depth': 5, 'num_leaves': 40, 'learning_rate': 0.02680332087271005, 'n_estimators': 308, 'reg_alpha': 0.006733977594257309, 'reg_lambda': 87560.83400162903}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:11,209]\u001b[0m Trial 39 finished with value: -2.9899302878386287 and parameters: {'max_depth': 5, 'num_leaves': 40, 'learning_rate': 0.005996126831602254, 'n_estimators': 235, 'reg_alpha': 0.004524190323732267, 'reg_lambda': 61636.76873511366}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:12,313]\u001b[0m Trial 43 finished with value: -3.10903953386884 and parameters: {'max_depth': 1, 'num_leaves': 29, 'learning_rate': 0.0013376092931891778, 'n_estimators': 337, 'reg_alpha': 50809.19749790556, 'reg_lambda': 995.1738036446042}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:13,034]\u001b[0m Trial 44 finished with value: -3.5938012294935042 and parameters: {'max_depth': 2, 'num_leaves': 47, 'learning_rate': 0.07562119677290897, 'n_estimators': 329, 'reg_alpha': 58954.86608520879, 'reg_lambda': 497.63761099814417}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:12:14,997]\u001b[0m Trial 45 finished with value: -3.728009631928313 and parameters: {'max_depth': 1, 'num_leaves': 47, 'learning_rate': 0.1673380878588861, 'n_estimators': 459, 'reg_alpha': 56611.69383593424, 'reg_lambda': 1020.6586750164307}. Best is trial 21 with value: -2.5686864762387507.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:16,869]\u001b[0m Trial 46 finished with value: -2.494433636568858 and parameters: {'max_depth': 2, 'num_leaves': 47, 'learning_rate': 0.10066346315883752, 'n_estimators': 440, 'reg_alpha': 1660.5830782888745, 'reg_lambda': 11.15252161109657}. Best is trial 46 with value: -2.494433636568858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:17,469]\u001b[0m Trial 49 finished with value: -2.5279784107614085 and parameters: {'max_depth': 33, 'num_leaves': 6, 'learning_rate': 0.2137156483032686, 'n_estimators': 12, 'reg_alpha': 1852.9832193627615, 'reg_lambda': 17.30610702045261}. Best is trial 46 with value: -2.494433636568858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:17,495]\u001b[0m Trial 47 finished with value: -2.5860789209984016 and parameters: {'max_depth': 32, 'num_leaves': 47, 'learning_rate': 0.1731946473466055, 'n_estimators': 394, 'reg_alpha': 1972.4753667946768, 'reg_lambda': 25.968274742819425}. Best is trial 46 with value: -2.494433636568858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:24,591]\u001b[0m Trial 48 finished with value: -2.8109534435730166 and parameters: {'max_depth': 17, 'num_leaves': 34, 'learning_rate': 0.06949814631990298, 'n_estimators': 156, 'reg_alpha': 0.7570814357223672, 'reg_lambda': 21.731396447615623}. Best is trial 46 with value: -2.494433636568858.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:29,926]\u001b[0m Trial 42 finished with value: -2.846932361174206 and parameters: {'max_depth': 18, 'num_leaves': 40, 'learning_rate': 0.0013857535698845393, 'n_estimators': 337, 'reg_alpha': 0.8983898208769299, 'reg_lambda': 1690.3018712530752}. Best is trial 46 with value: -2.494433636568858.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:12:33,048]\u001b[0m A new study created in memory with name: no-name-ea0886f8-f82d-4752-bf54-50b69ea78f4d\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:36,326]\u001b[0m Trial 2 finished with value: -2.3282517572088137 and parameters: {'max_depth': 47, 'num_leaves': 15, 'learning_rate': 0.027018665350508023, 'n_estimators': 431, 'reg_alpha': 200349.8027393253, 'reg_lambda': 80910.59468438341}. Best is trial 2 with value: -2.3282517572088137.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:40,800]\u001b[0m Trial 1 finished with value: -2.3282522632365295 and parameters: {'max_depth': 42, 'num_leaves': 32, 'learning_rate': 2.201538093960685e-05, 'n_estimators': 170, 'reg_alpha': 0.25086480350844226, 'reg_lambda': 2941389.2358706114}. Best is trial 2 with value: -2.3282517572088137.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:42,259]\u001b[0m Trial 4 finished with value: -2.328240108854622 and parameters: {'max_depth': 2, 'num_leaves': 44, 'learning_rate': 3.3257216738052944e-07, 'n_estimators': 458, 'reg_alpha': 1.1438765791078122e-07, 'reg_lambda': 1.0255570436391718e-06}. Best is trial 4 with value: -2.328240108854622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:43,466]\u001b[0m Trial 5 finished with value: -2.3282517572088137 and parameters: {'max_depth': 15, 'num_leaves': 34, 'learning_rate': 5.5041720915290376e-06, 'n_estimators': 361, 'reg_alpha': 1365245.0246452868, 'reg_lambda': 1.3092361043922083}. Best is trial 4 with value: -2.328240108854622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:51,961]\u001b[0m Trial 3 finished with value: -2.638469277069116 and parameters: {'max_depth': 23, 'num_leaves': 15, 'learning_rate': 0.12793448794664564, 'n_estimators': 431, 'reg_alpha': 0.016564271158011287, 'reg_lambda': 4.988748756921138e-07}. Best is trial 4 with value: -2.328240108854622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:54,228]\u001b[0m Trial 7 finished with value: -2.3282984515048706 and parameters: {'max_depth': 28, 'num_leaves': 28, 'learning_rate': 0.00017523078595529327, 'n_estimators': 230, 'reg_alpha': 3.8152107630852205e-06, 'reg_lambda': 376061.50859086466}. Best is trial 4 with value: -2.328240108854622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:54,708]\u001b[0m Trial 0 finished with value: -2.6013100067331334 and parameters: {'max_depth': 27, 'num_leaves': 20, 'learning_rate': 0.048100044379914435, 'n_estimators': 442, 'reg_alpha': 0.04313971321609245, 'reg_lambda': 2.0326256212412948}. Best is trial 4 with value: -2.328240108854622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:57,261]\u001b[0m Trial 10 finished with value: -2.3282517572088137 and parameters: {'max_depth': 37, 'num_leaves': 5, 'learning_rate': 0.0014910299203627574, 'n_estimators': 408, 'reg_alpha': 5908797.462220012, 'reg_lambda': 174214.80225886015}. Best is trial 4 with value: -2.328240108854622.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:57,739]\u001b[0m Trial 6 finished with value: -2.3279525957541054 and parameters: {'max_depth': 21, 'num_leaves': 26, 'learning_rate': 4.572701878908683e-06, 'n_estimators': 197, 'reg_alpha': 0.057601996497149914, 'reg_lambda': 201.63326153524795}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:12:59,968]\u001b[0m Trial 12 finished with value: -2.3282517572088137 and parameters: {'max_depth': 10, 'num_leaves': 26, 'learning_rate': 0.9871654629362818, 'n_estimators': 299, 'reg_alpha': 1006882.0288777491, 'reg_lambda': 3687.5925965139127}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:02,025]\u001b[0m Trial 13 finished with value: -2.32825144946747 and parameters: {'max_depth': 16, 'num_leaves': 46, 'learning_rate': 1.0318287999940728e-07, 'n_estimators': 11, 'reg_alpha': 105.98736029266364, 'reg_lambda': 399.74353511628254}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:04,622]\u001b[0m Trial 11 finished with value: -2.6756321960311262 and parameters: {'max_depth': 30, 'num_leaves': 5, 'learning_rate': 0.1639745004969754, 'n_estimators': 460, 'reg_alpha': 1.802234948092607e-07, 'reg_lambda': 2.0714258955605787}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:05,737]\u001b[0m Trial 9 finished with value: -2.328525226821877 and parameters: {'max_depth': 0, 'num_leaves': 33, 'learning_rate': 0.000270945757074856, 'n_estimators': 172, 'reg_alpha': 0.06403164399175168, 'reg_lambda': 48596.81632711995}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:17,417]\u001b[0m Trial 16 finished with value: -2.328240260319594 and parameters: {'max_depth': -1, 'num_leaves': 49, 'learning_rate': 3.69886646818024e-07, 'n_estimators': 89, 'reg_alpha': 6.654867847759606e-05, 'reg_lambda': 3.6420322862158755e-05}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:20,561]\u001b[0m Trial 14 finished with value: -2.3282338107766587 and parameters: {'max_depth': 0, 'num_leaves': 46, 'learning_rate': 3.6600860903459623e-07, 'n_estimators': 141, 'reg_alpha': 2.7127999316188775e-07, 'reg_lambda': 6.34795156874714e-05}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:23,667]\u001b[0m Trial 15 finished with value: -2.3282339886451187 and parameters: {'max_depth': 0, 'num_leaves': 50, 'learning_rate': 3.240766687515018e-07, 'n_estimators': 157, 'reg_alpha': 0.00031352349785216993, 'reg_lambda': 2.298531588211858e-05}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:29,990]\u001b[0m Trial 19 finished with value: -2.3281587380397015 and parameters: {'max_depth': 8, 'num_leaves': 40, 'learning_rate': 3.8351720630558755e-06, 'n_estimators': 70, 'reg_alpha': 36.93455994500964, 'reg_lambda': 0.010626153431320765}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:31,530]\u001b[0m Trial 20 finished with value: -2.3282264061082154 and parameters: {'max_depth': 8, 'num_leaves': 38, 'learning_rate': 5.223892906832474e-06, 'n_estimators': 14, 'reg_alpha': 20.37906580290308, 'reg_lambda': 0.015239952097145472}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:13:32,613]\u001b[0m Trial 18 finished with value: -2.3281565310489523 and parameters: {'max_depth': 8, 'num_leaves': 40, 'learning_rate': 2.47588058981161e-06, 'n_estimators': 110, 'reg_alpha': 0.00011939018163989843, 'reg_lambda': 0.003584646507908757}. Best is trial 6 with value: -2.3279525957541054.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:32,827]\u001b[0m Trial 8 finished with value: -2.322210689571907 and parameters: {'max_depth': -1, 'num_leaves': 45, 'learning_rate': 6.30261094670209e-05, 'n_estimators': 285, 'reg_alpha': 1.9836454727745407e-07, 'reg_lambda': 3.990498428229199e-06}. Best is trial 8 with value: -2.322210689571907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:40,525]\u001b[0m Trial 21 finished with value: -2.3281265508349156 and parameters: {'max_depth': 16, 'num_leaves': 39, 'learning_rate': 4.199820895299237e-06, 'n_estimators': 90, 'reg_alpha': 9.739638916930591, 'reg_lambda': 88.99960944265399}. Best is trial 8 with value: -2.322210689571907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:42,284]\u001b[0m Trial 17 finished with value: -2.3281172316177385 and parameters: {'max_depth': 6, 'num_leaves': 41, 'learning_rate': 1.3805333966213492e-06, 'n_estimators': 303, 'reg_alpha': 0.0002593965982390012, 'reg_lambda': 0.002395591114357132}. Best is trial 8 with value: -2.322210689571907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:51,889]\u001b[0m Trial 23 finished with value: -2.3234518179247328 and parameters: {'max_depth': 18, 'num_leaves': 24, 'learning_rate': 5.238737546680549e-05, 'n_estimators': 268, 'reg_alpha': 0.004142788450671733, 'reg_lambda': 30.264553420539546}. Best is trial 8 with value: -2.322210689571907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:52,711]\u001b[0m Trial 22 finished with value: -2.3248717143347823 and parameters: {'max_depth': 16, 'num_leaves': 26, 'learning_rate': 4.045909810801837e-05, 'n_estimators': 256, 'reg_alpha': 0.001024880789494154, 'reg_lambda': 85.38351334387119}. Best is trial 8 with value: -2.322210689571907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:53,046]\u001b[0m Trial 25 finished with value: -2.325991418434552 and parameters: {'max_depth': 4, 'num_leaves': 24, 'learning_rate': 3.059189178310669e-05, 'n_estimators': 275, 'reg_alpha': 0.0017681264503786203, 'reg_lambda': 1.4469175810071373e-07}. Best is trial 8 with value: -2.322210689571907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:13:55,467]\u001b[0m Trial 24 finished with value: -2.3255061879392693 and parameters: {'max_depth': 18, 'num_leaves': 25, 'learning_rate': 3.5036816834065334e-05, 'n_estimators': 236, 'reg_alpha': 0.0017531047877904868, 'reg_lambda': 94.61268885104326}. Best is trial 8 with value: -2.322210689571907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:07,944]\u001b[0m Trial 26 finished with value: -2.324756693954965 and parameters: {'max_depth': 20, 'num_leaves': 23, 'learning_rate': 4.4469972219674996e-05, 'n_estimators': 230, 'reg_alpha': 0.0042112795180034145, 'reg_lambda': 34.1556019115989}. Best is trial 8 with value: -2.322210689571907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:10,470]\u001b[0m Trial 27 finished with value: -2.324942647179117 and parameters: {'max_depth': 13, 'num_leaves': 20, 'learning_rate': 3.433511449669241e-05, 'n_estimators': 285, 'reg_alpha': 0.003139166534127336, 'reg_lambda': 22.747780402901356}. Best is trial 8 with value: -2.322210689571907.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:12,833]\u001b[0m Trial 29 finished with value: -2.276313280866494 and parameters: {'max_depth': 12, 'num_leaves': 19, 'learning_rate': 0.0009338778245070314, 'n_estimators': 354, 'reg_alpha': 6.282387916907773e-06, 'reg_lambda': 0.11884893689940923}. Best is trial 29 with value: -2.276313280866494.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:13,882]\u001b[0m Trial 28 finished with value: -2.322378212245893 and parameters: {'max_depth': 21, 'num_leaves': 20, 'learning_rate': 5.2542876097015416e-05, 'n_estimators': 335, 'reg_alpha': 8.17558326437421e-06, 'reg_lambda': 8.933326621878386}. Best is trial 29 with value: -2.276313280866494.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:26,070]\u001b[0m Trial 32 finished with value: -2.2776549253352156 and parameters: {'max_depth': 12, 'num_leaves': 14, 'learning_rate': 0.001035202325173261, 'n_estimators': 336, 'reg_alpha': 4.745553440336758e-06, 'reg_lambda': 0.22488081762115592}. Best is trial 29 with value: -2.276313280866494.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:27,988]\u001b[0m Trial 30 finished with value: -2.2765997913869995 and parameters: {'max_depth': 31, 'num_leaves': 19, 'learning_rate': 0.0009355591703463655, 'n_estimators': 345, 'reg_alpha': 5.31221404663378e-06, 'reg_lambda': 0.13631994470079403}. Best is trial 29 with value: -2.276313280866494.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:30,133]\u001b[0m Trial 33 finished with value: -2.2789017991917104 and parameters: {'max_depth': 24, 'num_leaves': 15, 'learning_rate': 0.0011947564397232148, 'n_estimators': 349, 'reg_alpha': 5.476985121711788e-06, 'reg_lambda': 0.17494943302162141}. Best is trial 29 with value: -2.276313280866494.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:32,770]\u001b[0m Trial 31 finished with value: -2.2760238332921343 and parameters: {'max_depth': 34, 'num_leaves': 20, 'learning_rate': 0.0009916143489736384, 'n_estimators': 357, 'reg_alpha': 6.871153313235288e-06, 'reg_lambda': 0.08102681691984419}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:39,221]\u001b[0m Trial 34 finished with value: -2.2784520534596306 and parameters: {'max_depth': 24, 'num_leaves': 14, 'learning_rate': 0.0011497720957741502, 'n_estimators': 339, 'reg_alpha': 4.775408795488884e-06, 'reg_lambda': 0.10877579048867102}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:44,586]\u001b[0m Trial 35 finished with value: -2.279540839058316 and parameters: {'max_depth': 31, 'num_leaves': 13, 'learning_rate': 0.0008989959328517078, 'n_estimators': 382, 'reg_alpha': 2.3716542630829833e-06, 'reg_lambda': 0.6690106445779621}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:45,369]\u001b[0m Trial 36 finished with value: -2.305113313737437 and parameters: {'max_depth': 33, 'num_leaves': 12, 'learning_rate': 0.0016630454661358974, 'n_estimators': 381, 'reg_alpha': 4.17196742807723e-06, 'reg_lambda': 0.10048819956754057}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:47,630]\u001b[0m Trial 37 finished with value: -2.315993070695164 and parameters: {'max_depth': 34, 'num_leaves': 11, 'learning_rate': 0.0017644247996330506, 'n_estimators': 388, 'reg_alpha': 2.3221003066526373e-05, 'reg_lambda': 0.1791893849784711}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:52,170]\u001b[0m Trial 38 finished with value: -2.4357416375098504 and parameters: {'max_depth': 36, 'num_leaves': 11, 'learning_rate': 0.004061097512157925, 'n_estimators': 395, 'reg_alpha': 2.6996536436213077e-05, 'reg_lambda': 0.2375311860996319}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:14:56,805]\u001b[0m Trial 39 finished with value: -2.452348697866822 and parameters: {'max_depth': 36, 'num_leaves': 9, 'learning_rate': 0.004841192337937151, 'n_estimators': 387, 'reg_alpha': 6.865467446384949e-07, 'reg_lambda': 0.08684574855674362}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:15:02,393]\u001b[0m Trial 40 finished with value: -2.5344715611634756 and parameters: {'max_depth': 40, 'num_leaves': 10, 'learning_rate': 0.007191244981831134, 'n_estimators': 492, 'reg_alpha': 3.1305242136350215e-05, 'reg_lambda': 3.454000976683356}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:15:03,464]\u001b[0m Trial 41 finished with value: -2.47151961864882 and parameters: {'max_depth': 42, 'num_leaves': 9, 'learning_rate': 0.004328172047303218, 'n_estimators': 493, 'reg_alpha': 3.371584321630899e-05, 'reg_lambda': 0.0005074028651519887}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:15:15,039]\u001b[0m Trial 42 finished with value: -2.5689039126754367 and parameters: {'max_depth': 46, 'num_leaves': 18, 'learning_rate': 0.012151751150033684, 'n_estimators': 488, 'reg_alpha': 9.879441845159075e-07, 'reg_lambda': 3.7387757193830393}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:15:20,651]\u001b[0m Trial 44 finished with value: -2.2884769153906053 and parameters: {'max_depth': 26, 'num_leaves': 17, 'learning_rate': 0.0005070512015605847, 'n_estimators': 333, 'reg_alpha': 1.1289789614259457e-06, 'reg_lambda': 1.0373223408166243}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:15:21,255]\u001b[0m Trial 45 finished with value: -2.2968234568300763 and parameters: {'max_depth': 25, 'num_leaves': 18, 'learning_rate': 0.0003601577827528753, 'n_estimators': 327, 'reg_alpha': 7.522131313499524e-07, 'reg_lambda': 0.02909703795952272}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:15:23,278]\u001b[0m Trial 43 finished with value: -2.2847416634386284 and parameters: {'max_depth': 45, 'num_leaves': 17, 'learning_rate': 0.00040419588398282746, 'n_estimators': 491, 'reg_alpha': 7.372712657820079e-07, 'reg_lambda': 3.612580804518247}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:15:31,183]\u001b[0m Trial 46 finished with value: -2.292391270823784 and parameters: {'max_depth': 25, 'num_leaves': 16, 'learning_rate': 0.0004457396763536476, 'n_estimators': 323, 'reg_alpha': 1.1199224057826001e-06, 'reg_lambda': 0.02479229584967638}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:15:36,911]\u001b[0m Trial 47 finished with value: -2.3040691649970007 and parameters: {'max_depth': 27, 'num_leaves': 17, 'learning_rate': 0.0002653822341244282, 'n_estimators': 318, 'reg_alpha': 1.0144874830636344e-07, 'reg_lambda': 0.01452403647228842}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:15:45,401]\u001b[0m Trial 49 finished with value: -2.308011601043399 and parameters: {'max_depth': 29, 'num_leaves': 22, 'learning_rate': 0.00015973667087845167, 'n_estimators': 421, 'reg_alpha': 1.1515193094707745e-05, 'reg_lambda': 0.48309545305961454}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:15:48,044]\u001b[0m Trial 48 finished with value: -2.3087777724304512 and parameters: {'max_depth': 28, 'num_leaves': 29, 'learning_rate': 0.0001509070974654123, 'n_estimators': 433, 'reg_alpha': 5.719150520818812e-06, 'reg_lambda': 0.03874453980681915}. Best is trial 31 with value: -2.2760238332921343.\u001b[0m\n",
      " 62%|                       | 10/16 [2:06:16<1:22:57, 829.66s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:15:52,830]\u001b[0m A new study created in memory with name: no-name-464592f7-e207-406b-af40-02cd1d2d786d\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 4.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 895, in fit\n",
      "    super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 1474, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(data,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/optuna/integration/sklearn.py:357: RuntimeWarning: Mean of empty slice\n",
      "  trial.set_user_attr(\"mean_{}\".format(name), np.nanmean(array))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "\u001b[33m[W 2023-04-25 19:15:54,727]\u001b[0m Trial 2 failed with parameters: {'max_depth': 34, 'num_leaves': 46, 'learning_rate': 0.007453219275620868, 'n_estimators': 415, 'reg_alpha': 299787.6343968721, 'reg_lambda': 47.72104636818736} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:15:54,728]\u001b[0m Trial 2 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:15:55,835]\u001b[0m Trial 4 failed with parameters: {'max_depth': 3, 'num_leaves': 25, 'learning_rate': 0.011724771371118114, 'n_estimators': 70, 'reg_alpha': 2.4123078735988242e-05, 'reg_lambda': 2430.4508658857444} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:15:55,837]\u001b[0m Trial 4 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:15:57,534]\u001b[0m Trial 0 failed with parameters: {'max_depth': 43, 'num_leaves': 18, 'learning_rate': 2.853813332794064e-06, 'n_estimators': 385, 'reg_alpha': 904.6718817300339, 'reg_lambda': 0.6375342281515478} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:15:57,534]\u001b[0m Trial 0 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:15:59,060]\u001b[0m Trial 5 failed with parameters: {'max_depth': 42, 'num_leaves': 50, 'learning_rate': 0.0008678914240222015, 'n_estimators': 268, 'reg_alpha': 1215.9294556423943, 'reg_lambda': 1.627064890894763e-07} because of the following error: The value nan is not acceptable..\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-04-25 19:15:59,060]\u001b[0m Trial 5 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:04,086]\u001b[0m Trial 1 failed with parameters: {'max_depth': 39, 'num_leaves': 24, 'learning_rate': 0.006392680019668673, 'n_estimators': 298, 'reg_alpha': 0.16266216047945478, 'reg_lambda': 149.77327376844588} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:04,087]\u001b[0m Trial 1 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:04,250]\u001b[0m Trial 8 failed with parameters: {'max_depth': 31, 'num_leaves': 46, 'learning_rate': 0.00024084931581374957, 'n_estimators': 40, 'reg_alpha': 82116.15260928537, 'reg_lambda': 2.1781779826566213e-05} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:04,251]\u001b[0m Trial 8 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:07,901]\u001b[0m Trial 7 failed with parameters: {'max_depth': 30, 'num_leaves': 16, 'learning_rate': 0.013538453148650442, 'n_estimators': 298, 'reg_alpha': 1.704115660543994e-06, 'reg_lambda': 146.43505009685677} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:07,902]\u001b[0m Trial 7 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:09,108]\u001b[0m Trial 10 failed with parameters: {'max_depth': 35, 'num_leaves': 24, 'learning_rate': 0.000995878656290743, 'n_estimators': 362, 'reg_alpha': 3576990.153621561, 'reg_lambda': 1.4646838034072337e-06} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:09,110]\u001b[0m Trial 10 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:13,816]\u001b[0m Trial 6 failed with parameters: {'max_depth': 31, 'num_leaves': 37, 'learning_rate': 0.0007936784638311329, 'n_estimators': 239, 'reg_alpha': 2.8988951026118573e-06, 'reg_lambda': 0.007426562222264834} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:13,817]\u001b[0m Trial 6 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:17,565]\u001b[0m Trial 9 failed with parameters: {'max_depth': 39, 'num_leaves': 19, 'learning_rate': 0.00010245719678565697, 'n_estimators': 459, 'reg_alpha': 10.195096714999561, 'reg_lambda': 0.011452356506242777} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:17,566]\u001b[0m Trial 9 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:19,119]\u001b[0m Trial 12 failed with parameters: {'max_depth': 16, 'num_leaves': 19, 'learning_rate': 7.837994438836568e-07, 'n_estimators': 148, 'reg_alpha': 1.8981541209340625e-06, 'reg_lambda': 0.0007683770117865942} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:19,119]\u001b[0m Trial 12 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:20,864]\u001b[0m Trial 3 failed with parameters: {'max_depth': 14, 'num_leaves': 35, 'learning_rate': 0.0031603543083678558, 'n_estimators': 443, 'reg_alpha': 3.560444401473455, 'reg_lambda': 5.347314342727946} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:20,865]\u001b[0m Trial 3 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:22,382]\u001b[0m Trial 15 failed with parameters: {'max_depth': 1, 'num_leaves': 7, 'learning_rate': 0.07693469652518421, 'n_estimators': 309, 'reg_alpha': 2.2692530279971005e-06, 'reg_lambda': 1.7654603520226846} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:22,382]\u001b[0m Trial 15 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:24,307]\u001b[0m Trial 13 failed with parameters: {'max_depth': 8, 'num_leaves': 39, 'learning_rate': 0.002259721276750237, 'n_estimators': 110, 'reg_alpha': 5.735774195394961e-07, 'reg_lambda': 4.849496908742895e-07} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:24,307]\u001b[0m Trial 13 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:24,688]\u001b[0m Trial 11 failed with parameters: {'max_depth': 0, 'num_leaves': 40, 'learning_rate': 9.103199638402968e-05, 'n_estimators': 214, 'reg_alpha': 4.172584812230794e-06, 'reg_lambda': 1.577159434309442e-06} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:24,689]\u001b[0m Trial 11 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:25,446]\u001b[0m Trial 16 failed with parameters: {'max_depth': 40, 'num_leaves': 5, 'learning_rate': 3.264662842226735e-05, 'n_estimators': 288, 'reg_alpha': 84.73230079765949, 'reg_lambda': 30.064679288904927} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:25,447]\u001b[0m Trial 16 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:26,480]\u001b[0m Trial 18 failed with parameters: {'max_depth': 5, 'num_leaves': 37, 'learning_rate': 0.0005484208682484733, 'n_estimators': 497, 'reg_alpha': 6338.692546732256, 'reg_lambda': 5.406781639049878} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:26,481]\u001b[0m Trial 18 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:27,172]\u001b[0m Trial 17 failed with parameters: {'max_depth': 46, 'num_leaves': 8, 'learning_rate': 1.0957553778151109e-07, 'n_estimators': 234, 'reg_alpha': 1145.7730558059548, 'reg_lambda': 2.1225183190849094e-07} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:27,173]\u001b[0m Trial 17 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:27,813]\u001b[0m Trial 21 failed with parameters: {'max_depth': 6, 'num_leaves': 20, 'learning_rate': 4.496621173613358e-07, 'n_estimators': 16, 'reg_alpha': 6.825637254942302e-07, 'reg_lambda': 8.893161273033233e-07} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:27,814]\u001b[0m Trial 21 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:28,038]\u001b[0m Trial 22 failed with parameters: {'max_depth': 1, 'num_leaves': 5, 'learning_rate': 0.03634812495109023, 'n_estimators': 47, 'reg_alpha': 2.888924515569718e-06, 'reg_lambda': 44.010439821407005} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:28,038]\u001b[0m Trial 22 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:28,128]\u001b[0m Trial 23 failed with parameters: {'max_depth': 4, 'num_leaves': 26, 'learning_rate': 7.172091591266343e-05, 'n_estimators': 13, 'reg_alpha': 43578.00902387214, 'reg_lambda': 1559.4708037670823} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:28,129]\u001b[0m Trial 23 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:28,447]\u001b[0m Trial 24 failed with parameters: {'max_depth': 13, 'num_leaves': 47, 'learning_rate': 0.0004077367378347871, 'n_estimators': 97, 'reg_alpha': 2671.2816221593703, 'reg_lambda': 2.934126275038656e-07} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:28,448]\u001b[0m Trial 24 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:29,836]\u001b[0m Trial 19 failed with parameters: {'max_depth': 19, 'num_leaves': 8, 'learning_rate': 5.817377591715012e-07, 'n_estimators': 293, 'reg_alpha': 164.01480448354994, 'reg_lambda': 0.01471797218499585} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:29,837]\u001b[0m Trial 19 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:29,841]\u001b[0m Trial 25 failed with parameters: {'max_depth': 3, 'num_leaves': 11, 'learning_rate': 0.003986426716431986, 'n_estimators': 499, 'reg_alpha': 28964.79217919303, 'reg_lambda': 605.9682609911196} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:29,842]\u001b[0m Trial 25 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:36,145]\u001b[0m Trial 20 failed with parameters: {'max_depth': 9, 'num_leaves': 18, 'learning_rate': 4.732655129157711e-06, 'n_estimators': 259, 'reg_alpha': 4.995948861907795e-06, 'reg_lambda': 6.625624817211103e-06} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:36,145]\u001b[0m Trial 20 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:37,033]\u001b[0m Trial 14 failed with parameters: {'max_depth': 13, 'num_leaves': 31, 'learning_rate': 0.0002210139839616175, 'n_estimators': 313, 'reg_alpha': 6.51556431041102, 'reg_lambda': 3.590102098846083e-06} because of the following error: The value nan is not acceptable..\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-04-25 19:16:37,033]\u001b[0m Trial 14 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:37,568]\u001b[0m Trial 27 failed with parameters: {'max_depth': 28, 'num_leaves': 13, 'learning_rate': 3.6223723043475004e-07, 'n_estimators': 331, 'reg_alpha': 0.023385615235125962, 'reg_lambda': 0.022572264649466055} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:37,569]\u001b[0m Trial 27 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:37,981]\u001b[0m Trial 28 failed with parameters: {'max_depth': 35, 'num_leaves': 26, 'learning_rate': 3.144000801054058e-07, 'n_estimators': 159, 'reg_alpha': 1184.0914043663722, 'reg_lambda': 17.460360557155383} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:37,982]\u001b[0m Trial 28 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:40,950]\u001b[0m Trial 30 failed with parameters: {'max_depth': 5, 'num_leaves': 10, 'learning_rate': 0.0002295501852859809, 'n_estimators': 208, 'reg_alpha': 0.009477288049520397, 'reg_lambda': 0.023488155862339048} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:40,952]\u001b[0m Trial 30 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:41,242]\u001b[0m Trial 32 failed with parameters: {'max_depth': 35, 'num_leaves': 11, 'learning_rate': 2.2458383651374954e-06, 'n_estimators': 90, 'reg_alpha': 1501724.8474933866, 'reg_lambda': 4.3653477912221547e-05} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:41,243]\u001b[0m Trial 32 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:42,135]\u001b[0m Trial 33 failed with parameters: {'max_depth': 28, 'num_leaves': 42, 'learning_rate': 1.3942885391510414e-06, 'n_estimators': 276, 'reg_alpha': 264010.0105752196, 'reg_lambda': 1037.026535544211} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:42,136]\u001b[0m Trial 33 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:42,468]\u001b[0m Trial 34 failed with parameters: {'max_depth': 33, 'num_leaves': 25, 'learning_rate': 0.0027091338028720283, 'n_estimators': 104, 'reg_alpha': 2101.013445248219, 'reg_lambda': 6116543.365589668} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:42,469]\u001b[0m Trial 34 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:43,905]\u001b[0m Trial 26 failed with parameters: {'max_depth': 21, 'num_leaves': 48, 'learning_rate': 2.173191441445879e-07, 'n_estimators': 165, 'reg_alpha': 2.2571314698422715, 'reg_lambda': 0.0368808184654284} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:43,906]\u001b[0m Trial 26 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:44,925]\u001b[0m Trial 35 failed with parameters: {'max_depth': 23, 'num_leaves': 34, 'learning_rate': 1.2122394619566774e-05, 'n_estimators': 183, 'reg_alpha': 381.38879781310675, 'reg_lambda': 5.992817726600818} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:44,925]\u001b[0m Trial 35 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:47,199]\u001b[0m Trial 29 failed with parameters: {'max_depth': 17, 'num_leaves': 12, 'learning_rate': 0.26171073180449017, 'n_estimators': 465, 'reg_alpha': 0.09799774080590028, 'reg_lambda': 0.03045129748739211} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:47,200]\u001b[0m Trial 29 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:47,215]\u001b[0m Trial 31 failed with parameters: {'max_depth': 5, 'num_leaves': 41, 'learning_rate': 0.25834935073965254, 'n_estimators': 238, 'reg_alpha': 4.800750021456636e-07, 'reg_lambda': 1731.7593121069335} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:47,217]\u001b[0m Trial 31 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:48,505]\u001b[0m Trial 38 failed with parameters: {'max_depth': 24, 'num_leaves': 24, 'learning_rate': 0.0001025488656495576, 'n_estimators': 421, 'reg_alpha': 877653.3480353259, 'reg_lambda': 1309.306070421208} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:48,506]\u001b[0m Trial 38 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:48,851]\u001b[0m Trial 39 failed with parameters: {'max_depth': 35, 'num_leaves': 14, 'learning_rate': 1.9132389693894015e-05, 'n_estimators': 491, 'reg_alpha': 7327818.96121908, 'reg_lambda': 89399.89011114436} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:48,852]\u001b[0m Trial 39 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:49,126]\u001b[0m Trial 41 failed with parameters: {'max_depth': 28, 'num_leaves': 43, 'learning_rate': 0.019012277389700145, 'n_estimators': 41, 'reg_alpha': 950207.3075391857, 'reg_lambda': 45304.423332420236} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:49,127]\u001b[0m Trial 41 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:49,343]\u001b[0m Trial 36 failed with parameters: {'max_depth': 32, 'num_leaves': 24, 'learning_rate': 0.005702463897481081, 'n_estimators': 388, 'reg_alpha': 430.818795641209, 'reg_lambda': 87.26059635659368} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:49,344]\u001b[0m Trial 36 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:49,472]\u001b[0m Trial 42 failed with parameters: {'max_depth': 2, 'num_leaves': 27, 'learning_rate': 3.6422224091377893e-06, 'n_estimators': 83, 'reg_alpha': 15025.788568482207, 'reg_lambda': 1.604426169664853} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:49,472]\u001b[0m Trial 42 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:49,824]\u001b[0m Trial 40 failed with parameters: {'max_depth': 30, 'num_leaves': 48, 'learning_rate': 0.01641387778649577, 'n_estimators': 353, 'reg_alpha': 279518.9722100521, 'reg_lambda': 0.03285606100682542} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:49,825]\u001b[0m Trial 40 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:50,203]\u001b[0m Trial 44 failed with parameters: {'max_depth': 2, 'num_leaves': 44, 'learning_rate': 0.2267472091577657, 'n_estimators': 95, 'reg_alpha': 0.00029390233456173283, 'reg_lambda': 1.6500163642830958e-07} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:50,204]\u001b[0m Trial 44 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:50,685]\u001b[0m Trial 45 failed with parameters: {'max_depth': 23, 'num_leaves': 8, 'learning_rate': 0.006904984519318236, 'n_estimators': 56, 'reg_alpha': 0.0010798102091993556, 'reg_lambda': 34341.106567268806} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:50,686]\u001b[0m Trial 45 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:53,188]\u001b[0m Trial 47 failed with parameters: {'max_depth': 7, 'num_leaves': 14, 'learning_rate': 2.9636655264098002e-06, 'n_estimators': 113, 'reg_alpha': 1.9600604917060744, 'reg_lambda': 13832.371595249733} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:53,189]\u001b[0m Trial 47 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:53,859]\u001b[0m Trial 48 failed with parameters: {'max_depth': 7, 'num_leaves': 45, 'learning_rate': 1.06319806257873e-05, 'n_estimators': 172, 'reg_alpha': 2298.8087507404093, 'reg_lambda': 1.5749863813309478e-05} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:53,861]\u001b[0m Trial 48 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:55,067]\u001b[0m Trial 43 failed with parameters: {'max_depth': 32, 'num_leaves': 27, 'learning_rate': 0.0032243284771287873, 'n_estimators': 306, 'reg_alpha': 0.010811035360628655, 'reg_lambda': 5671003.361987601} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:55,067]\u001b[0m Trial 43 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:58,614]\u001b[0m Trial 37 failed with parameters: {'max_depth': 26, 'num_leaves': 29, 'learning_rate': 1.0086975427191021e-05, 'n_estimators': 332, 'reg_alpha': 4.322391203131511e-07, 'reg_lambda': 0.0062303120245644685} because of the following error: The value nan is not acceptable..\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-04-25 19:16:58,614]\u001b[0m Trial 37 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:58,920]\u001b[0m Trial 49 failed with parameters: {'max_depth': 18, 'num_leaves': 32, 'learning_rate': 4.7324632024385325e-05, 'n_estimators': 113, 'reg_alpha': 2.4125593156989084e-06, 'reg_lambda': 0.0007405622003293433} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:16:58,921]\u001b[0m Trial 49 failed with value nan.\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:17:01,985]\u001b[0m Trial 46 failed with parameters: {'max_depth': 13, 'num_leaves': 34, 'learning_rate': 7.058548068520509e-07, 'n_estimators': 322, 'reg_alpha': 0.0001674754931054207, 'reg_lambda': 9.519724504145181e-07} because of the following error: The value nan is not acceptable..\u001b[0m\n",
      "\u001b[33m[W 2023-04-25 19:17:01,986]\u001b[0m Trial 46 failed with value nan.\u001b[0m\n",
      "\u001b[31m[E 2023-04-25 19:17:01,987]\u001b[0m No trials are completed yet.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/optuna/integration/sklearn.py\", line 788, in _refit\n",
      "    self.best_estimator_.set_params(**self.study_.best_params)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/optuna/study/study.py\", line 116, in best_params\n",
      "    return self.best_trial.params\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/optuna/study/study.py\", line 159, in best_trial\n",
      "    return copy.deepcopy(self._storage.get_best_trial(self._study_id))\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/optuna/storages/_in_memory.py\", line 250, in get_best_trial\n",
      "    raise ValueError(\"No trials are completed yet.\")\n",
      "ValueError: No trials are completed yet.\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:17:04,902]\u001b[0m A new study created in memory with name: no-name-3285d83d-5ccf-4395-bd8e-b3968423c7e1\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:06,067]\u001b[0m Trial 2 finished with value: -2.050330740686216 and parameters: {'max_depth': 1, 'num_leaves': 27, 'learning_rate': 0.05859855710213612, 'n_estimators': 119, 'reg_alpha': 37.004315573138854, 'reg_lambda': 2129430.0091077667}. Best is trial 2 with value: -2.050330740686216.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:16,794]\u001b[0m Trial 1 finished with value: -2.0941234942562565 and parameters: {'max_depth': 21, 'num_leaves': 24, 'learning_rate': 3.251958700281163e-05, 'n_estimators': 178, 'reg_alpha': 0.12218182549312932, 'reg_lambda': 0.13490277142697818}. Best is trial 2 with value: -2.050330740686216.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:20,723]\u001b[0m Trial 0 finished with value: -2.0598050410348088 and parameters: {'max_depth': 43, 'num_leaves': 26, 'learning_rate': 0.00011972133859913753, 'n_estimators': 266, 'reg_alpha': 2.6376758650999697, 'reg_lambda': 4.1140063741522114e-05}. Best is trial 2 with value: -2.050330740686216.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:21,451]\u001b[0m Trial 3 finished with value: -2.019010389465177 and parameters: {'max_depth': 31, 'num_leaves': 45, 'learning_rate': 0.0004788210655166949, 'n_estimators': 133, 'reg_alpha': 1.5265084616988107e-07, 'reg_lambda': 1.0571052227906014e-07}. Best is trial 3 with value: -2.019010389465177.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:22,220]\u001b[0m Trial 6 finished with value: -2.1019172556277987 and parameters: {'max_depth': 47, 'num_leaves': 14, 'learning_rate': 1.1095437450242112e-07, 'n_estimators': 35, 'reg_alpha': 0.12243741047249444, 'reg_lambda': 0.3996303842411942}. Best is trial 3 with value: -2.019010389465177.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:24,177]\u001b[0m Trial 8 finished with value: -2.100207621914385 and parameters: {'max_depth': 18, 'num_leaves': 6, 'learning_rate': 1.565478693805376e-05, 'n_estimators': 82, 'reg_alpha': 8.091015575972736e-06, 'reg_lambda': 2.4989785335855624e-06}. Best is trial 3 with value: -2.019010389465177.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:26,988]\u001b[0m Trial 4 finished with value: -2.101817494609269 and parameters: {'max_depth': 15, 'num_leaves': 43, 'learning_rate': 6.06312062829757e-06, 'n_estimators': 480, 'reg_alpha': 3.177199314676996e-07, 'reg_lambda': 471405.1581126577}. Best is trial 3 with value: -2.019010389465177.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:29,219]\u001b[0m Trial 10 finished with value: -2.0901308842349478 and parameters: {'max_depth': 0, 'num_leaves': 6, 'learning_rate': 9.563332603293956e-05, 'n_estimators': 93, 'reg_alpha': 0.104765732062174, 'reg_lambda': 6.237053748522972e-05}. Best is trial 3 with value: -2.019010389465177.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:31,975]\u001b[0m Trial 7 finished with value: -2.1014446162023575 and parameters: {'max_depth': 40, 'num_leaves': 8, 'learning_rate': 5.727783391169982e-05, 'n_estimators': 454, 'reg_alpha': 1381.4496944364148, 'reg_lambda': 885570.2788727237}. Best is trial 3 with value: -2.019010389465177.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:33,961]\u001b[0m Trial 9 finished with value: -2.053310591617752 and parameters: {'max_depth': 13, 'num_leaves': 8, 'learning_rate': 0.005591507155527609, 'n_estimators': 493, 'reg_alpha': 0.00037336742174213106, 'reg_lambda': 944997.4266520952}. Best is trial 3 with value: -2.019010389465177.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:35,524]\u001b[0m Trial 13 finished with value: -2.101922446188127 and parameters: {'max_depth': 29, 'num_leaves': 43, 'learning_rate': 0.9772126882557995, 'n_estimators': 302, 'reg_alpha': 3144235.2183289467, 'reg_lambda': 1.0065523374047548e-07}. Best is trial 3 with value: -2.019010389465177.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:39,189]\u001b[0m Trial 5 finished with value: -2.0709533726205955 and parameters: {'max_depth': 0, 'num_leaves': 26, 'learning_rate': 0.00047883373544932813, 'n_estimators': 459, 'reg_alpha': 0.0003944629868303852, 'reg_lambda': 107596.73852543453}. Best is trial 3 with value: -2.019010389465177.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:39,462]\u001b[0m Trial 12 finished with value: -1.9801475787498628 and parameters: {'max_depth': 15, 'num_leaves': 28, 'learning_rate': 0.0010258780333188757, 'n_estimators': 261, 'reg_alpha': 11981.920148595655, 'reg_lambda': 193.65144167413757}. Best is trial 12 with value: -1.9801475787498628.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:48,752]\u001b[0m Trial 11 finished with value: -2.055228991297241 and parameters: {'max_depth': 23, 'num_leaves': 31, 'learning_rate': 0.00015226065831349466, 'n_estimators': 254, 'reg_alpha': 5.142688896127298e-06, 'reg_lambda': 1260.5490661711017}. Best is trial 12 with value: -1.9801475787498628.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:51,650]\u001b[0m Trial 17 finished with value: -2.26432850111027 and parameters: {'max_depth': 31, 'num_leaves': 50, 'learning_rate': 0.0016757230206999867, 'n_estimators': 362, 'reg_alpha': 49124.534037349986, 'reg_lambda': 57.19708389424741}. Best is trial 12 with value: -1.9801475787498628.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:54,183]\u001b[0m Trial 14 finished with value: -1.4752414437580361 and parameters: {'max_depth': 31, 'num_leaves': 50, 'learning_rate': 0.009698749894079099, 'n_estimators': 171, 'reg_alpha': 0.0004759656344833566, 'reg_lambda': 84.79169935038242}. Best is trial 14 with value: -1.4752414437580361.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:54,496]\u001b[0m Trial 15 finished with value: -1.4537701949928041 and parameters: {'max_depth': 32, 'num_leaves': 50, 'learning_rate': 0.01700411588369522, 'n_estimators': 119, 'reg_alpha': 2.1940299484239624e-07, 'reg_lambda': 441.6834156209737}. Best is trial 15 with value: -1.4537701949928041.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:55,248]\u001b[0m Trial 19 finished with value: -2.101922446188127 and parameters: {'max_depth': 8, 'num_leaves': 35, 'learning_rate': 0.011418699118505592, 'n_estimators': 194, 'reg_alpha': 9584206.759335618, 'reg_lambda': 25.92196941478784}. Best is trial 15 with value: -1.4537701949928041.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:55,321]\u001b[0m Trial 16 finished with value: -1.5374923869304655 and parameters: {'max_depth': 31, 'num_leaves': 37, 'learning_rate': 0.0021513281540124734, 'n_estimators': 358, 'reg_alpha': 1089.414855028463, 'reg_lambda': 37.558692399598414}. Best is trial 15 with value: -1.4537701949928041.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:17:55,675]\u001b[0m Trial 21 finished with value: -1.9783616003535327 and parameters: {'max_depth': 36, 'num_leaves': 50, 'learning_rate': 0.05975096548796008, 'n_estimators': 3, 'reg_alpha': 0.002143336900904202, 'reg_lambda': 10405.123190322664}. Best is trial 15 with value: -1.4537701949928041.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:17:58,654]\u001b[0m Trial 22 finished with value: -1.462227901377941 and parameters: {'max_depth': 37, 'num_leaves': 50, 'learning_rate': 0.05181181576875393, 'n_estimators': 30, 'reg_alpha': 0.0008095180635873451, 'reg_lambda': 6010.220767318185}. Best is trial 15 with value: -1.4537701949928041.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:03,319]\u001b[0m Trial 18 finished with value: -1.4503906125177555 and parameters: {'max_depth': 9, 'num_leaves': 34, 'learning_rate': 0.007128031490263916, 'n_estimators': 182, 'reg_alpha': 476.8209530187218, 'reg_lambda': 0.004355443657601004}. Best is trial 18 with value: -1.4503906125177555.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:03,975]\u001b[0m Trial 23 finished with value: -1.4378827244419317 and parameters: {'max_depth': 36, 'num_leaves': 20, 'learning_rate': 0.0284762482857111, 'n_estimators': 171, 'reg_alpha': 9.33491805908978e-06, 'reg_lambda': 4542.137210846443}. Best is trial 23 with value: -1.4378827244419317.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:08,118]\u001b[0m Trial 25 finished with value: -1.451077429455408 and parameters: {'max_depth': 37, 'num_leaves': 37, 'learning_rate': 0.049240681424642024, 'n_estimators': 50, 'reg_alpha': 1.2194052716147234e-05, 'reg_lambda': 13990.35558407589}. Best is trial 23 with value: -1.4378827244419317.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:12,583]\u001b[0m Trial 26 finished with value: -1.6219265520089576 and parameters: {'max_depth': 26, 'num_leaves': 17, 'learning_rate': 0.21687894011410516, 'n_estimators': 206, 'reg_alpha': 3.9702632175539526e-06, 'reg_lambda': 0.022424467735574796}. Best is trial 23 with value: -1.4378827244419317.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:14,757]\u001b[0m Trial 20 finished with value: -1.5607828255883405 and parameters: {'max_depth': 37, 'num_leaves': 39, 'learning_rate': 0.021473715336063286, 'n_estimators': 184, 'reg_alpha': 0.0002893581165902454, 'reg_lambda': 7.781337959611344}. Best is trial 23 with value: -1.4378827244419317.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:16,334]\u001b[0m Trial 28 finished with value: -1.632395749054076 and parameters: {'max_depth': 46, 'num_leaves': 20, 'learning_rate': 0.4178686865049429, 'n_estimators': 74, 'reg_alpha': 2.9689232900466802e-05, 'reg_lambda': 2.3077541165905906}. Best is trial 23 with value: -1.4378827244419317.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:17,506]\u001b[0m Trial 24 finished with value: -1.4010866576278003 and parameters: {'max_depth': 37, 'num_leaves': 46, 'learning_rate': 0.02945291760309041, 'n_estimators': 169, 'reg_alpha': 1.6908951193885316e-05, 'reg_lambda': 9531.26755515047}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:17,647]\u001b[0m Trial 29 finished with value: -2.101391814796483 and parameters: {'max_depth': 8, 'num_leaves': 20, 'learning_rate': 0.004165823566940599, 'n_estimators': 69, 'reg_alpha': 0.01380109067156384, 'reg_lambda': 9462430.59859992}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:19,366]\u001b[0m Trial 27 finished with value: -1.5116107686190041 and parameters: {'max_depth': 26, 'num_leaves': 19, 'learning_rate': 0.1986354012969661, 'n_estimators': 211, 'reg_alpha': 4.804563545749914e-06, 'reg_lambda': 36614.01291765483}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:23,271]\u001b[0m Trial 31 finished with value: -2.100835812233526 and parameters: {'max_depth': 9, 'num_leaves': 32, 'learning_rate': 0.0030859591855813126, 'n_estimators': 148, 'reg_alpha': 0.009948901813414795, 'reg_lambda': 7336049.825423106}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:32,120]\u001b[0m Trial 30 finished with value: -1.5011506929663083 and parameters: {'max_depth': 42, 'num_leaves': 32, 'learning_rate': 0.182560388515107, 'n_estimators': 226, 'reg_alpha': 0.012184632558048594, 'reg_lambda': 46582.00644468849}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:36,672]\u001b[0m Trial 32 finished with value: -1.536050317363436 and parameters: {'max_depth': 43, 'num_leaves': 32, 'learning_rate': 0.0037551227139612114, 'n_estimators': 226, 'reg_alpha': 13.79343408263181, 'reg_lambda': 0.0039818095946444025}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:44,982]\u001b[0m Trial 33 finished with value: -1.450200858559116 and parameters: {'max_depth': 42, 'num_leaves': 32, 'learning_rate': 0.004097968771319763, 'n_estimators': 310, 'reg_alpha': 7.96183261921916, 'reg_lambda': 1216.3479899972929}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:54,077]\u001b[0m Trial 34 finished with value: -1.5292930015687296 and parameters: {'max_depth': 42, 'num_leaves': 40, 'learning_rate': 0.03163694074840093, 'n_estimators': 297, 'reg_alpha': 4.2855204947795214e-05, 'reg_lambda': 2393.1798783515496}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:18:58,116]\u001b[0m Trial 35 finished with value: -1.5364700621509213 and parameters: {'max_depth': 35, 'num_leaves': 40, 'learning_rate': 0.030572792049503604, 'n_estimators': 304, 'reg_alpha': 3.985254919288685, 'reg_lambda': 1938.6882879930529}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:03,712]\u001b[0m Trial 37 finished with value: -1.5238902526857132 and parameters: {'max_depth': 40, 'num_leaves': 23, 'learning_rate': 0.024096158908481026, 'n_estimators': 314, 'reg_alpha': 1.553989668796273, 'reg_lambda': 1815.663662346255}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:04,389]\u001b[0m Trial 38 finished with value: -1.4536879017254787 and parameters: {'max_depth': 4, 'num_leaves': 23, 'learning_rate': 0.008755484091631315, 'n_estimators': 326, 'reg_alpha': 8.850509879212531, 'reg_lambda': 772.5499851931057}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:07,994]\u001b[0m Trial 39 finished with value: -1.4429063152796866 and parameters: {'max_depth': 4, 'num_leaves': 24, 'learning_rate': 0.008128682500344741, 'n_estimators': 359, 'reg_alpha': 39.63394839088676, 'reg_lambda': 1106.0561705213947}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:09,623]\u001b[0m Trial 36 finished with value: -1.5585484824021085 and parameters: {'max_depth': 35, 'num_leaves': 40, 'learning_rate': 0.036527827729654426, 'n_estimators': 313, 'reg_alpha': 3.675465479345007e-05, 'reg_lambda': 1445.7083188426898}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:10,287]\u001b[0m Trial 41 finished with value: -2.0682028083107356 and parameters: {'max_depth': 21, 'num_leaves': 13, 'learning_rate': 0.0012543154066006795, 'n_estimators': 162, 'reg_alpha': 68.18844014318933, 'reg_lambda': 88675.26792513965}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:10,788]\u001b[0m Trial 40 finished with value: -1.9238948850095 and parameters: {'max_depth': 34, 'num_leaves': 46, 'learning_rate': 0.007980354701057025, 'n_estimators': 153, 'reg_alpha': 39.82502600936089, 'reg_lambda': 90484.53522940501}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:19,156]\u001b[0m Trial 45 finished with value: -1.4620959291303186 and parameters: {'max_depth': 3, 'num_leaves': 28, 'learning_rate': 0.004268729759654544, 'n_estimators': 392, 'reg_alpha': 0.31752821275487125, 'reg_lambda': 269.6654586148381}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:19,226]\u001b[0m Trial 44 finished with value: -1.474088041636331 and parameters: {'max_depth': 3, 'num_leaves': 29, 'learning_rate': 0.0073324194506699195, 'n_estimators': 418, 'reg_alpha': 57.91803080187822, 'reg_lambda': 280.35796639565444}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:20,081]\u001b[0m Trial 42 finished with value: -2.0857351243840156 and parameters: {'max_depth': 45, 'num_leaves': 28, 'learning_rate': 0.0008714711211766453, 'n_estimators': 401, 'reg_alpha': 82.49482348945791, 'reg_lambda': 358773.6658543441}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:19:24,878]\u001b[0m Trial 43 finished with value: -2.005018824927844 and parameters: {'max_depth': 45, 'num_leaves': 13, 'learning_rate': 0.0010183872464943368, 'n_estimators': 397, 'reg_alpha': 78.27642977915093, 'reg_lambda': 53700.56460919062}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:27,476]\u001b[0m Trial 48 finished with value: -1.4712691935717284 and parameters: {'max_depth': 40, 'num_leaves': 25, 'learning_rate': 0.09250371426684476, 'n_estimators': 123, 'reg_alpha': 0.41186668453010966, 'reg_lambda': 12868.591449029664}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:31,351]\u001b[0m Trial 49 finished with value: -2.0682657192776315 and parameters: {'max_depth': 11, 'num_leaves': 25, 'learning_rate': 0.0003460408589489764, 'n_estimators': 111, 'reg_alpha': 0.5841097568624843, 'reg_lambda': 6415.070924331955}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:31,851]\u001b[0m Trial 46 finished with value: -2.0760208055963414 and parameters: {'max_depth': 5, 'num_leaves': 25, 'learning_rate': 0.0008509135398968835, 'n_estimators': 394, 'reg_alpha': 8.344930150222664e-07, 'reg_lambda': 208629.81481242843}. Best is trial 24 with value: -1.4010866576278003.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:32,993]\u001b[0m Trial 47 finished with value: -1.3917051791249913 and parameters: {'max_depth': 45, 'num_leaves': 24, 'learning_rate': 0.013865492808117665, 'n_estimators': 272, 'reg_alpha': 1.0007880802481207e-06, 'reg_lambda': 11779.84246403113}. Best is trial 47 with value: -1.3917051791249913.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:37,201]\u001b[0m A new study created in memory with name: no-name-7bf56972-7dbd-4a77-bdf6-73731df7b3bd\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:38,298]\u001b[0m Trial 0 finished with value: -2.3916458823430236 and parameters: {'max_depth': 45, 'num_leaves': 13, 'learning_rate': 0.11709340893292194, 'n_estimators': 191, 'reg_alpha': 6370656.863965633, 'reg_lambda': 3242728.063807656}. Best is trial 0 with value: -2.3916458823430236.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:40,734]\u001b[0m Trial 2 finished with value: -1.3384012483053758 and parameters: {'max_depth': 29, 'num_leaves': 10, 'learning_rate': 0.2106715815736868, 'n_estimators': 176, 'reg_alpha': 52.05568537163751, 'reg_lambda': 1.3714888929223987}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:43,716]\u001b[0m Trial 4 finished with value: -2.3557874654802218 and parameters: {'max_depth': 11, 'num_leaves': 12, 'learning_rate': 0.00010425706946755031, 'n_estimators': 190, 'reg_alpha': 0.00011558802450677749, 'reg_lambda': 0.00019878519695497933}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:47,455]\u001b[0m Trial 5 finished with value: -2.391638868474464 and parameters: {'max_depth': 25, 'num_leaves': 49, 'learning_rate': 1.7448612947733608e-07, 'n_estimators': 249, 'reg_alpha': 125.63572747395361, 'reg_lambda': 60343.83286572855}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:48,346]\u001b[0m Trial 1 finished with value: -2.390945131018565 and parameters: {'max_depth': 18, 'num_leaves': 50, 'learning_rate': 0.0001981270353223069, 'n_estimators': 383, 'reg_alpha': 0.7395502231062243, 'reg_lambda': 1191593.8477851797}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:54,952]\u001b[0m Trial 6 finished with value: -2.3914672006867175 and parameters: {'max_depth': 12, 'num_leaves': 42, 'learning_rate': 7.175438848900327e-07, 'n_estimators': 495, 'reg_alpha': 952.591784234495, 'reg_lambda': 12977.039508052536}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:55,206]\u001b[0m Trial 9 finished with value: -2.3916458823430236 and parameters: {'max_depth': 19, 'num_leaves': 8, 'learning_rate': 1.0421384983068394e-07, 'n_estimators': 30, 'reg_alpha': 476882.20628691337, 'reg_lambda': 0.0002852849329650995}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:57,501]\u001b[0m Trial 3 finished with value: -2.3915195668684412 and parameters: {'max_depth': 42, 'num_leaves': 16, 'learning_rate': 1.6895492004519947e-07, 'n_estimators': 486, 'reg_alpha': 12.525003148470715, 'reg_lambda': 511.29976041857947}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:19:57,809]\u001b[0m Trial 8 finished with value: -2.355582180236904 and parameters: {'max_depth': 18, 'num_leaves': 24, 'learning_rate': 0.00012971796829651044, 'n_estimators': 149, 'reg_alpha': 0.059398456785521005, 'reg_lambda': 0.41918693754836633}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:58,617]\u001b[0m Trial 7 finished with value: -2.3462829858488607 and parameters: {'max_depth': 17, 'num_leaves': 13, 'learning_rate': 7.884403120318696e-05, 'n_estimators': 317, 'reg_alpha': 1.5306567674079704e-06, 'reg_lambda': 3.251782641820201e-05}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:19:58,874]\u001b[0m Trial 10 finished with value: -2.386972592828586 and parameters: {'max_depth': 28, 'num_leaves': 7, 'learning_rate': 1.3217220160866985e-05, 'n_estimators': 239, 'reg_alpha': 1093.3549277096704, 'reg_lambda': 0.00015553819950273845}. Best is trial 2 with value: -1.3384012483053758.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:00,936]\u001b[0m Trial 14 finished with value: -1.3045890260324742 and parameters: {'max_depth': 1, 'num_leaves': 23, 'learning_rate': 0.016670949521663293, 'n_estimators': 366, 'reg_alpha': 4.100133383790365e-07, 'reg_lambda': 2.3036681577327057e-07}. Best is trial 14 with value: -1.3045890260324742.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:01,884]\u001b[0m Trial 13 finished with value: -1.4727434434274684 and parameters: {'max_depth': 33, 'num_leaves': 32, 'learning_rate': 0.6846624832276486, 'n_estimators': 43, 'reg_alpha': 0.008353236394022282, 'reg_lambda': 1.7482295023761837e-07}. Best is trial 14 with value: -1.3045890260324742.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:20:03,540]\u001b[0m Trial 11 finished with value: -2.3904402280514194 and parameters: {'max_depth': 19, 'num_leaves': 35, 'learning_rate': 9.178680691473267e-06, 'n_estimators': 89, 'reg_alpha': 6.295264784658217e-07, 'reg_lambda': 630.722870128517}. Best is trial 14 with value: -1.3045890260324742.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:11,532]\u001b[0m Trial 12 finished with value: -2.391065745182271 and parameters: {'max_depth': 46, 'num_leaves': 47, 'learning_rate': 2.3533990823652055e-06, 'n_estimators': 129, 'reg_alpha': 0.7416121098613864, 'reg_lambda': 7.4970882767852505}. Best is trial 14 with value: -1.3045890260324742.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:19,786]\u001b[0m Trial 15 finished with value: -1.4178444354260602 and parameters: {'max_depth': -1, 'num_leaves': 27, 'learning_rate': 0.0801213834101243, 'n_estimators': 369, 'reg_alpha': 1.0540873041906439e-07, 'reg_lambda': 2.1395646891413166e-07}. Best is trial 14 with value: -1.3045890260324742.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:20:21,696]\u001b[0m Trial 16 finished with value: -1.3414168970552884 and parameters: {'max_depth': 35, 'num_leaves': 22, 'learning_rate': 0.013625637317306035, 'n_estimators': 367, 'reg_alpha': 1.384921692360702e-07, 'reg_lambda': 1.8406590156107652}. Best is trial 14 with value: -1.3045890260324742.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:24,053]\u001b[0m Trial 17 finished with value: -1.3119940990877101 and parameters: {'max_depth': -1, 'num_leaves': 23, 'learning_rate': 0.01115540553569428, 'n_estimators': 354, 'reg_alpha': 0.0006420749219076242, 'reg_lambda': 0.36142680587049875}. Best is trial 14 with value: -1.3045890260324742.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:20:24,089]\u001b[0m Trial 20 finished with value: -1.5525604998718088 and parameters: {'max_depth': 1, 'num_leaves': 18, 'learning_rate': 0.003669575060436928, 'n_estimators': 303, 'reg_alpha': 0.00045813203744507437, 'reg_lambda': 0.024712400896605126}. Best is trial 14 with value: -1.3045890260324742.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:28,095]\u001b[0m Trial 19 finished with value: -1.24371855146807 and parameters: {'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.007645722687304839, 'n_estimators': 316, 'reg_alpha': 0.0001505329032094012, 'reg_lambda': 0.09846348673049278}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:35,352]\u001b[0m Trial 18 finished with value: -1.3252830433262908 and parameters: {'max_depth': -1, 'num_leaves': 23, 'learning_rate': 0.010783149175218136, 'n_estimators': 392, 'reg_alpha': 0.0001592514365509196, 'reg_lambda': 0.07502134304876121}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:48,148]\u001b[0m Trial 21 finished with value: -1.3096509631394149 and parameters: {'max_depth': -1, 'num_leaves': 20, 'learning_rate': 0.0033261134606539684, 'n_estimators': 429, 'reg_alpha': 5.82190944908177e-05, 'reg_lambda': 0.013933048064733649}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:53,837]\u001b[0m Trial 22 finished with value: -1.5808661829774024 and parameters: {'max_depth': 6, 'num_leaves': 30, 'learning_rate': 0.0014897693287091336, 'n_estimators': 446, 'reg_alpha': 7.218764886694153e-05, 'reg_lambda': 0.019873151269510628}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:20:56,550]\u001b[0m Trial 23 finished with value: -1.6239304236405914 and parameters: {'max_depth': 6, 'num_leaves': 38, 'learning_rate': 0.0014282076938998336, 'n_estimators': 425, 'reg_alpha': 1.879601543658243e-05, 'reg_lambda': 0.00805159730751423}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:03,054]\u001b[0m Trial 25 finished with value: -1.7553557584082158 and parameters: {'max_depth': 4, 'num_leaves': 31, 'learning_rate': 0.0010910927466480373, 'n_estimators': 433, 'reg_alpha': 6.048630767114763e-06, 'reg_lambda': 0.004755689149398328}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:04,816]\u001b[0m Trial 27 finished with value: -1.295221892317837 and parameters: {'max_depth': 4, 'num_leaves': 18, 'learning_rate': 0.0355171063886387, 'n_estimators': 309, 'reg_alpha': 2.1568312499682074e-06, 'reg_lambda': 1.7336992731987643e-05}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:06,363]\u001b[0m Trial 24 finished with value: -1.4549794574142274 and parameters: {'max_depth': 6, 'num_leaves': 31, 'learning_rate': 0.0020480479994644477, 'n_estimators': 434, 'reg_alpha': 1.2541942279636658e-05, 'reg_lambda': 0.005144135209911062}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:12,125]\u001b[0m Trial 26 finished with value: -1.4841158701933297 and parameters: {'max_depth': 5, 'num_leaves': 18, 'learning_rate': 0.0019080847128906673, 'n_estimators': 436, 'reg_alpha': 7.687216443548874e-06, 'reg_lambda': 0.00257619837094602}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:16,176]\u001b[0m Trial 28 finished with value: -1.3557817578144222 and parameters: {'max_depth': 10, 'num_leaves': 18, 'learning_rate': 0.0365659021617624, 'n_estimators': 293, 'reg_alpha': 5.046836310538567e-06, 'reg_lambda': 2.504263154508152e-06}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:18,547]\u001b[0m Trial 30 finished with value: -1.3638057944629836 and parameters: {'max_depth': 11, 'num_leaves': 17, 'learning_rate': 0.0469257085657318, 'n_estimators': 294, 'reg_alpha': 2.1196398004139738e-06, 'reg_lambda': 5.001120735969964e-06}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:21,616]\u001b[0m Trial 29 finished with value: -1.3802758710209442 and parameters: {'max_depth': 11, 'num_leaves': 27, 'learning_rate': 0.04155666727367517, 'n_estimators': 302, 'reg_alpha': 2.9238924030464087e-06, 'reg_lambda': 3.1465497010091e-06}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:26,650]\u001b[0m Trial 34 finished with value: -1.2929259945365716 and parameters: {'max_depth': 3, 'num_leaves': 21, 'learning_rate': 0.006435734130387768, 'n_estimators': 337, 'reg_alpha': 0.002226585614352013, 'reg_lambda': 0.0007006544139258798}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:31,648]\u001b[0m Trial 35 finished with value: -1.3373800789191863 and parameters: {'max_depth': 3, 'num_leaves': 15, 'learning_rate': 0.14714978661841854, 'n_estimators': 334, 'reg_alpha': 0.00252676278972651, 'reg_lambda': 2.712030617513138e-05}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:32,869]\u001b[0m Trial 31 finished with value: -1.355141704648337 and parameters: {'max_depth': 11, 'num_leaves': 27, 'learning_rate': 0.022729578784323676, 'n_estimators': 313, 'reg_alpha': 1.3998085648108224e-06, 'reg_lambda': 3.355515723006254e-06}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:21:34,214]\u001b[0m Trial 33 finished with value: -1.3381827272678688 and parameters: {'max_depth': 14, 'num_leaves': 27, 'learning_rate': 0.01986448103072474, 'n_estimators': 225, 'reg_alpha': 4.2768436944267307e-07, 'reg_lambda': 1.9141782163144097e-06}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:37,224]\u001b[0m Trial 32 finished with value: -1.394350722775063 and parameters: {'max_depth': 14, 'num_leaves': 27, 'learning_rate': 0.04660711898173405, 'n_estimators': 330, 'reg_alpha': 5.12750181161251e-07, 'reg_lambda': 3.4422586961430674e-06}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:44,096]\u001b[0m Trial 36 finished with value: -2.2032164774864604 and parameters: {'max_depth': 8, 'num_leaves': 25, 'learning_rate': 0.00047547026800934516, 'n_estimators': 223, 'reg_alpha': 3.5286819606095866e-07, 'reg_lambda': 0.0007327782974203415}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:46,788]\u001b[0m Trial 40 finished with value: -1.353984137049202 and parameters: {'max_depth': 2, 'num_leaves': 21, 'learning_rate': 0.007106295173635278, 'n_estimators': 274, 'reg_alpha': 3.563344248295467e-05, 'reg_lambda': 4.0151051882398885e-05}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:21:47,346]\u001b[0m Trial 39 finished with value: -1.2988744517394115 and parameters: {'max_depth': 8, 'num_leaves': 14, 'learning_rate': 0.005891954879807916, 'n_estimators': 274, 'reg_alpha': 3.8033284481063814e-05, 'reg_lambda': 0.0008823480500630566}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:21:48,004]\u001b[0m Trial 37 finished with value: -1.2779574205390856 and parameters: {'max_depth': 8, 'num_leaves': 21, 'learning_rate': 0.007045561677640606, 'n_estimators': 268, 'reg_alpha': 0.004888743981873695, 'reg_lambda': 1.0010468691620463e-07}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:21:48,210]\u001b[0m Trial 38 finished with value: -1.2804547236702242 and parameters: {'max_depth': 8, 'num_leaves': 20, 'learning_rate': 0.00685977392477392, 'n_estimators': 270, 'reg_alpha': 0.003117260099777461, 'reg_lambda': 5.692272175061561e-07}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:54,804]\u001b[0m Trial 44 finished with value: -1.3675632673052978 and parameters: {'max_depth': 15, 'num_leaves': 11, 'learning_rate': 0.006175297630607614, 'n_estimators': 202, 'reg_alpha': 0.015742519476162693, 'reg_lambda': 5.504995299934011e-07}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:21:56,013]\u001b[0m Trial 42 finished with value: -1.435001402746451 and parameters: {'max_depth': 8, 'num_leaves': 12, 'learning_rate': 0.2793068224090926, 'n_estimators': 268, 'reg_alpha': 0.018222280590381758, 'reg_lambda': 0.0010117489027888457}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:56,793]\u001b[0m Trial 41 finished with value: -1.4433483349393672 and parameters: {'max_depth': 23, 'num_leaves': 12, 'learning_rate': 0.36810720888082354, 'n_estimators': 402, 'reg_alpha': 0.013556969312493635, 'reg_lambda': 0.0005420685099814225}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:21:59,116]\u001b[0m Trial 43 finished with value: -1.478359300313877 and parameters: {'max_depth': 15, 'num_leaves': 11, 'learning_rate': 0.3189005803181954, 'n_estimators': 396, 'reg_alpha': 0.02953284659811174, 'reg_lambda': 8.286271936624009e-05}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:22:01,138]\u001b[0m Trial 47 finished with value: -1.3049977333709746 and parameters: {'max_depth': 4, 'num_leaves': 20, 'learning_rate': 0.08145213845901006, 'n_estimators': 172, 'reg_alpha': 0.0014201690037298825, 'reg_lambda': 2.0365820971113813e-05}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:22:05,642]\u001b[0m Trial 48 finished with value: -1.3103428154215524 and parameters: {'max_depth': 3, 'num_leaves': 20, 'learning_rate': 0.005308217519286167, 'n_estimators': 342, 'reg_alpha': 0.21380948587454868, 'reg_lambda': 1.6347962746497383e-05}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:22:06,811]\u001b[0m Trial 45 finished with value: -1.44640612212514 and parameters: {'max_depth': 9, 'num_leaves': 20, 'learning_rate': 0.26078357050201284, 'n_estimators': 271, 'reg_alpha': 0.10563672880037422, 'reg_lambda': 4.76854947141334e-05}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:22:10,088]\u001b[0m Trial 49 finished with value: -2.120354372426625 and parameters: {'max_depth': 8, 'num_leaves': 16, 'learning_rate': 0.00047382342474392407, 'n_estimators': 343, 'reg_alpha': 0.2374414707581776, 'reg_lambda': 7.153717270774078e-07}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:10,702]\u001b[0m Trial 46 finished with value: -1.9779166578836733 and parameters: {'max_depth': 23, 'num_leaves': 20, 'learning_rate': 0.0006595574154716612, 'n_estimators': 398, 'reg_alpha': 0.13200493651596856, 'reg_lambda': 5.294071928376353e-05}. Best is trial 19 with value: -1.24371855146807.\u001b[0m\n",
      " 69%|                    | 11/16 [2:12:37<57:41, 692.33s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:22:14,358]\u001b[0m A new study created in memory with name: no-name-96cddede-4368-445f-84c4-9aa3b495a611\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:16,918]\u001b[0m Trial 2 finished with value: -1.203519882112593 and parameters: {'max_depth': 44, 'num_leaves': 19, 'learning_rate': 1.3150250300661824e-06, 'n_estimators': 44, 'reg_alpha': 62446.1462916379, 'reg_lambda': 33.87537708942471}. Best is trial 2 with value: -1.203519882112593.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:18,693]\u001b[0m Trial 1 finished with value: -1.1604322259104416 and parameters: {'max_depth': 18, 'num_leaves': 19, 'learning_rate': 0.0027304767872489686, 'n_estimators': 34, 'reg_alpha': 0.02630151993517578, 'reg_lambda': 6658.023693390076}. Best is trial 1 with value: -1.1604322259104416.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:22,009]\u001b[0m Trial 0 finished with value: -0.8824324636954992 and parameters: {'max_depth': 21, 'num_leaves': 25, 'learning_rate': 0.5489543405390667, 'n_estimators': 418, 'reg_alpha': 11825.201512715183, 'reg_lambda': 114.40085701064366}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:25,330]\u001b[0m Trial 5 finished with value: -0.9303617656701451 and parameters: {'max_depth': 43, 'num_leaves': 32, 'learning_rate': 0.5496864238599333, 'n_estimators': 225, 'reg_alpha': 452.8433301279874, 'reg_lambda': 0.007710703152569165}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:39,385]\u001b[0m Trial 3 finished with value: -1.2010385605993132 and parameters: {'max_depth': 27, 'num_leaves': 20, 'learning_rate': 1.4039900800124079e-05, 'n_estimators': 260, 'reg_alpha': 5.522234368346606e-06, 'reg_lambda': 609.0608987238489}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:41,414]\u001b[0m Trial 7 finished with value: -0.9404244249401417 and parameters: {'max_depth': 34, 'num_leaves': 37, 'learning_rate': 0.07956364365009859, 'n_estimators': 116, 'reg_alpha': 0.03767631934324336, 'reg_lambda': 0.31447969435885365}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:48,597]\u001b[0m Trial 4 finished with value: -0.9023485938021772 and parameters: {'max_depth': 39, 'num_leaves': 26, 'learning_rate': 0.005947861141505747, 'n_estimators': 296, 'reg_alpha': 0.0019944444540107476, 'reg_lambda': 2.592180606341476e-05}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:50,562]\u001b[0m Trial 6 finished with value: -1.0513505941687746 and parameters: {'max_depth': 17, 'num_leaves': 14, 'learning_rate': 0.000750702359165132, 'n_estimators': 375, 'reg_alpha': 0.003123122303651148, 'reg_lambda': 3.983317584827846e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:51,886]\u001b[0m Trial 8 finished with value: -0.9106080693850241 and parameters: {'max_depth': 2, 'num_leaves': 43, 'learning_rate': 0.0030934041374732282, 'n_estimators': 451, 'reg_alpha': 1.4518209281801526e-07, 'reg_lambda': 7540.193610938025}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:51,947]\u001b[0m Trial 10 finished with value: -1.203513204265858 and parameters: {'max_depth': 21, 'num_leaves': 34, 'learning_rate': 7.827802795211734e-07, 'n_estimators': 41, 'reg_alpha': 3.7516312089854676e-07, 'reg_lambda': 19333.923714089444}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:22:59,353]\u001b[0m Trial 13 finished with value: -1.2035246286511367 and parameters: {'max_depth': 6, 'num_leaves': 5, 'learning_rate': 0.8203371477749712, 'n_estimators': 468, 'reg_alpha': 4124678.692981236, 'reg_lambda': 5619224.461194326}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:23:02,009]\u001b[0m Trial 12 finished with value: -1.2035149540657815 and parameters: {'max_depth': 22, 'num_leaves': 50, 'learning_rate': 6.596414791336773e-07, 'n_estimators': 403, 'reg_alpha': 68961.55296310972, 'reg_lambda': 0.730746025872264}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:23:16,948]\u001b[0m Trial 11 finished with value: -0.9429884118718712 and parameters: {'max_depth': 26, 'num_leaves': 31, 'learning_rate': 0.15803035488677403, 'n_estimators': 245, 'reg_alpha': 0.0006989929027951231, 'reg_lambda': 0.12656484317878477}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:23:30,176]\u001b[0m Trial 9 finished with value: -1.2031321187033073 and parameters: {'max_depth': 25, 'num_leaves': 37, 'learning_rate': 1.5190248261349766e-06, 'n_estimators': 349, 'reg_alpha': 9.941574393791345, 'reg_lambda': 36.91440280237366}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:23:30,269]\u001b[0m Trial 14 finished with value: -0.9350667399625341 and parameters: {'max_depth': 32, 'num_leaves': 27, 'learning_rate': 0.027460536655680445, 'n_estimators': 338, 'reg_alpha': 16.205340355386845, 'reg_lambda': 2.5746280440000277e-07}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:23:33,813]\u001b[0m Trial 15 finished with value: -0.9367090041300794 and parameters: {'max_depth': 32, 'num_leaves': 26, 'learning_rate': 0.03568351530841883, 'n_estimators': 314, 'reg_alpha': 36.01330243851189, 'reg_lambda': 5.638821808633359e-07}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:23:44,133]\u001b[0m Trial 19 finished with value: -0.8839203923776482 and parameters: {'max_depth': 10, 'num_leaves': 10, 'learning_rate': 0.011683857496333681, 'n_estimators': 163, 'reg_alpha': 0.670044550329425, 'reg_lambda': 0.0007942815592782471}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:23:48,776]\u001b[0m Trial 16 finished with value: -0.9358082863659721 and parameters: {'max_depth': 34, 'num_leaves': 24, 'learning_rate': 0.03538246978523396, 'n_estimators': 323, 'reg_alpha': 6.99104630977304, 'reg_lambda': 1.3984406688951543e-07}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:23:51,287]\u001b[0m Trial 20 finished with value: -1.1859257571124064 and parameters: {'max_depth': 12, 'num_leaves': 6, 'learning_rate': 0.0001624908800094238, 'n_estimators': 162, 'reg_alpha': 0.5311097780492084, 'reg_lambda': 0.002629812538581505}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:23:56,603]\u001b[0m Trial 21 finished with value: -1.1831606518096345 and parameters: {'max_depth': 11, 'num_leaves': 6, 'learning_rate': 0.00018381106033071718, 'n_estimators': 171, 'reg_alpha': 868.6107305724595, 'reg_lambda': 0.0023091522465067}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:23:56,893]\u001b[0m Trial 22 finished with value: -0.9210699826040019 and parameters: {'max_depth': 10, 'num_leaves': 11, 'learning_rate': 0.2152426096867201, 'n_estimators': 171, 'reg_alpha': 1528.1582392658993, 'reg_lambda': 0.0005571140773591366}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:24:01,118]\u001b[0m Trial 18 finished with value: -0.9336365702152916 and parameters: {'max_depth': 13, 'num_leaves': 26, 'learning_rate': 0.027769028877645898, 'n_estimators': 313, 'reg_alpha': 1.5004431540373648, 'reg_lambda': 0.00013837685403409106}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:24:02,034]\u001b[0m Trial 17 finished with value: -0.9296830910765274 and parameters: {'max_depth': 36, 'num_leaves': 25, 'learning_rate': 0.017505098289872477, 'n_estimators': 306, 'reg_alpha': 4.3570067263693755, 'reg_lambda': 1.4190282061786898e-07}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:24:09,949]\u001b[0m Trial 25 finished with value: -0.9300339101963746 and parameters: {'max_depth': -1, 'num_leaves': 13, 'learning_rate': 0.00651876782595265, 'n_estimators': 119, 'reg_alpha': 0.00019280982605604272, 'reg_lambda': 1.8286196569354416e-05}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:24:25,453]\u001b[0m Trial 23 finished with value: -0.9440902842303812 and parameters: {'max_depth': 0, 'num_leaves': 14, 'learning_rate': 0.22121587606261325, 'n_estimators': 498, 'reg_alpha': 0.27549007537438375, 'reg_lambda': 9.666527423145929e-05}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:24:27,113]\u001b[0m Trial 24 finished with value: -0.9098732361471193 and parameters: {'max_depth': 39, 'num_leaves': 13, 'learning_rate': 0.009457426400914076, 'n_estimators': 423, 'reg_alpha': 0.24471291222936029, 'reg_lambda': 2.6211318096411767e-05}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:24:34,976]\u001b[0m Trial 26 finished with value: -0.9065456214367867 and parameters: {'max_depth': 0, 'num_leaves': 12, 'learning_rate': 0.00730042757930233, 'n_estimators': 500, 'reg_alpha': 5.079401775721321e-05, 'reg_lambda': 1.5997004350904673e-05}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:24:43,221]\u001b[0m Trial 27 finished with value: -0.9406594111019215 and parameters: {'max_depth': 39, 'num_leaves': 21, 'learning_rate': 0.1311624823435512, 'n_estimators': 431, 'reg_alpha': 0.08382932375392592, 'reg_lambda': 2.6285556134069094e-05}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:24:55,030]\u001b[0m Trial 30 finished with value: -0.9708955399323524 and parameters: {'max_depth': 6, 'num_leaves': 22, 'learning_rate': 0.99177799326287, 'n_estimators': 273, 'reg_alpha': 0.012348713479830652, 'reg_lambda': 0.03881208020389755}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:24:56,983]\u001b[0m Trial 29 finished with value: -1.0303788663813611 and parameters: {'max_depth': 17, 'num_leaves': 22, 'learning_rate': 0.0011473300457401333, 'n_estimators': 279, 'reg_alpha': 7.270080915629059e-05, 'reg_lambda': 0.01687977648746257}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:25:04,803]\u001b[0m Trial 31 finished with value: -0.9513682840985582 and parameters: {'max_depth': 7, 'num_leaves': 29, 'learning_rate': 0.4530040836118973, 'n_estimators': 273, 'reg_alpha': 0.0066194051965409294, 'reg_lambda': 0.02656671014177664}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:25:13,137]\u001b[0m Trial 33 finished with value: -0.9259389508060685 and parameters: {'max_depth': 29, 'num_leaves': 17, 'learning_rate': 0.06677937086842221, 'n_estimators': 211, 'reg_alpha': 0.028877499051627318, 'reg_lambda': 0.000551225670791588}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:25:15,897]\u001b[0m Trial 28 finished with value: -0.9257526076211715 and parameters: {'max_depth': 38, 'num_leaves': 21, 'learning_rate': 0.010432053522306426, 'n_estimators': 407, 'reg_alpha': 0.03856437347824614, 'reg_lambda': 0.0387764962586738}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:25:22,566]\u001b[0m Trial 34 finished with value: -0.9006528257901473 and parameters: {'max_depth': 3, 'num_leaves': 9, 'learning_rate': 0.007304658413686273, 'n_estimators': 486, 'reg_alpha': 2.862287225862371e-05, 'reg_lambda': 1.8409011360657108e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:25:24,499]\u001b[0m Trial 32 finished with value: -1.0671254919699396 and parameters: {'max_depth': 17, 'num_leaves': 30, 'learning_rate': 0.0010139787101936413, 'n_estimators': 224, 'reg_alpha': 0.017350491996649477, 'reg_lambda': 0.020734978234183077}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:25:26,036]\u001b[0m Trial 38 finished with value: -1.1857468334474903 and parameters: {'max_depth': 3, 'num_leaves': 9, 'learning_rate': 0.004393898742080135, 'n_estimators': 6, 'reg_alpha': 0.0015820978963262753, 'reg_lambda': 2.225523999940812e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:25:30,554]\u001b[0m Trial 37 finished with value: -1.0618635503359188 and parameters: {'max_depth': 15, 'num_leaves': 10, 'learning_rate': 0.002518162292404537, 'n_estimators': 102, 'reg_alpha': 0.0010412366121713356, 'reg_lambda': 2.0278238801588027e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:25:40,407]\u001b[0m Trial 35 finished with value: -0.8939099344264051 and parameters: {'max_depth': 19, 'num_leaves': 8, 'learning_rate': 0.005510413096013447, 'n_estimators': 497, 'reg_alpha': 0.0017150853097373908, 'reg_lambda': 1.190129948672129e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:25:46,026]\u001b[0m Trial 36 finished with value: -0.8852849382636934 and parameters: {'max_depth': 46, 'num_leaves': 10, 'learning_rate': 0.004280575655047297, 'n_estimators': 475, 'reg_alpha': 2.0334585390971668e-05, 'reg_lambda': 5.177306517961574e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:25:57,898]\u001b[0m Trial 40 finished with value: -0.9313984648054792 and parameters: {'max_depth': 46, 'num_leaves': 18, 'learning_rate': 0.0643641544646806, 'n_estimators': 373, 'reg_alpha': 8.449249353045714e-06, 'reg_lambda': 8.843852811041826}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:26:00,564]\u001b[0m Trial 39 finished with value: -0.8918649651753185 and parameters: {'max_depth': 14, 'num_leaves': 18, 'learning_rate': 0.003598626610800197, 'n_estimators': 382, 'reg_alpha': 8.196343637175467e-06, 'reg_lambda': 1.4711824568920452e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:26:01,705]\u001b[0m Trial 41 finished with value: -0.925760432048311 and parameters: {'max_depth': 19, 'num_leaves': 8, 'learning_rate': 0.054274400476110186, 'n_estimators': 470, 'reg_alpha': 6.27273871390291e-06, 'reg_lambda': 9.69927898261999e-07}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:26:30,644]\u001b[0m Trial 42 finished with value: -1.0803196881857082 and parameters: {'max_depth': 45, 'num_leaves': 18, 'learning_rate': 0.00044963315849741757, 'n_estimators': 461, 'reg_alpha': 4.897928981734225e-06, 'reg_lambda': 2.2171364382283603}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:26:35,618]\u001b[0m Trial 43 finished with value: -1.1062526194058369 and parameters: {'max_depth': 19, 'num_leaves': 16, 'learning_rate': 0.0003376200487490111, 'n_estimators': 466, 'reg_alpha': 2.3842223863726654e-06, 'reg_lambda': 8.381289174902308e-07}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:26:41,655]\u001b[0m Trial 44 finished with value: -0.9195326904321137 and parameters: {'max_depth': 20, 'num_leaves': 16, 'learning_rate': 0.0018991085046546567, 'n_estimators': 457, 'reg_alpha': 1.8089359167672128e-06, 'reg_lambda': 7.851495512881291e-07}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:26:44,531]\u001b[0m Trial 45 finished with value: -0.9061584316910832 and parameters: {'max_depth': 20, 'num_leaves': 17, 'learning_rate': 0.0022871794491215276, 'n_estimators': 445, 'reg_alpha': 0.00025054892235524, 'reg_lambda': 6.258653413543262e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:00,561]\u001b[0m Trial 48 finished with value: -0.9064673594828259 and parameters: {'max_depth': 24, 'num_leaves': 7, 'learning_rate': 0.013561997260843199, 'n_estimators': 381, 'reg_alpha': 0.00018066179487698808, 'reg_lambda': 9.842919473479312e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:03,577]\u001b[0m Trial 49 finished with value: -0.8943236665390109 and parameters: {'max_depth': 24, 'num_leaves': 7, 'learning_rate': 0.0034463972145126393, 'n_estimators': 389, 'reg_alpha': 0.00372019482486527, 'reg_lambda': 5.695704351107442e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:07,026]\u001b[0m Trial 46 finished with value: -0.9254785248103057 and parameters: {'max_depth': 20, 'num_leaves': 15, 'learning_rate': 0.0018449773035995494, 'n_estimators': 441, 'reg_alpha': 0.00029277782976745075, 'reg_lambda': 5.785204427885581e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:07,584]\u001b[0m Trial 47 finished with value: -0.912188488377335 and parameters: {'max_depth': 24, 'num_leaves': 15, 'learning_rate': 0.0021447726029948486, 'n_estimators': 438, 'reg_alpha': 0.00020401271347634853, 'reg_lambda': 2.892013134128893e-06}. Best is trial 0 with value: -0.8824324636954992.\u001b[0m\n",
      " 75%|                | 12/16 [2:17:34<38:08, 572.23s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:27:13,641]\u001b[0m A new study created in memory with name: no-name-90053771-056d-4ed7-b43f-2a7c8f08c7f2\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:23,924]\u001b[0m Trial 1 finished with value: -1.3664791755859156 and parameters: {'max_depth': 19, 'num_leaves': 25, 'learning_rate': 0.00013575961705497772, 'n_estimators': 84, 'reg_alpha': 2718099.5171116577, 'reg_lambda': 0.006121843827226403}. Best is trial 1 with value: -1.3664791755859156.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:24,953]\u001b[0m Trial 3 finished with value: -1.1231579444986557 and parameters: {'max_depth': 1, 'num_leaves': 8, 'learning_rate': 0.013557774126394629, 'n_estimators': 107, 'reg_alpha': 2.001931384435362, 'reg_lambda': 1.7742161168454339e-06}. Best is trial 3 with value: -1.1231579444986557.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:28,212]\u001b[0m Trial 2 finished with value: -1.366353027803385 and parameters: {'max_depth': 47, 'num_leaves': 47, 'learning_rate': 1.0692781888647686e-05, 'n_estimators': 21, 'reg_alpha': 110.47814957951935, 'reg_lambda': 8631.34099622429}. Best is trial 3 with value: -1.1231579444986557.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:28,281]\u001b[0m Trial 0 finished with value: -1.3571833664566508 and parameters: {'max_depth': 15, 'num_leaves': 45, 'learning_rate': 0.0006204476029384292, 'n_estimators': 85, 'reg_alpha': 166724.37528552423, 'reg_lambda': 318.67186990977405}. Best is trial 3 with value: -1.1231579444986557.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:35,288]\u001b[0m Trial 4 finished with value: -1.3664791755859156 and parameters: {'max_depth': 2, 'num_leaves': 8, 'learning_rate': 0.019635855548057805, 'n_estimators': 166, 'reg_alpha': 1962602.1457777787, 'reg_lambda': 4.716917135246258}. Best is trial 3 with value: -1.1231579444986557.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:42,268]\u001b[0m Trial 7 finished with value: -1.366463974039699 and parameters: {'max_depth': 20, 'num_leaves': 50, 'learning_rate': 7.82106298515222e-07, 'n_estimators': 44, 'reg_alpha': 515.1090624346284, 'reg_lambda': 34012.50557808457}. Best is trial 3 with value: -1.1231579444986557.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:27:55,348]\u001b[0m Trial 8 finished with value: -1.365673536111069 and parameters: {'max_depth': 1, 'num_leaves': 18, 'learning_rate': 7.753725089044408e-06, 'n_estimators': 251, 'reg_alpha': 9533.50158886048, 'reg_lambda': 200.59411829439952}. Best is trial 3 with value: -1.1231579444986557.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:28:00,221]\u001b[0m Trial 9 finished with value: -1.3664791755859156 and parameters: {'max_depth': 13, 'num_leaves': 14, 'learning_rate': 0.010998315098428598, 'n_estimators': 280, 'reg_alpha': 5105139.353751657, 'reg_lambda': 0.0021731358448290263}. Best is trial 3 with value: -1.1231579444986557.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:28:16,883]\u001b[0m Trial 6 finished with value: -1.1027478322918631 and parameters: {'max_depth': 22, 'num_leaves': 10, 'learning_rate': 0.028273968279258533, 'n_estimators': 293, 'reg_alpha': 0.002101379469340018, 'reg_lambda': 0.11380437605845167}. Best is trial 6 with value: -1.1027478322918631.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:28:33,799]\u001b[0m Trial 12 finished with value: -1.3664791755859156 and parameters: {'max_depth': 32, 'num_leaves': 33, 'learning_rate': 0.00022837196293131365, 'n_estimators': 271, 'reg_alpha': 3912968.738183984, 'reg_lambda': 6.319516443913881}. Best is trial 6 with value: -1.1027478322918631.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:28:37,594]\u001b[0m Trial 5 finished with value: -1.1359595816433483 and parameters: {'max_depth': 41, 'num_leaves': 10, 'learning_rate': 0.03769607508634839, 'n_estimators': 484, 'reg_alpha': 2.5614468893959232e-05, 'reg_lambda': 12.934779336836415}. Best is trial 6 with value: -1.1027478322918631.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:29:15,643]\u001b[0m Trial 11 finished with value: -1.1069012068920472 and parameters: {'max_depth': 33, 'num_leaves': 17, 'learning_rate': 0.0057174883677021905, 'n_estimators': 337, 'reg_alpha': 33.63264311015085, 'reg_lambda': 35.18826388029505}. Best is trial 6 with value: -1.1027478322918631.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:29:38,470]\u001b[0m Trial 14 finished with value: -1.2782746009871258 and parameters: {'max_depth': 30, 'num_leaves': 23, 'learning_rate': 0.6341766314398452, 'n_estimators': 382, 'reg_alpha': 0.032220333881862656, 'reg_lambda': 4.0301596060264756e-07}. Best is trial 6 with value: -1.1027478322918631.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:30:07,393]\u001b[0m Trial 10 finished with value: -1.324507596538013 and parameters: {'max_depth': 47, 'num_leaves': 31, 'learning_rate': 0.00015594615053323563, 'n_estimators': 408, 'reg_alpha': 5.016393594631997, 'reg_lambda': 8.276652238960426e-06}. Best is trial 6 with value: -1.1027478322918631.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:30:26,844]\u001b[0m Trial 13 finished with value: -1.0393002880675277 and parameters: {'max_depth': 32, 'num_leaves': 31, 'learning_rate': 0.6298795975671763, 'n_estimators': 434, 'reg_alpha': 0.00012242191248325294, 'reg_lambda': 2744030.4648894463}. Best is trial 13 with value: -1.0393002880675277.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:30:42,891]\u001b[0m Trial 15 finished with value: -1.1052190059884115 and parameters: {'max_depth': 30, 'num_leaves': 21, 'learning_rate': 0.4683491488777632, 'n_estimators': 379, 'reg_alpha': 0.004061783073508446, 'reg_lambda': 498052.2470989675}. Best is trial 13 with value: -1.0393002880675277.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:31:08,439]\u001b[0m Trial 16 finished with value: -1.032666046715569 and parameters: {'max_depth': 29, 'num_leaves': 35, 'learning_rate': 0.5908318388345518, 'n_estimators': 359, 'reg_alpha': 0.015394483562267778, 'reg_lambda': 2650123.3241001554}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:31:18,707]\u001b[0m Trial 17 finished with value: -1.0384455261610481 and parameters: {'max_depth': 29, 'num_leaves': 18, 'learning_rate': 0.2803111030815816, 'n_estimators': 345, 'reg_alpha': 0.007805109055488521, 'reg_lambda': 1284189.4378503596}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:31:54,737]\u001b[0m Trial 21 finished with value: -1.0887192310377007 and parameters: {'max_depth': 39, 'num_leaves': 35, 'learning_rate': 0.1649112337435158, 'n_estimators': 218, 'reg_alpha': 0.1268210333117597, 'reg_lambda': 3961127.761468688}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:32:18,058]\u001b[0m Trial 19 finished with value: -1.0531085593105123 and parameters: {'max_depth': 25, 'num_leaves': 39, 'learning_rate': 0.16360302246469285, 'n_estimators': 471, 'reg_alpha': 1.1119372695070923e-07, 'reg_lambda': 4467510.754884697}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:32:40,470]\u001b[0m Trial 22 finished with value: -1.1436669461952036 and parameters: {'max_depth': 27, 'num_leaves': 39, 'learning_rate': 0.102430008597203, 'n_estimators': 335, 'reg_alpha': 3.228334163076995e-07, 'reg_lambda': 8352437.096517883}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:32:43,511]\u001b[0m Trial 18 finished with value: -1.0394971022899817 and parameters: {'max_depth': 26, 'num_leaves': 38, 'learning_rate': 0.9417995834802796, 'n_estimators': 485, 'reg_alpha': 6.14777381470967e-05, 'reg_lambda': 4191763.5346229356}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:33:21,828]\u001b[0m Trial 20 finished with value: -1.0373444240078233 and parameters: {'max_depth': 36, 'num_leaves': 39, 'learning_rate': 0.9606942449188026, 'n_estimators': 499, 'reg_alpha': 1.3340740715695798e-07, 'reg_lambda': 4987911.047907351}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:34:05,387]\u001b[0m Trial 23 finished with value: -1.194103096609727 and parameters: {'max_depth': 39, 'num_leaves': 39, 'learning_rate': 0.10193907472723486, 'n_estimators': 331, 'reg_alpha': 0.14279405060288006, 'reg_lambda': 18650.089717829735}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:34:27,009]\u001b[0m Trial 25 finished with value: -1.1770853310200489 and parameters: {'max_depth': 37, 'num_leaves': 27, 'learning_rate': 0.9387184108207687, 'n_estimators': 422, 'reg_alpha': 0.23336361497768396, 'reg_lambda': 109622.37293440057}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:34:32,912]\u001b[0m Trial 24 finished with value: -1.183301847989973 and parameters: {'max_depth': 36, 'num_leaves': 28, 'learning_rate': 0.47637829040150415, 'n_estimators': 430, 'reg_alpha': 0.00012318964865684571, 'reg_lambda': 100041.10550629858}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:34:58,132]\u001b[0m Trial 28 finished with value: -1.2479849313039668 and parameters: {'max_depth': 36, 'num_leaves': 43, 'learning_rate': 0.0035097467934420185, 'n_estimators': 202, 'reg_alpha': 2.5671884648599013e-06, 'reg_lambda': 279939.24770829023}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:35:22,579]\u001b[0m Trial 26 finished with value: -1.149212800414326 and parameters: {'max_depth': 37, 'num_leaves': 28, 'learning_rate': 0.10709800665177166, 'n_estimators': 436, 'reg_alpha': 0.08272493667369173, 'reg_lambda': 98020.9959726548}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:35:39,276]\u001b[0m Trial 29 finished with value: -1.203980691477621 and parameters: {'max_depth': 42, 'num_leaves': 43, 'learning_rate': 0.07680885534977645, 'n_estimators': 190, 'reg_alpha': 1.6662985430497337e-06, 'reg_lambda': 2931.7725472685206}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:35:56,836]\u001b[0m Trial 27 finished with value: -1.1800871249492115 and parameters: {'max_depth': 37, 'num_leaves': 27, 'learning_rate': 0.8342073947084377, 'n_estimators': 438, 'reg_alpha': 1.6126783675146526e-06, 'reg_lambda': 113280.86541861741}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:36:45,815]\u001b[0m Trial 30 finished with value: -1.2249917592899806 and parameters: {'max_depth': 7, 'num_leaves': 42, 'learning_rate': 0.06598662338753136, 'n_estimators': 385, 'reg_alpha': 0.0030373150918722005, 'reg_lambda': 1534.8921260884767}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:37:08,954]\u001b[0m Trial 31 finished with value: -1.1917063708652105 and parameters: {'max_depth': 43, 'num_leaves': 36, 'learning_rate': 0.043409085462307734, 'n_estimators': 382, 'reg_alpha': 0.004149826459048674, 'reg_lambda': 3614.7541141716138}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:37:26,823]\u001b[0m Trial 33 finished with value: -1.2388528741485456 and parameters: {'max_depth': 13, 'num_leaves': 35, 'learning_rate': 0.26657505525475855, 'n_estimators': 373, 'reg_alpha': 0.0022188160177629046, 'reg_lambda': 2295.4300985529308}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:37:43,319]\u001b[0m Trial 32 finished with value: -1.1395255099218795 and parameters: {'max_depth': 15, 'num_leaves': 36, 'learning_rate': 0.002322750265504474, 'n_estimators': 363, 'reg_alpha': 0.002243282977199755, 'reg_lambda': 386.6908511480527}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:38:57,778]\u001b[0m Trial 34 finished with value: -1.0594723217157285 and parameters: {'max_depth': 29, 'num_leaves': 35, 'learning_rate': 0.2810178827728164, 'n_estimators': 457, 'reg_alpha': 0.0008548595497287814, 'reg_lambda': 836890.1735422999}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:39:19,079]\u001b[0m Trial 35 finished with value: -1.0513393512568128 and parameters: {'max_depth': 29, 'num_leaves': 32, 'learning_rate': 0.23027386333471922, 'n_estimators': 497, 'reg_alpha': 0.0003106493029848793, 'reg_lambda': 859432.5556331977}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:39:35,625]\u001b[0m Trial 36 finished with value: -1.0630543957461502 and parameters: {'max_depth': 28, 'num_leaves': 31, 'learning_rate': 0.29399155944465793, 'n_estimators': 454, 'reg_alpha': 0.0002854309549908783, 'reg_lambda': 824224.4858773916}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:40:09,800]\u001b[0m Trial 40 finished with value: -1.2685345089543698 and parameters: {'max_depth': 32, 'num_leaves': 23, 'learning_rate': 0.02428887321180895, 'n_estimators': 305, 'reg_alpha': 1.2603026878880897e-05, 'reg_lambda': 8473882.382606542}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:40:09,967]\u001b[0m Trial 39 finished with value: -1.0746298961741676 and parameters: {'max_depth': 33, 'num_leaves': 30, 'learning_rate': 0.33008088087914883, 'n_estimators': 302, 'reg_alpha': 1.556829714455022e-05, 'reg_lambda': 9035573.436604433}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:40:20,373]\u001b[0m Trial 37 finished with value: -1.0486256446047015 and parameters: {'max_depth': 28, 'num_leaves': 31, 'learning_rate': 0.2812501938641458, 'n_estimators': 472, 'reg_alpha': 1.526478677032089e-05, 'reg_lambda': 1354203.4866093541}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:41:30,524]\u001b[0m Trial 38 finished with value: -1.0665906623800323 and parameters: {'max_depth': 33, 'num_leaves': 33, 'learning_rate': 0.2663620525197875, 'n_estimators': 498, 'reg_alpha': 1.2452146123312325e-05, 'reg_lambda': 740172.3933158652}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:41:41,825]\u001b[0m Trial 41 finished with value: -1.2071769068224816 and parameters: {'max_depth': 21, 'num_leaves': 15, 'learning_rate': 0.0009860852756278767, 'n_estimators': 402, 'reg_alpha': 9.245053247115957e-06, 'reg_lambda': 13830.052349771599}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:42:29,141]\u001b[0m Trial 45 finished with value: -1.2219569103374988 and parameters: {'max_depth': 25, 'num_leaves': 47, 'learning_rate': 0.9017877234393767, 'n_estimators': 124, 'reg_alpha': 9.288275025032547e-05, 'reg_lambda': 41792.58186887653}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:42:37,033]\u001b[0m Trial 42 finished with value: -1.1733302477701453 and parameters: {'max_depth': 23, 'num_leaves': 45, 'learning_rate': 0.04828415217888583, 'n_estimators': 405, 'reg_alpha': 0.017376559913154496, 'reg_lambda': 32528.69320663536}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:42:58,656]\u001b[0m Trial 43 finished with value: -1.1270452254395187 and parameters: {'max_depth': 24, 'num_leaves': 47, 'learning_rate': 0.03460959175440571, 'n_estimators': 407, 'reg_alpha': 0.02930602056615884, 'reg_lambda': 13972.93821287255}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:43:40,097]\u001b[0m Trial 44 finished with value: -1.221952429159568 and parameters: {'max_depth': 22, 'num_leaves': 46, 'learning_rate': 0.7913995828367855, 'n_estimators': 399, 'reg_alpha': 8.303137608093423e-05, 'reg_lambda': 18853.13115693864}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:43:45,816]\u001b[0m Trial 48 finished with value: -1.0370291361139012 and parameters: {'max_depth': 17, 'num_leaves': 5, 'learning_rate': 0.619286918245086, 'n_estimators': 465, 'reg_alpha': 7.176175057334556e-05, 'reg_lambda': 2216869.72548331}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:43:53,353]\u001b[0m Trial 46 finished with value: -1.091156209991244 and parameters: {'max_depth': 24, 'num_leaves': 41, 'learning_rate': 0.042092189735439704, 'n_estimators': 458, 'reg_alpha': 0.0180474844466747, 'reg_lambda': 1904564.8868074468}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:44:25,738]\u001b[0m Trial 47 finished with value: -1.052921880499162 and parameters: {'max_depth': 25, 'num_leaves': 41, 'learning_rate': 0.961191697782742, 'n_estimators': 456, 'reg_alpha': 6.229702941082422e-05, 'reg_lambda': 2640541.635402283}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:44:48,232]\u001b[0m Trial 49 finished with value: -1.0674009257450847 and parameters: {'max_depth': 19, 'num_leaves': 41, 'learning_rate': 0.9421717270498948, 'n_estimators': 459, 'reg_alpha': 0.0007384588390460914, 'reg_lambda': 2179639.5316721317}. Best is trial 16 with value: -1.032666046715569.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:45:02,853]\u001b[0m A new study created in memory with name: no-name-d74c529c-0204-4396-af47-640d93a4e313\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:45:15,976]\u001b[0m Trial 3 finished with value: -2.427971775385701 and parameters: {'max_depth': 20, 'num_leaves': 7, 'learning_rate': 0.12870308017962434, 'n_estimators': 406, 'reg_alpha': 4346214.592969822, 'reg_lambda': 74102.60975540572}. Best is trial 3 with value: -2.427971775385701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:45:17,595]\u001b[0m Trial 2 finished with value: -2.427971775385701 and parameters: {'max_depth': 12, 'num_leaves': 19, 'learning_rate': 0.7344016078487305, 'n_estimators': 461, 'reg_alpha': 2896211.7485580756, 'reg_lambda': 3.0006733167780575e-06}. Best is trial 3 with value: -2.427971775385701.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:45:19,799]\u001b[0m Trial 0 finished with value: -2.404634099238953 and parameters: {'max_depth': 6, 'num_leaves': 5, 'learning_rate': 0.00013349698163557974, 'n_estimators': 216, 'reg_alpha': 4.819430349425166e-05, 'reg_lambda': 7.554701994434293e-05}. Best is trial 0 with value: -2.404634099238953.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:45:38,254]\u001b[0m Trial 1 finished with value: -2.198378008729539 and parameters: {'max_depth': 18, 'num_leaves': 49, 'learning_rate': 0.7234405445919265, 'n_estimators': 363, 'reg_alpha': 715.2412626710719, 'reg_lambda': 37567.76017499621}. Best is trial 1 with value: -2.198378008729539.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:45:49,219]\u001b[0m Trial 7 finished with value: -2.1229992966216247 and parameters: {'max_depth': 42, 'num_leaves': 46, 'learning_rate': 0.016749224046049383, 'n_estimators': 38, 'reg_alpha': 0.00018455806094508592, 'reg_lambda': 0.01658691813490732}. Best is trial 7 with value: -2.1229992966216247.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:45:52,930]\u001b[0m Trial 5 finished with value: -2.2967114246011646 and parameters: {'max_depth': 0, 'num_leaves': 18, 'learning_rate': 0.2336620413564796, 'n_estimators': 371, 'reg_alpha': 0.07434472247645256, 'reg_lambda': 0.00016327982507149862}. Best is trial 7 with value: -2.1229992966216247.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:45:59,377]\u001b[0m Trial 4 finished with value: -2.4226448000481717 and parameters: {'max_depth': 21, 'num_leaves': 15, 'learning_rate': 1.4765216097739993e-05, 'n_estimators': 417, 'reg_alpha': 193.24161488342634, 'reg_lambda': 0.010997385760912068}. Best is trial 7 with value: -2.1229992966216247.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:46:00,914]\u001b[0m Trial 9 finished with value: -2.4279677897439074 and parameters: {'max_depth': 27, 'num_leaves': 5, 'learning_rate': 1.933366198547516e-06, 'n_estimators': 111, 'reg_alpha': 17.895317495371533, 'reg_lambda': 5624401.437826101}. Best is trial 7 with value: -2.1229992966216247.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:46:07,001]\u001b[0m Trial 6 finished with value: -2.0761887717069443 and parameters: {'max_depth': 25, 'num_leaves': 18, 'learning_rate': 0.01394067266136655, 'n_estimators': 378, 'reg_alpha': 0.004830897880059423, 'reg_lambda': 1.1756655965490697e-05}. Best is trial 6 with value: -2.0761887717069443.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:46:36,519]\u001b[0m Trial 11 finished with value: -1.98755249538674 and parameters: {'max_depth': 45, 'num_leaves': 8, 'learning_rate': 0.009967836257639686, 'n_estimators': 492, 'reg_alpha': 63.93457176482928, 'reg_lambda': 0.09316767497822531}. Best is trial 11 with value: -1.98755249538674.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:46:50,563]\u001b[0m Trial 10 finished with value: -1.9071382240193935 and parameters: {'max_depth': 23, 'num_leaves': 31, 'learning_rate': 0.9751243356162584, 'n_estimators': 436, 'reg_alpha': 7679.3714201656085, 'reg_lambda': 9523442.324811047}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:46:57,160]\u001b[0m Trial 12 finished with value: -2.4279476116609047 and parameters: {'max_depth': 7, 'num_leaves': 41, 'learning_rate': 1.0629128060340551e-07, 'n_estimators': 244, 'reg_alpha': 0.007001640386975071, 'reg_lambda': 0.0006275420646384226}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:47:18,230]\u001b[0m Trial 13 finished with value: -2.3009147609108505 and parameters: {'max_depth': 44, 'num_leaves': 36, 'learning_rate': 0.000791810739950655, 'n_estimators': 217, 'reg_alpha': 1.4147051711098782e-07, 'reg_lambda': 9.451759455641401}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:47:24,178]\u001b[0m Trial 8 finished with value: -1.9221854148164466 and parameters: {'max_depth': 9, 'num_leaves': 50, 'learning_rate': 0.35142316685766767, 'n_estimators': 469, 'reg_alpha': 0.003102080776909134, 'reg_lambda': 2545730.6699172077}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:47:51,438]\u001b[0m Trial 17 finished with value: -2.1179672075636855 and parameters: {'max_depth': 33, 'num_leaves': 29, 'learning_rate': 0.07833596395360619, 'n_estimators': 306, 'reg_alpha': 33787.84470763087, 'reg_lambda': 3724050.874199232}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:47:58,805]\u001b[0m Trial 15 finished with value: -1.9365321067886048 and parameters: {'max_depth': 37, 'num_leaves': 33, 'learning_rate': 0.0037756132500406272, 'n_estimators': 500, 'reg_alpha': 22098.316184722076, 'reg_lambda': 42.17908726895987}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:48:11,641]\u001b[0m Trial 14 finished with value: -1.9293215968313413 and parameters: {'max_depth': 38, 'num_leaves': 36, 'learning_rate': 0.004897279855591864, 'n_estimators': 494, 'reg_alpha': 6004.45835306217, 'reg_lambda': 62.00347325473485}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:48:25,386]\u001b[0m Trial 16 finished with value: -1.9531559337846487 and parameters: {'max_depth': 34, 'num_leaves': 29, 'learning_rate': 0.01671911253675547, 'n_estimators': 489, 'reg_alpha': 8876.8979836273, 'reg_lambda': 17.34886911373315}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:48:42,213]\u001b[0m Trial 19 finished with value: -2.3076589719132685 and parameters: {'max_depth': 13, 'num_leaves': 25, 'learning_rate': 0.7343837663216356, 'n_estimators': 328, 'reg_alpha': 1.1738242873112923, 'reg_lambda': 3240.717347215358}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:48:48,744]\u001b[0m Trial 22 finished with value: -2.2616622186519972 and parameters: {'max_depth': 1, 'num_leaves': 43, 'learning_rate': 0.08207795672848128, 'n_estimators': 151, 'reg_alpha': 2.562176661125755, 'reg_lambda': 5040342.940452595}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:48:50,395]\u001b[0m Trial 20 finished with value: -2.2339699224808403 and parameters: {'max_depth': 15, 'num_leaves': 25, 'learning_rate': 0.9671191995727091, 'n_estimators': 295, 'reg_alpha': 5.156379402106348, 'reg_lambda': 20420.6432389621}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:49:04,434]\u001b[0m Trial 24 finished with value: -2.5507049595697864 and parameters: {'max_depth': 30, 'num_leaves': 37, 'learning_rate': 0.06198499394530181, 'n_estimators': 422, 'reg_alpha': 694551.6607107315, 'reg_lambda': 1882.9020868801235}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:49:08,123]\u001b[0m Trial 21 finished with value: -2.145968630771685 and parameters: {'max_depth': 14, 'num_leaves': 24, 'learning_rate': 0.08414574775585737, 'n_estimators': 281, 'reg_alpha': 1.4899329197114215, 'reg_lambda': 18922.595185660666}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:49:20,866]\u001b[0m Trial 18 finished with value: -2.0564299581212695 and parameters: {'max_depth': 33, 'num_leaves': 33, 'learning_rate': 0.002076360357970115, 'n_estimators': 492, 'reg_alpha': 0.6716472056579437, 'reg_lambda': 205.35104211007777}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:50:04,034]\u001b[0m Trial 23 finished with value: -2.2038945759004345 and parameters: {'max_depth': 29, 'num_leaves': 50, 'learning_rate': 0.07172055102757957, 'n_estimators': 297, 'reg_alpha': 3.895729679578182, 'reg_lambda': 4222.705060865771}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:50:06,287]\u001b[0m Trial 26 finished with value: -2.3213431357966665 and parameters: {'max_depth': 39, 'num_leaves': 40, 'learning_rate': 0.002368457244808214, 'n_estimators': 449, 'reg_alpha': 854.186871579759, 'reg_lambda': 810295.247256015}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:50:08,957]\u001b[0m Trial 25 finished with value: -2.1567497908700517 and parameters: {'max_depth': 40, 'num_leaves': 39, 'learning_rate': 0.0027781149878099115, 'n_estimators': 462, 'reg_alpha': 2184.3947330623164, 'reg_lambda': 194258.3167232246}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:50:22,386]\u001b[0m Trial 29 finished with value: -2.8496924589691277 and parameters: {'max_depth': 7, 'num_leaves': 45, 'learning_rate': 0.1920468906819923, 'n_estimators': 446, 'reg_alpha': 353556.9573999801, 'reg_lambda': 222907.14685123204}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:50:29,188]\u001b[0m Trial 30 finished with value: -2.323925051242117 and parameters: {'max_depth': 47, 'num_leaves': 45, 'learning_rate': 0.2764538773883072, 'n_estimators': 447, 'reg_alpha': 178039.07418216253, 'reg_lambda': 761867.3869915472}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:51:03,781]\u001b[0m Trial 27 finished with value: -2.0821125199465103 and parameters: {'max_depth': 38, 'num_leaves': 50, 'learning_rate': 0.22487822975551586, 'n_estimators': 440, 'reg_alpha': 1199.4025988088138, 'reg_lambda': 263795.92772856954}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:51:21,901]\u001b[0m Trial 32 finished with value: -2.178935771903851 and parameters: {'max_depth': 24, 'num_leaves': 33, 'learning_rate': 0.03551819150624336, 'n_estimators': 343, 'reg_alpha': 67.5518652851803, 'reg_lambda': 713.0118347264521}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:51:24,136]\u001b[0m Trial 31 finished with value: -2.0761327608728983 and parameters: {'max_depth': 24, 'num_leaves': 33, 'learning_rate': 0.32470437145752423, 'n_estimators': 351, 'reg_alpha': 113.42112339174928, 'reg_lambda': 385607.7719021181}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:51:38,700]\u001b[0m Trial 28 finished with value: -2.116401491465834 and parameters: {'max_depth': 39, 'num_leaves': 40, 'learning_rate': 0.26782094283108304, 'n_estimators': 435, 'reg_alpha': 446.0590118107703, 'reg_lambda': 220988.82906730004}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:52:05,576]\u001b[0m Trial 33 finished with value: -2.194915809900066 and parameters: {'max_depth': 24, 'num_leaves': 34, 'learning_rate': 0.03289605557953323, 'n_estimators': 344, 'reg_alpha': 101.97797123204744, 'reg_lambda': 1.62459773207618}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:52:19,600]\u001b[0m Trial 34 finished with value: -2.355392651908594 and parameters: {'max_depth': 36, 'num_leaves': 34, 'learning_rate': 0.00023663569104680722, 'n_estimators': 391, 'reg_alpha': 14957.689816411914, 'reg_lambda': 73.48874921283603}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:52:30,556]\u001b[0m Trial 36 finished with value: -2.3266746323937637 and parameters: {'max_depth': 36, 'num_leaves': 31, 'learning_rate': 0.0003823244972463252, 'n_estimators': 390, 'reg_alpha': 26259.674583394975, 'reg_lambda': 105.6325385587879}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:52:32,241]\u001b[0m Trial 38 finished with value: -2.427971775385701 and parameters: {'max_depth': 18, 'num_leaves': 30, 'learning_rate': 0.005851832569398093, 'n_estimators': 471, 'reg_alpha': 8807299.847740365, 'reg_lambda': 26597.886863832788}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:52:44,349]\u001b[0m Trial 35 finished with value: -2.3108017599434474 and parameters: {'max_depth': 18, 'num_leaves': 31, 'learning_rate': 0.000304065639698524, 'n_estimators': 499, 'reg_alpha': 10235.94387995808, 'reg_lambda': 132.2918746710972}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:52:44,958]\u001b[0m Trial 39 finished with value: -2.427971775385701 and parameters: {'max_depth': 3, 'num_leaves': 21, 'learning_rate': 0.007134156696983711, 'n_estimators': 476, 'reg_alpha': 6396484.0596550545, 'reg_lambda': 52770.529161437305}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:52:50,744]\u001b[0m Trial 40 finished with value: -2.1347860462594435 and parameters: {'max_depth': 10, 'num_leaves': 22, 'learning_rate': 0.6137703653291515, 'n_estimators': 498, 'reg_alpha': 3150.3084566248194, 'reg_lambda': 1.361912086121156}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:52:57,028]\u001b[0m Trial 41 finished with value: -2.427971775385701 and parameters: {'max_depth': 5, 'num_leaves': 22, 'learning_rate': 0.5125339812340193, 'n_estimators': 414, 'reg_alpha': 2029738.0491447507, 'reg_lambda': 1.219678975477325e-07}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:53:01,142]\u001b[0m Trial 37 finished with value: -2.3749156909178817 and parameters: {'max_depth': 37, 'num_leaves': 31, 'learning_rate': 0.00018302299829317005, 'n_estimators': 392, 'reg_alpha': 24158.13424106876, 'reg_lambda': 265.5110583553916}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:53:22,958]\u001b[0m Trial 44 finished with value: -2.9180678748258098 and parameters: {'max_depth': 33, 'num_leaves': 27, 'learning_rate': 0.023045119823221008, 'n_estimators': 473, 'reg_alpha': 250759.3516430452, 'reg_lambda': 12.134459464159761}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:53:25,696]\u001b[0m Trial 46 finished with value: -2.426893076554781 and parameters: {'max_depth': 42, 'num_leaves': 28, 'learning_rate': 0.01988287401518551, 'n_estimators': 7, 'reg_alpha': 104840.05390672137, 'reg_lambda': 7526239.937682049}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:53:25,716]\u001b[0m Trial 43 finished with value: -2.302028409252298 and parameters: {'max_depth': 29, 'num_leaves': 13, 'learning_rate': 0.03692166323563095, 'n_estimators': 409, 'reg_alpha': 117970.64287622613, 'reg_lambda': 4726846.578220582}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:53:27,235]\u001b[0m Trial 45 finished with value: -2.0396804203385184 and parameters: {'max_depth': 32, 'num_leaves': 27, 'learning_rate': 0.022100276280034036, 'n_estimators': 472, 'reg_alpha': 92341.66540510317, 'reg_lambda': 33.23046689126666}. Best is trial 10 with value: -1.9071382240193935.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:53:31,960]\u001b[0m Trial 42 finished with value: -1.906788229977229 and parameters: {'max_depth': 10, 'num_leaves': 13, 'learning_rate': 0.7064610008367309, 'n_estimators': 404, 'reg_alpha': 3023.1644145799883, 'reg_lambda': 6765586.802840695}. Best is trial 42 with value: -1.906788229977229.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:53:54,907]\u001b[0m Trial 49 finished with value: -1.9761481270210304 and parameters: {'max_depth': 27, 'num_leaves': 37, 'learning_rate': 0.14431057420551133, 'n_estimators': 499, 'reg_alpha': 8464.583840128875, 'reg_lambda': 0.476714453146373}. Best is trial 42 with value: -1.906788229977229.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:54:03,550]\u001b[0m Trial 47 finished with value: -1.930005810417399 and parameters: {'max_depth': 21, 'num_leaves': 14, 'learning_rate': 0.009033624016028963, 'n_estimators': 472, 'reg_alpha': 7631.890343417896, 'reg_lambda': 14.26566133286853}. Best is trial 42 with value: -1.906788229977229.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:54:22,073]\u001b[0m Trial 48 finished with value: -1.9771968614891133 and parameters: {'max_depth': 20, 'num_leaves': 36, 'learning_rate': 0.007895667672098204, 'n_estimators': 474, 'reg_alpha': 4969.33482458701, 'reg_lambda': 0.2220180988827525}. Best is trial 42 with value: -1.906788229977229.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 19:54:31,435]\u001b[0m A new study created in memory with name: no-name-4d1aa85f-7002-4184-99d5-5882b7c48f19\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:54:36,670]\u001b[0m Trial 3 finished with value: -2.769194251882477 and parameters: {'max_depth': 16, 'num_leaves': 8, 'learning_rate': 0.002028498611926337, 'n_estimators': 49, 'reg_alpha': 570865.3982804015, 'reg_lambda': 1.0453526604807039e-06}. Best is trial 3 with value: -2.769194251882477.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:54:38,135]\u001b[0m Trial 2 finished with value: -2.759159154556782 and parameters: {'max_depth': 5, 'num_leaves': 9, 'learning_rate': 1.6107064041961144e-06, 'n_estimators': 37, 'reg_alpha': 5.454618703949785, 'reg_lambda': 0.015730247155929005}. Best is trial 2 with value: -2.759159154556782.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:55:12,586]\u001b[0m Trial 0 finished with value: -2.7504644890977197 and parameters: {'max_depth': -1, 'num_leaves': 20, 'learning_rate': 6.416007341701724e-05, 'n_estimators': 274, 'reg_alpha': 226.6458483089805, 'reg_lambda': 11434.088458613927}. Best is trial 0 with value: -2.7504644890977197.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:55:19,162]\u001b[0m Trial 1 finished with value: -2.6845195332190603 and parameters: {'max_depth': -1, 'num_leaves': 23, 'learning_rate': 0.0003384965772151564, 'n_estimators': 320, 'reg_alpha': 3.6658750979855416e-06, 'reg_lambda': 0.00018325698066319434}. Best is trial 1 with value: -2.6845195332190603.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:55:21,146]\u001b[0m Trial 6 finished with value: -2.7586505447764518 and parameters: {'max_depth': 10, 'num_leaves': 12, 'learning_rate': 1.2780848548143324e-05, 'n_estimators': 61, 'reg_alpha': 7.3159868302065725e-06, 'reg_lambda': 0.002006422077191751}. Best is trial 1 with value: -2.6845195332190603.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:55:30,253]\u001b[0m Trial 5 finished with value: -2.7591182097160964 and parameters: {'max_depth': 15, 'num_leaves': 43, 'learning_rate': 4.761470091209326e-07, 'n_estimators': 214, 'reg_alpha': 0.3246232618083043, 'reg_lambda': 2.4344422945380574e-05}. Best is trial 1 with value: -2.6845195332190603.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:55:35,960]\u001b[0m Trial 7 finished with value: -2.757385185566121 and parameters: {'max_depth': 37, 'num_leaves': 37, 'learning_rate': 0.0012658053304917542, 'n_estimators': 133, 'reg_alpha': 0.013088338271145899, 'reg_lambda': 7081207.603121171}. Best is trial 1 with value: -2.6845195332190603.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:55:46,872]\u001b[0m Trial 10 finished with value: -2.7592015043409805 and parameters: {'max_depth': 25, 'num_leaves': 6, 'learning_rate': 0.9928949417512372, 'n_estimators': 380, 'reg_alpha': 9879030.893577851, 'reg_lambda': 8265.718825394362}. Best is trial 1 with value: -2.6845195332190603.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:55:55,361]\u001b[0m Trial 4 finished with value: -2.732928568708 and parameters: {'max_depth': 43, 'num_leaves': 32, 'learning_rate': 0.00034974592654717947, 'n_estimators': 474, 'reg_alpha': 1.5032718043847142e-06, 'reg_lambda': 313184.4539547827}. Best is trial 1 with value: -2.6845195332190603.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:56:07,128]\u001b[0m Trial 8 finished with value: -2.7590422746457715 and parameters: {'max_depth': 8, 'num_leaves': 33, 'learning_rate': 8.613164588169791e-07, 'n_estimators': 231, 'reg_alpha': 1.1462252653904556e-07, 'reg_lambda': 0.001199857960473126}. Best is trial 1 with value: -2.6845195332190603.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:56:12,324]\u001b[0m Trial 11 finished with value: -2.7590502937012586 and parameters: {'max_depth': 40, 'num_leaves': 39, 'learning_rate': 2.296297982735328e-06, 'n_estimators': 136, 'reg_alpha': 585.2948296190608, 'reg_lambda': 20549.15884419945}. Best is trial 1 with value: -2.6845195332190603.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 19:56:50,453]\u001b[0m Trial 9 finished with value: -2.7003298866528294 and parameters: {'max_depth': 24, 'num_leaves': 37, 'learning_rate': 0.0002227795697385215, 'n_estimators': 365, 'reg_alpha': 1.3647228287894091e-06, 'reg_lambda': 132.68209781865886}. Best is trial 1 with value: -2.6845195332190603.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:56:59,013]\u001b[0m Trial 13 finished with value: -2.618687249995297 and parameters: {'max_depth': 30, 'num_leaves': 22, 'learning_rate': 0.018614211401654826, 'n_estimators': 352, 'reg_alpha': 0.00026351705108123994, 'reg_lambda': 4.821016569223132}. Best is trial 13 with value: -2.618687249995297.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:57:22,177]\u001b[0m Trial 14 finished with value: -2.6748900290600024 and parameters: {'max_depth': 29, 'num_leaves': 23, 'learning_rate': 0.00025013713738742435, 'n_estimators': 500, 'reg_alpha': 2.2395018613678197e-05, 'reg_lambda': 3.508071562498242}. Best is trial 13 with value: -2.618687249995297.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:57:36,854]\u001b[0m Trial 12 finished with value: -2.750468527972698 and parameters: {'max_depth': 14, 'num_leaves': 47, 'learning_rate': 5.53986945148519e-05, 'n_estimators': 444, 'reg_alpha': 0.06228263816805471, 'reg_lambda': 74552.00155791473}. Best is trial 13 with value: -2.618687249995297.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:57:46,129]\u001b[0m Trial 15 finished with value: -2.5563245554406255 and parameters: {'max_depth': 26, 'num_leaves': 23, 'learning_rate': 0.007646982539932249, 'n_estimators': 355, 'reg_alpha': 8.660393565620567e-05, 'reg_lambda': 10.116099848330698}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:57:54,173]\u001b[0m Trial 16 finished with value: -2.5621923609326163 and parameters: {'max_depth': 31, 'num_leaves': 22, 'learning_rate': 0.0092454972396032, 'n_estimators': 351, 'reg_alpha': 0.0002654396835050319, 'reg_lambda': 2.0063002413003406}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:58:18,841]\u001b[0m Trial 17 finished with value: -2.6019780689193373 and parameters: {'max_depth': 33, 'num_leaves': 18, 'learning_rate': 0.01628346814365543, 'n_estimators': 489, 'reg_alpha': 0.0006206138488989125, 'reg_lambda': 1.6559152618248631}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:58:31,928]\u001b[0m Trial 19 finished with value: -2.5889078049914342 and parameters: {'max_depth': 33, 'num_leaves': 15, 'learning_rate': 0.024307120364907946, 'n_estimators': 407, 'reg_alpha': 0.0005386249287434304, 'reg_lambda': 0.6926892205517493}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:58:43,808]\u001b[0m Trial 18 finished with value: -2.6170719274353966 and parameters: {'max_depth': 32, 'num_leaves': 18, 'learning_rate': 0.0210974116160348, 'n_estimators': 497, 'reg_alpha': 0.00046326106027689445, 'reg_lambda': 2.894580358698745}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:58:45,517]\u001b[0m Trial 20 finished with value: -2.5984427831634402 and parameters: {'max_depth': 34, 'num_leaves': 17, 'learning_rate': 0.02557189312911542, 'n_estimators': 417, 'reg_alpha': 0.0004250750667509125, 'reg_lambda': 0.05405943438289303}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:59:01,953]\u001b[0m Trial 21 finished with value: -2.601713541402784 and parameters: {'max_depth': 47, 'num_leaves': 15, 'learning_rate': 0.023293179986112373, 'n_estimators': 416, 'reg_alpha': 0.001649699929622309, 'reg_lambda': 0.0868842850797599}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:59:13,797]\u001b[0m Trial 22 finished with value: -2.6684809267161356 and parameters: {'max_depth': 47, 'num_leaves': 30, 'learning_rate': 0.11866182074214283, 'n_estimators': 260, 'reg_alpha': 0.005972551184004527, 'reg_lambda': 200.67368857344104}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:59:37,288]\u001b[0m Trial 24 finished with value: -2.7591733749749316 and parameters: {'max_depth': 19, 'num_leaves': 26, 'learning_rate': 1.2099997009733786e-07, 'n_estimators': 295, 'reg_alpha': 0.006579411556415706, 'reg_lambda': 180.837273926245}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:59:43,401]\u001b[0m Trial 23 finished with value: -2.759167967205211 and parameters: {'max_depth': 20, 'num_leaves': 28, 'learning_rate': 1.3895471829604958e-07, 'n_estimators': 308, 'reg_alpha': 0.009407492065892064, 'reg_lambda': 252.5129218451126}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 19:59:43,861]\u001b[0m Trial 25 finished with value: -2.681391815497703 and parameters: {'max_depth': 20, 'num_leaves': 29, 'learning_rate': 0.1242442451755026, 'n_estimators': 312, 'reg_alpha': 0.008441493293574005, 'reg_lambda': 110.86374959707891}. Best is trial 15 with value: -2.5563245554406255.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:00:04,432]\u001b[0m Trial 26 finished with value: -2.5036323639970766 and parameters: {'max_depth': 20, 'num_leaves': 25, 'learning_rate': 0.0038883705323267243, 'n_estimators': 309, 'reg_alpha': 4.0034436591246544e-05, 'reg_lambda': 85.81496460284305}. Best is trial 26 with value: -2.5036323639970766.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:00:31,956]\u001b[0m Trial 28 finished with value: -2.4597536430823554 and parameters: {'max_depth': 27, 'num_leaves': 13, 'learning_rate': 0.003812797711953942, 'n_estimators': 399, 'reg_alpha': 5.07217006869705e-05, 'reg_lambda': 0.4449016726193089}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:00:37,393]\u001b[0m Trial 30 finished with value: -2.525495945162091 and parameters: {'max_depth': 27, 'num_leaves': 25, 'learning_rate': 0.003908419590836404, 'n_estimators': 182, 'reg_alpha': 1.980245983013746e-05, 'reg_lambda': 9.672268956542723}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:00:39,524]\u001b[0m Trial 27 finished with value: -2.50704212870801 and parameters: {'max_depth': 26, 'num_leaves': 27, 'learning_rate': 0.002996090491623878, 'n_estimators': 321, 'reg_alpha': 5.0482571449755526e-05, 'reg_lambda': 0.4059208888248867}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:00:47,927]\u001b[0m Trial 29 finished with value: -2.4704615640517633 and parameters: {'max_depth': 26, 'num_leaves': 14, 'learning_rate': 0.003551821712497353, 'n_estimators': 394, 'reg_alpha': 3.699776680363839e-05, 'reg_lambda': 0.42696848660381975}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:01:01,684]\u001b[0m Trial 32 finished with value: -2.5732812064612713 and parameters: {'max_depth': 28, 'num_leaves': 13, 'learning_rate': 0.002332194269183336, 'n_estimators': 200, 'reg_alpha': 2.7312332517134052e-05, 'reg_lambda': 1877.3452166815377}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:01:08,851]\u001b[0m Trial 31 finished with value: -2.5290465339641877 and parameters: {'max_depth': 26, 'num_leaves': 26, 'learning_rate': 0.0036601227478981766, 'n_estimators': 188, 'reg_alpha': 3.8260987064987223e-05, 'reg_lambda': 0.1831324687415598}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:01:10,174]\u001b[0m Trial 33 finished with value: -2.595657603853649 and parameters: {'max_depth': 22, 'num_leaves': 12, 'learning_rate': 0.0012147655051671803, 'n_estimators': 261, 'reg_alpha': 1.2309464069985546e-07, 'reg_lambda': 0.23209901776116376}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:01:33,145]\u001b[0m Trial 35 finished with value: -2.631898147288312 and parameters: {'max_depth': 22, 'num_leaves': 11, 'learning_rate': 0.0008322836112603428, 'n_estimators': 281, 'reg_alpha': 1.6424765444598642e-07, 'reg_lambda': 0.3096715151147762}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:01:39,343]\u001b[0m Trial 34 finished with value: -2.51444706182334 and parameters: {'max_depth': 22, 'num_leaves': 12, 'learning_rate': 0.0013743993426156877, 'n_estimators': 446, 'reg_alpha': 1.7138659683931546e-07, 'reg_lambda': 0.12142205218988787}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:01:42,046]\u001b[0m Trial 36 finished with value: -2.6180894584417667 and parameters: {'max_depth': 21, 'num_leaves': 11, 'learning_rate': 0.0009466211785796385, 'n_estimators': 279, 'reg_alpha': 2.3655124988065114e-07, 'reg_lambda': 0.02096486339135287}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:01:53,843]\u001b[0m Trial 39 finished with value: -2.736873705185669 and parameters: {'max_depth': 1, 'num_leaves': 6, 'learning_rate': 0.0005069888583050979, 'n_estimators': 326, 'reg_alpha': 2.4218964111560208e-06, 'reg_lambda': 0.014226673561636791}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:01:54,845]\u001b[0m Trial 37 finished with value: -2.581916130551668 and parameters: {'max_depth': 22, 'num_leaves': 11, 'learning_rate': 0.000912170127370391, 'n_estimators': 387, 'reg_alpha': 2.9019206129478455e-06, 'reg_lambda': 0.013823111298507645}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:02:04,841]\u001b[0m Trial 38 finished with value: -2.601327333690329 and parameters: {'max_depth': 17, 'num_leaves': 5, 'learning_rate': 0.0008122172163120784, 'n_estimators': 446, 'reg_alpha': 5.068814990527576e-06, 'reg_lambda': 0.0038828231260005655}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:02:06,909]\u001b[0m Trial 40 finished with value: -2.679321238932621 and parameters: {'max_depth': 17, 'num_leaves': 5, 'learning_rate': 0.00046701395068735854, 'n_estimators': 330, 'reg_alpha': 3.3954728640277257e-06, 'reg_lambda': 0.0029023673982302217}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:02:45,498]\u001b[0m Trial 42 finished with value: -2.5043349711756853 and parameters: {'max_depth': 17, 'num_leaves': 20, 'learning_rate': 0.004161283288041049, 'n_estimators': 331, 'reg_alpha': 8.627520017567566e-05, 'reg_lambda': 23.10033064559762}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:02:52,787]\u001b[0m Trial 41 finished with value: -2.506637346504789 and parameters: {'max_depth': 17, 'num_leaves': 20, 'learning_rate': 0.004242406301587982, 'n_estimators': 391, 'reg_alpha': 4.866151700660376e-06, 'reg_lambda': 23.239609402202287}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:02:54,077]\u001b[0m Trial 43 finished with value: -2.5020390502536927 and parameters: {'max_depth': 11, 'num_leaves': 20, 'learning_rate': 0.00372305250554576, 'n_estimators': 330, 'reg_alpha': 4.9095969326829405e-05, 'reg_lambda': 0.0003764076379187277}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:03:08,937]\u001b[0m Trial 44 finished with value: -2.5029362957911765 and parameters: {'max_depth': 12, 'num_leaves': 20, 'learning_rate': 0.0028432780256113436, 'n_estimators': 396, 'reg_alpha': 7.376727250792653e-07, 'reg_lambda': 26.058301095319447}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:03:34,094]\u001b[0m Trial 47 finished with value: -2.505330458508173 and parameters: {'max_depth': 12, 'num_leaves': 20, 'learning_rate': 0.006814785713905517, 'n_estimators': 242, 'reg_alpha': 8.769398045501754e-05, 'reg_lambda': 4.306636302296247e-05}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:03:48,129]\u001b[0m Trial 45 finished with value: -2.5015447842420993 and parameters: {'max_depth': 11, 'num_leaves': 20, 'learning_rate': 0.0035948346474682425, 'n_estimators': 382, 'reg_alpha': 4.915915354415142e-05, 'reg_lambda': 22.643927995788346}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:05,190]\u001b[0m Trial 48 finished with value: -2.7098358660287767 and parameters: {'max_depth': 13, 'num_leaves': 14, 'learning_rate': 0.00016413438307447646, 'n_estimators': 461, 'reg_alpha': 1.0168071462357969e-06, 'reg_lambda': 6.199311946756356e-05}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:07,688]\u001b[0m Trial 49 finished with value: -2.700269534975046 and parameters: {'max_depth': 7, 'num_leaves': 8, 'learning_rate': 0.00018326799862991306, 'n_estimators': 459, 'reg_alpha': 6.758051784701826e-07, 'reg_lambda': 1.2313628402959047e-05}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:08,821]\u001b[0m Trial 46 finished with value: -2.5211385553157766 and parameters: {'max_depth': 12, 'num_leaves': 20, 'learning_rate': 0.005510694125013172, 'n_estimators': 393, 'reg_alpha': 7.462681284096985e-07, 'reg_lambda': 13.64742568633316}. Best is trial 28 with value: -2.4597536430823554.\u001b[0m\n",
      " 81%|            | 13/16 [2:54:40<53:39, 1073.25s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:04:18,272]\u001b[0m A new study created in memory with name: no-name-403487c2-54d1-41f7-bd3d-d894038065a1\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:24,867]\u001b[0m Trial 2 finished with value: -1.4821807240258165 and parameters: {'max_depth': 47, 'num_leaves': 15, 'learning_rate': 0.08279917524570182, 'n_estimators': 95, 'reg_alpha': 1087512.1806504994, 'reg_lambda': 1.5116913657558704}. Best is trial 2 with value: -1.4821807240258165.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:26,275]\u001b[0m Trial 1 finished with value: -1.2324093345542757 and parameters: {'max_depth': 36, 'num_leaves': 8, 'learning_rate': 0.1381322564486966, 'n_estimators': 39, 'reg_alpha': 0.00041427678257279784, 'reg_lambda': 48388.16923735934}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:34,158]\u001b[0m Trial 5 finished with value: -1.469186542022535 and parameters: {'max_depth': 8, 'num_leaves': 11, 'learning_rate': 0.0009235656843777994, 'n_estimators': 35, 'reg_alpha': 0.00013660129755574754, 'reg_lambda': 1864.282504022941}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:38,875]\u001b[0m Trial 6 finished with value: -1.3961099880639543 and parameters: {'max_depth': 41, 'num_leaves': 19, 'learning_rate': 0.6620376486029621, 'n_estimators': 12, 'reg_alpha': 0.8021554847201783, 'reg_lambda': 0.007987964425902522}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:42,567]\u001b[0m Trial 4 finished with value: -1.4815468945372825 and parameters: {'max_depth': 15, 'num_leaves': 46, 'learning_rate': 1.0042038822454128e-05, 'n_estimators': 373, 'reg_alpha': 313385.97870124533, 'reg_lambda': 0.0471776781524182}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:47,173]\u001b[0m Trial 8 finished with value: -1.4820790791844283 and parameters: {'max_depth': 1, 'num_leaves': 45, 'learning_rate': 4.049846438143145e-06, 'n_estimators': 71, 'reg_alpha': 3.7579958384583613e-07, 'reg_lambda': 4.359765365361927}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:50,281]\u001b[0m Trial 0 finished with value: -1.4821137682214018 and parameters: {'max_depth': 43, 'num_leaves': 38, 'learning_rate': 9.879234992658384e-07, 'n_estimators': 271, 'reg_alpha': 4.85297683243678e-07, 'reg_lambda': 128629.83112750413}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:04:57,457]\u001b[0m Trial 3 finished with value: -1.3886009264596126 and parameters: {'max_depth': 18, 'num_leaves': 25, 'learning_rate': 0.34157732567665217, 'n_estimators': 254, 'reg_alpha': 0.009189358300094048, 'reg_lambda': 3.3325306587589507e-06}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:05:08,979]\u001b[0m Trial 11 finished with value: -1.263301737937116 and parameters: {'max_depth': 5, 'num_leaves': 24, 'learning_rate': 0.01849675611281767, 'n_estimators': 125, 'reg_alpha': 38608.98754679092, 'reg_lambda': 63.41419222905547}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:05:18,889]\u001b[0m Trial 10 finished with value: -1.481522161657716 and parameters: {'max_depth': 21, 'num_leaves': 32, 'learning_rate': 1.0594621033145315e-05, 'n_estimators': 128, 'reg_alpha': 9.069188190673932e-05, 'reg_lambda': 0.0005563867394094175}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:05:26,176]\u001b[0m Trial 12 finished with value: -1.482115527438804 and parameters: {'max_depth': 38, 'num_leaves': 16, 'learning_rate': 1.2302812209066191e-06, 'n_estimators': 114, 'reg_alpha': 0.04339606647715103, 'reg_lambda': 0.1785581654007432}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:05:39,979]\u001b[0m Trial 14 finished with value: -1.4528645582095217 and parameters: {'max_depth': 33, 'num_leaves': 7, 'learning_rate': 0.01258709531707368, 'n_estimators': 185, 'reg_alpha': 64.72134813138665, 'reg_lambda': 6387963.3019100195}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:05:49,739]\u001b[0m Trial 13 finished with value: -1.4551315300391685 and parameters: {'max_depth': 35, 'num_leaves': 6, 'learning_rate': 0.005109613849957051, 'n_estimators': 456, 'reg_alpha': 132.42058747152024, 'reg_lambda': 6989106.028326093}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:05:55,089]\u001b[0m Trial 15 finished with value: -1.2658623175060797 and parameters: {'max_depth': 28, 'num_leaves': 5, 'learning_rate': 0.017639499193683093, 'n_estimators': 181, 'reg_alpha': 216.0696902745316, 'reg_lambda': 327.3943547689733}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:06:07,203]\u001b[0m Trial 17 finished with value: -1.2511287245828049 and parameters: {'max_depth': -1, 'num_leaves': 24, 'learning_rate': 0.0797757473903699, 'n_estimators': 184, 'reg_alpha': 23038.215358351757, 'reg_lambda': 493.0901991257979}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:06:14,072]\u001b[0m Trial 7 finished with value: -1.3478013232897041 and parameters: {'max_depth': 24, 'num_leaves': 34, 'learning_rate': 0.020191680819259178, 'n_estimators': 476, 'reg_alpha': 1.4630534641015044e-06, 'reg_lambda': 1.4330486051666362}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:06:21,562]\u001b[0m Trial 16 finished with value: -1.254487002156878 and parameters: {'max_depth': 29, 'num_leaves': 23, 'learning_rate': 0.03826603188475985, 'n_estimators': 194, 'reg_alpha': 4389.744634776556, 'reg_lambda': 385.0664921754864}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:06:26,677]\u001b[0m Trial 19 finished with value: -1.2394449792627085 and parameters: {'max_depth': 11, 'num_leaves': 21, 'learning_rate': 0.7354129272029097, 'n_estimators': 313, 'reg_alpha': 20139.78748485738, 'reg_lambda': 26148.548148403082}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:06:27,492]\u001b[0m Trial 18 finished with value: -1.2676836202989052 and parameters: {'max_depth': 27, 'num_leaves': 33, 'learning_rate': 0.6504391490916438, 'n_estimators': 363, 'reg_alpha': 2640.5346544688678, 'reg_lambda': 24194.115859639416}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:06:34,624]\u001b[0m Trial 20 finished with value: -1.4821807240258165 and parameters: {'max_depth': 13, 'num_leaves': 30, 'learning_rate': 0.9339504399542544, 'n_estimators': 332, 'reg_alpha': 4703544.423375436, 'reg_lambda': 11699.76556607726}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:06:39,909]\u001b[0m Trial 21 finished with value: -1.4821807240258165 and parameters: {'max_depth': 12, 'num_leaves': 12, 'learning_rate': 0.619797726796932, 'n_estimators': 335, 'reg_alpha': 5720867.427637481, 'reg_lambda': 36171.907600987484}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:06:41,180]\u001b[0m Trial 22 finished with value: -1.4821807240258165 and parameters: {'max_depth': 12, 'num_leaves': 12, 'learning_rate': 0.0022112952223530932, 'n_estimators': 348, 'reg_alpha': 1695390.2700436476, 'reg_lambda': 569420.7328656386}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:06:42,962]\u001b[0m Trial 9 finished with value: -1.4780398214814447 and parameters: {'max_depth': 30, 'num_leaves': 40, 'learning_rate': 1.76817939134909e-05, 'n_estimators': 456, 'reg_alpha': 0.011617311191862933, 'reg_lambda': 0.019961186031606317}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:07:01,334]\u001b[0m Trial 24 finished with value: -1.2812273203130449 and parameters: {'max_depth': -1, 'num_leaves': 20, 'learning_rate': 0.15368638435870055, 'n_estimators': 287, 'reg_alpha': 73105.36100655528, 'reg_lambda': 600592.214826547}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:07:06,082]\u001b[0m Trial 23 finished with value: -1.3940037240833858 and parameters: {'max_depth': 11, 'num_leaves': 13, 'learning_rate': 0.0020033543386610343, 'n_estimators': 297, 'reg_alpha': 6.808252434091952, 'reg_lambda': 238812.6358640099}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:07:22,421]\u001b[0m Trial 25 finished with value: -1.3246575526756361 and parameters: {'max_depth': 0, 'num_leaves': 21, 'learning_rate': 0.12541368850092402, 'n_estimators': 283, 'reg_alpha': 7.4241069165589515, 'reg_lambda': 2250.960586427081}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:07:24,339]\u001b[0m Trial 26 finished with value: -1.322123610187965 and parameters: {'max_depth': 0, 'num_leaves': 20, 'learning_rate': 0.10239395387729415, 'n_estimators': 296, 'reg_alpha': 5.898671820012106, 'reg_lambda': 4402.945562409581}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:07:31,326]\u001b[0m Trial 28 finished with value: -1.244620246743192 and parameters: {'max_depth': 4, 'num_leaves': 28, 'learning_rate': 0.06989913595739264, 'n_estimators': 410, 'reg_alpha': 4629.851563148363, 'reg_lambda': 2433.616203333597}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:07:38,366]\u001b[0m Trial 27 finished with value: -1.3351046188724651 and parameters: {'max_depth': 6, 'num_leaves': 28, 'learning_rate': 0.11472261143883618, 'n_estimators': 227, 'reg_alpha': 11.414347047200387, 'reg_lambda': 3761.436623873823}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:07:42,083]\u001b[0m Trial 29 finished with value: -1.2386217262265589 and parameters: {'max_depth': 5, 'num_leaves': 27, 'learning_rate': 0.08872090013039932, 'n_estimators': 215, 'reg_alpha': 6559.577250136622, 'reg_lambda': 36.93689626032971}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:07:52,950]\u001b[0m Trial 31 finished with value: -1.296769628979915 and parameters: {'max_depth': 5, 'num_leaves': 30, 'learning_rate': 0.23888892484928678, 'n_estimators': 418, 'reg_alpha': 2105.740648616795, 'reg_lambda': 24.53275085323896}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:07:53,166]\u001b[0m Trial 33 finished with value: -1.3512709052866216 and parameters: {'max_depth': 18, 'num_leaves': 37, 'learning_rate': 0.30076509018795156, 'n_estimators': 225, 'reg_alpha': 116220.58665076706, 'reg_lambda': 35.13237935523515}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:08:02,161]\u001b[0m Trial 30 finished with value: -1.2761727574199826 and parameters: {'max_depth': 5, 'num_leaves': 28, 'learning_rate': 0.05978003186052637, 'n_estimators': 225, 'reg_alpha': 2535.089002200995, 'reg_lambda': 43.0258520731725}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:08:16,649]\u001b[0m Trial 36 finished with value: -1.4821807240258165 and parameters: {'max_depth': 46, 'num_leaves': 17, 'learning_rate': 0.037660654920620415, 'n_estimators': 415, 'reg_alpha': 463943.7389909985, 'reg_lambda': 49642.401635926646}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:08:42,804]\u001b[0m Trial 37 finished with value: -1.2343688952675642 and parameters: {'max_depth': 9, 'num_leaves': 37, 'learning_rate': 0.26316167722458117, 'n_estimators': 391, 'reg_alpha': 10972.28576616101, 'reg_lambda': 115828.96038070462}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:08:56,549]\u001b[0m Trial 38 finished with value: -1.4821807240258165 and parameters: {'max_depth': 9, 'num_leaves': 40, 'learning_rate': 0.30330963441865, 'n_estimators': 379, 'reg_alpha': 641485.3064569056, 'reg_lambda': 95525.71874211942}. Best is trial 1 with value: -1.2324093345542757.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:03,789]\u001b[0m Trial 39 finished with value: -1.2317681549155983 and parameters: {'max_depth': 18, 'num_leaves': 9, 'learning_rate': 0.9749008514187527, 'n_estimators': 63, 'reg_alpha': 551.8146699386454, 'reg_lambda': 1673307.0979705136}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:09:07,182]\u001b[0m Trial 35 finished with value: -1.2468880467369114 and parameters: {'max_depth': 8, 'num_leaves': 28, 'learning_rate': 0.03961177338938058, 'n_estimators': 414, 'reg_alpha': 1091.7467531188754, 'reg_lambda': 67715.5757134678}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:14,930]\u001b[0m Trial 34 finished with value: -1.247258201027512 and parameters: {'max_depth': 8, 'num_leaves': 37, 'learning_rate': 0.05545739656456374, 'n_estimators': 404, 'reg_alpha': 937.034810214432, 'reg_lambda': 80561.28052591126}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:15,036]\u001b[0m Trial 40 finished with value: -1.2608403514818827 and parameters: {'max_depth': 16, 'num_leaves': 49, 'learning_rate': 0.2009246492699316, 'n_estimators': 67, 'reg_alpha': 643.3468891810894, 'reg_lambda': 1294335.8619956963}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:16,180]\u001b[0m Trial 32 finished with value: -1.4536540987385849 and parameters: {'max_depth': 19, 'num_leaves': 37, 'learning_rate': 0.00019100612067555282, 'n_estimators': 405, 'reg_alpha': 1398.5192727959572, 'reg_lambda': 29.575453627277533}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:17,933]\u001b[0m Trial 42 finished with value: -1.472991076331882 and parameters: {'max_depth': 18, 'num_leaves': 9, 'learning_rate': 0.25141893208186095, 'n_estimators': 5, 'reg_alpha': 162299.1822120266, 'reg_lambda': 1272089.2361737995}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:18,798]\u001b[0m Trial 43 finished with value: -1.3847534633280998 and parameters: {'max_depth': 23, 'num_leaves': 8, 'learning_rate': 0.3014187197310503, 'n_estimators': 9, 'reg_alpha': 0.5618499121698642, 'reg_lambda': 1576539.2684978724}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:20,899]\u001b[0m Trial 44 finished with value: -1.2864587980760191 and parameters: {'max_depth': 23, 'num_leaves': 8, 'learning_rate': 0.5012869033003459, 'n_estimators': 26, 'reg_alpha': 16941.405095233215, 'reg_lambda': 1939287.1767269853}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:22,720]\u001b[0m Trial 41 finished with value: -1.2394745393326814 and parameters: {'max_depth': 16, 'num_leaves': 49, 'learning_rate': 0.29371625455369277, 'n_estimators': 59, 'reg_alpha': 533.4991011559538, 'reg_lambda': 484537.0170115484}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:23,361]\u001b[0m Trial 45 finished with value: -1.2338717018480498 and parameters: {'max_depth': 15, 'num_leaves': 8, 'learning_rate': 0.9620977964269903, 'n_estimators': 33, 'reg_alpha': 16748.32883587502, 'reg_lambda': 230116.73545966827}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:26,024]\u001b[0m Trial 46 finished with value: -1.238371172324127 and parameters: {'max_depth': 15, 'num_leaves': 43, 'learning_rate': 0.5887441063099008, 'n_estimators': 45, 'reg_alpha': 16512.28805902718, 'reg_lambda': 301481.80170316715}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:26,855]\u001b[0m Trial 47 finished with value: -1.2376848061163372 and parameters: {'max_depth': 3, 'num_leaves': 15, 'learning_rate': 0.8795604447151931, 'n_estimators': 50, 'reg_alpha': 15691.401549183463, 'reg_lambda': 241372.36163516855}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:27,511]\u001b[0m Trial 49 finished with value: -1.244314511918589 and parameters: {'max_depth': 14, 'num_leaves': 10, 'learning_rate': 0.9881288637274, 'n_estimators': 49, 'reg_alpha': 13781.743841667814, 'reg_lambda': 11944.890680968709}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:28,657]\u001b[0m Trial 48 finished with value: -1.2345422194878544 and parameters: {'max_depth': 3, 'num_leaves': 14, 'learning_rate': 0.9952797755066853, 'n_estimators': 143, 'reg_alpha': 13997.840266154084, 'reg_lambda': 16690.43987260872}. Best is trial 39 with value: -1.2317681549155983.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:09:31,703]\u001b[0m A new study created in memory with name: no-name-6336f869-bc91-4480-acf4-040759a6e2d6\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:41,244]\u001b[0m Trial 2 finished with value: -2.670016931810663 and parameters: {'max_depth': 1, 'num_leaves': 11, 'learning_rate': 0.5425591239177293, 'n_estimators': 297, 'reg_alpha': 538.581468934772, 'reg_lambda': 0.00518657689074385}. Best is trial 2 with value: -2.670016931810663.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:46,835]\u001b[0m Trial 1 finished with value: -2.5804688231019246 and parameters: {'max_depth': 6, 'num_leaves': 22, 'learning_rate': 1.2044438053255755e-05, 'n_estimators': 110, 'reg_alpha': 0.11721032448790064, 'reg_lambda': 0.0019910229598507877}. Best is trial 1 with value: -2.5804688231019246.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:09:57,004]\u001b[0m Trial 3 finished with value: -2.471001734524206 and parameters: {'max_depth': 3, 'num_leaves': 17, 'learning_rate': 0.0023714405195409266, 'n_estimators': 472, 'reg_alpha': 0.19781752652774012, 'reg_lambda': 3872.5982690025735}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:10:12,610]\u001b[0m Trial 0 finished with value: -2.697355387283447 and parameters: {'max_depth': 27, 'num_leaves': 29, 'learning_rate': 0.005592096929832437, 'n_estimators': 266, 'reg_alpha': 3.2323996806806966e-05, 'reg_lambda': 1.0607225919053873e-05}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:10:16,410]\u001b[0m Trial 4 finished with value: -2.5806676814375384 and parameters: {'max_depth': 27, 'num_leaves': 32, 'learning_rate': 3.215513908943838e-06, 'n_estimators': 212, 'reg_alpha': 2.9640787768082086e-07, 'reg_lambda': 2.2729322871866333e-05}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:10:23,146]\u001b[0m Trial 8 finished with value: -2.5710734896109324 and parameters: {'max_depth': 17, 'num_leaves': 49, 'learning_rate': 0.006464838944074502, 'n_estimators': 181, 'reg_alpha': 107908.10220575234, 'reg_lambda': 55702.34835801227}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:10:36,881]\u001b[0m Trial 6 finished with value: -2.5805287878984906 and parameters: {'max_depth': 44, 'num_leaves': 33, 'learning_rate': 3.440923678185039e-06, 'n_estimators': 269, 'reg_alpha': 3309.3177740436518, 'reg_lambda': 0.005208075050074525}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:04,948]\u001b[0m Trial 5 finished with value: -2.58083231175241 and parameters: {'max_depth': 0, 'num_leaves': 41, 'learning_rate': 1.3072213005211282e-07, 'n_estimators': 405, 'reg_alpha': 2.3848156989096365e-07, 'reg_lambda': 3.423528195260709e-05}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:08,792]\u001b[0m Trial 7 finished with value: -2.579642135276907 and parameters: {'max_depth': 33, 'num_leaves': 39, 'learning_rate': 1.3648452997150349e-05, 'n_estimators': 302, 'reg_alpha': 81.74701741394901, 'reg_lambda': 5.379675377140432e-07}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:13,271]\u001b[0m Trial 12 finished with value: -2.5808458196366466 and parameters: {'max_depth': 38, 'num_leaves': 29, 'learning_rate': 3.3536216807501703e-07, 'n_estimators': 20, 'reg_alpha': 6.259378514547663e-06, 'reg_lambda': 83.38972602790705}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:17,677]\u001b[0m Trial 11 finished with value: -2.607802962167466 and parameters: {'max_depth': 1, 'num_leaves': 25, 'learning_rate': 0.09905321013465464, 'n_estimators': 491, 'reg_alpha': 0.00020051901012072205, 'reg_lambda': 0.2266585945205819}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:11:18,517]\u001b[0m Trial 10 finished with value: -2.5807966698874436 and parameters: {'max_depth': 44, 'num_leaves': 25, 'learning_rate': 2.4621301675188157e-05, 'n_estimators': 360, 'reg_alpha': 1.7464084572220487e-05, 'reg_lambda': 5471234.493079898}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:23,289]\u001b[0m Trial 14 finished with value: -2.5808475747458104 and parameters: {'max_depth': 13, 'num_leaves': 49, 'learning_rate': 0.0012832457504375625, 'n_estimators': 151, 'reg_alpha': 7889284.853869872, 'reg_lambda': 1462862.6453817026}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:24,219]\u001b[0m Trial 13 finished with value: -2.5808475747458104 and parameters: {'max_depth': 13, 'num_leaves': 7, 'learning_rate': 0.0003942837052811676, 'n_estimators': 457, 'reg_alpha': 5879780.94290937, 'reg_lambda': 8569253.750627717}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:24,327]\u001b[0m Trial 15 finished with value: -2.5808475747458104 and parameters: {'max_depth': 13, 'num_leaves': 50, 'learning_rate': 0.00116077346218187, 'n_estimators': 175, 'reg_alpha': 4748593.386000909, 'reg_lambda': 7838.806380474391}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:34,230]\u001b[0m Trial 18 finished with value: -2.5293541751161572 and parameters: {'max_depth': 19, 'num_leaves': 18, 'learning_rate': 0.011791341622120402, 'n_estimators': 81, 'reg_alpha': 0.09257253599546887, 'reg_lambda': 4603.827750946504}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:38,459]\u001b[0m Trial 19 finished with value: -2.5552307869373947 and parameters: {'max_depth': 22, 'num_leaves': 16, 'learning_rate': 0.029311164347901035, 'n_estimators': 34, 'reg_alpha': 0.13537952883096738, 'reg_lambda': 224.1544581778097}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:41,912]\u001b[0m Trial 17 finished with value: -2.5224990433387253 and parameters: {'max_depth': 16, 'num_leaves': 17, 'learning_rate': 0.00768704481367035, 'n_estimators': 168, 'reg_alpha': 0.07272525350169798, 'reg_lambda': 7234.847026768115}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:43,758]\u001b[0m Trial 9 finished with value: -2.5783574669341345 and parameters: {'max_depth': 25, 'num_leaves': 48, 'learning_rate': 1.971134432729475e-05, 'n_estimators': 377, 'reg_alpha': 846.8441959234405, 'reg_lambda': 0.0017097084478664842}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:11:50,698]\u001b[0m Trial 20 finished with value: -2.5780797818555548 and parameters: {'max_depth': 7, 'num_leaves': 18, 'learning_rate': 0.00011147778664069364, 'n_estimators': 109, 'reg_alpha': 0.0049373844506175124, 'reg_lambda': 56.87014779573389}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:00,649]\u001b[0m Trial 22 finished with value: -2.572831237794411 and parameters: {'max_depth': 6, 'num_leaves': 5, 'learning_rate': 0.00013383159868590684, 'n_estimators': 334, 'reg_alpha': 0.0028096240884167324, 'reg_lambda': 9.233886720390831}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:01,082]\u001b[0m Trial 23 finished with value: -2.7559166388631295 and parameters: {'max_depth': 8, 'num_leaves': 5, 'learning_rate': 0.10249009517679443, 'n_estimators': 220, 'reg_alpha': 29.467983846456857, 'reg_lambda': 3.4375146302875765}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:03,208]\u001b[0m Trial 16 finished with value: -2.618514712593541 and parameters: {'max_depth': 18, 'num_leaves': 12, 'learning_rate': 0.007098298637257931, 'n_estimators': 482, 'reg_alpha': 1.3718842271518286, 'reg_lambda': 4399.366347432304}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:09,538]\u001b[0m Trial 25 finished with value: -2.5112358806690898 and parameters: {'max_depth': 19, 'num_leaves': 15, 'learning_rate': 0.008046579898715179, 'n_estimators': 75, 'reg_alpha': 2.173407189615952, 'reg_lambda': 3325.7354191679296}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:10,221]\u001b[0m Trial 24 finished with value: -2.5194811587041483 and parameters: {'max_depth': 20, 'num_leaves': 15, 'learning_rate': 0.011471631853519062, 'n_estimators': 82, 'reg_alpha': 8.254105016774664, 'reg_lambda': 3441.4038668791754}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:14,195]\u001b[0m Trial 26 finished with value: -2.48350973906594 and parameters: {'max_depth': 19, 'num_leaves': 19, 'learning_rate': 0.025154004615449133, 'n_estimators': 88, 'reg_alpha': 6.093727368170675, 'reg_lambda': 194210.1485508426}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:14,939]\u001b[0m Trial 27 finished with value: -2.572166063083526 and parameters: {'max_depth': 30, 'num_leaves': 13, 'learning_rate': 0.002511426219902875, 'n_estimators': 53, 'reg_alpha': 9.386474120338766, 'reg_lambda': 283699.27020491596}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:16,483]\u001b[0m Trial 21 finished with value: -2.5643319415729104 and parameters: {'max_depth': 7, 'num_leaves': 14, 'learning_rate': 0.0001958672171199989, 'n_estimators': 369, 'reg_alpha': 0.0024812362925086956, 'reg_lambda': 21.959583440831977}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:16,677]\u001b[0m Trial 29 finished with value: -2.5801829555072655 and parameters: {'max_depth': 30, 'num_leaves': 21, 'learning_rate': 0.0016821671523501306, 'n_estimators': 6, 'reg_alpha': 14.964489190835726, 'reg_lambda': 275285.8757241404}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:16,973]\u001b[0m Trial 28 finished with value: -2.5722995060309644 and parameters: {'max_depth': 31, 'num_leaves': 12, 'learning_rate': 0.001569026644828414, 'n_estimators': 62, 'reg_alpha': 4.18440851140492, 'reg_lambda': 189410.52210699226}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:17,091]\u001b[0m Trial 30 finished with value: -2.5730491847353174 and parameters: {'max_depth': 35, 'num_leaves': 22, 'learning_rate': 0.03410653098462848, 'n_estimators': 3, 'reg_alpha': 1.2966997392397361, 'reg_lambda': 214165.78318849998}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:26,191]\u001b[0m Trial 33 finished with value: -2.658927216464806 and parameters: {'max_depth': 37, 'num_leaves': 9, 'learning_rate': 0.04755748417917935, 'n_estimators': 117, 'reg_alpha': 0.7212266724104064, 'reg_lambda': 504.59525693106013}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:26,528]\u001b[0m Trial 34 finished with value: -2.579985700221725 and parameters: {'max_depth': 22, 'num_leaves': 9, 'learning_rate': 0.020874732254380704, 'n_estimators': 129, 'reg_alpha': 0.9633169141272137, 'reg_lambda': 711.7051378933123}. Best is trial 3 with value: -2.471001734524206.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:32,076]\u001b[0m Trial 31 finished with value: -2.4598991085805983 and parameters: {'max_depth': 35, 'num_leaves': 21, 'learning_rate': 0.0391766044696969, 'n_estimators': 124, 'reg_alpha': 0.7757833173501965, 'reg_lambda': 129691.0748620987}. Best is trial 31 with value: -2.4598991085805983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:36,703]\u001b[0m Trial 35 finished with value: -2.55046590188275 and parameters: {'max_depth': 22, 'num_leaves': 20, 'learning_rate': 0.012414803015611995, 'n_estimators': 83, 'reg_alpha': 75.52363297808142, 'reg_lambda': 1692.1746077124353}. Best is trial 31 with value: -2.4598991085805983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:37,014]\u001b[0m Trial 36 finished with value: -2.515538545057164 and parameters: {'max_depth': 10, 'num_leaves': 20, 'learning_rate': 0.0050628013818175225, 'n_estimators': 94, 'reg_alpha': 96.84009398026843, 'reg_lambda': 33879.90020779641}. Best is trial 31 with value: -2.4598991085805983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:42,111]\u001b[0m Trial 32 finished with value: -2.8286057672431064 and parameters: {'max_depth': 23, 'num_leaves': 9, 'learning_rate': 0.05698356883521487, 'n_estimators': 430, 'reg_alpha': 1.0145842521501838, 'reg_lambda': 399.376910669133}. Best is trial 31 with value: -2.4598991085805983.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:12:58,387]\u001b[0m Trial 37 finished with value: -2.8791427195553543 and parameters: {'max_depth': 26, 'num_leaves': 20, 'learning_rate': 0.46713290313032385, 'n_estimators': 239, 'reg_alpha': 98.07320740511625, 'reg_lambda': 18785.122512494527}. Best is trial 31 with value: -2.4598991085805983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:12:59,780]\u001b[0m Trial 40 finished with value: -2.470820563713572 and parameters: {'max_depth': 4, 'num_leaves': 26, 'learning_rate': 0.21864850140621106, 'n_estimators': 220, 'reg_alpha': 0.023180656386452662, 'reg_lambda': 1092344.0725184178}. Best is trial 31 with value: -2.4598991085805983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:04,152]\u001b[0m Trial 38 finished with value: -2.869451010324597 and parameters: {'max_depth': 26, 'num_leaves': 24, 'learning_rate': 0.4066381159514586, 'n_estimators': 207, 'reg_alpha': 0.015647712029957257, 'reg_lambda': 36815.196477520614}. Best is trial 31 with value: -2.4598991085805983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:05,640]\u001b[0m Trial 39 finished with value: -2.884196223176268 and parameters: {'max_depth': 27, 'num_leaves': 25, 'learning_rate': 0.7520256349834927, 'n_estimators': 216, 'reg_alpha': 0.022974841538926163, 'reg_lambda': 41957.15855121811}. Best is trial 31 with value: -2.4598991085805983.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:08,113]\u001b[0m Trial 41 finished with value: -2.4473935522016976 and parameters: {'max_depth': 3, 'num_leaves': 25, 'learning_rate': 0.2145416776537465, 'n_estimators': 143, 'reg_alpha': 0.02272644135816216, 'reg_lambda': 995766.3199659981}. Best is trial 41 with value: -2.4473935522016976.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:15,736]\u001b[0m Trial 43 finished with value: -2.4443606753709624 and parameters: {'max_depth': 4, 'num_leaves': 32, 'learning_rate': 0.1785470879218443, 'n_estimators': 141, 'reg_alpha': 0.2770777444298408, 'reg_lambda': 1621219.299449801}. Best is trial 43 with value: -2.4443606753709624.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:16,803]\u001b[0m Trial 42 finished with value: -2.4742647713089587 and parameters: {'max_depth': 3, 'num_leaves': 25, 'learning_rate': 0.3034313566773772, 'n_estimators': 302, 'reg_alpha': 0.035359137326488536, 'reg_lambda': 1761791.4831531844}. Best is trial 43 with value: -2.4443606753709624.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:20,187]\u001b[0m Trial 45 finished with value: -2.4430755315075334 and parameters: {'max_depth': 4, 'num_leaves': 32, 'learning_rate': 0.252105778954323, 'n_estimators': 143, 'reg_alpha': 0.309631345630742, 'reg_lambda': 1870685.8399355435}. Best is trial 45 with value: -2.4430755315075334.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:24,497]\u001b[0m Trial 46 finished with value: -2.443796094441737 and parameters: {'max_depth': 3, 'num_leaves': 31, 'learning_rate': 0.21699206568350676, 'n_estimators': 142, 'reg_alpha': 0.18555201469000515, 'reg_lambda': 1299344.4342154567}. Best is trial 45 with value: -2.4430755315075334.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:26,238]\u001b[0m Trial 44 finished with value: -2.451364999307372 and parameters: {'max_depth': 4, 'num_leaves': 32, 'learning_rate': 0.18842820383029968, 'n_estimators': 277, 'reg_alpha': 0.24201728389085453, 'reg_lambda': 1836920.6174130423}. Best is trial 45 with value: -2.4430755315075334.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:35,980]\u001b[0m Trial 48 finished with value: -2.445017308479081 and parameters: {'max_depth': -1, 'num_leaves': 33, 'learning_rate': 0.2381858531189529, 'n_estimators': 139, 'reg_alpha': 0.2139593141595617, 'reg_lambda': 1974491.3075206522}. Best is trial 45 with value: -2.4430755315075334.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:39,718]\u001b[0m Trial 49 finished with value: -2.4693419975633497 and parameters: {'max_depth': -1, 'num_leaves': 34, 'learning_rate': 0.7925215035988141, 'n_estimators': 141, 'reg_alpha': 0.18169037394322157, 'reg_lambda': 2730689.3622251404}. Best is trial 45 with value: -2.4430755315075334.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:13:43,590]\u001b[0m Trial 47 finished with value: -2.4524623624801145 and parameters: {'max_depth': -1, 'num_leaves': 34, 'learning_rate': 0.15414461911296756, 'n_estimators': 268, 'reg_alpha': 0.20822015453240247, 'reg_lambda': 1440289.164470283}. Best is trial 45 with value: -2.4430755315075334.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:13:47,811]\u001b[0m A new study created in memory with name: no-name-ad296d82-57c9-413d-a769-a3811db3ece2\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:14:08,503]\u001b[0m Trial 3 finished with value: -2.6625598760317395 and parameters: {'max_depth': 14, 'num_leaves': 19, 'learning_rate': 1.132411498888977e-05, 'n_estimators': 200, 'reg_alpha': 60428.90175735102, 'reg_lambda': 87169.58561546338}. Best is trial 3 with value: -2.6625598760317395.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:14:18,126]\u001b[0m Trial 0 finished with value: -2.6629211942677684 and parameters: {'max_depth': 29, 'num_leaves': 5, 'learning_rate': 7.924299156195186e-07, 'n_estimators': 461, 'reg_alpha': 7.564804672026946, 'reg_lambda': 62776.634174300445}. Best is trial 3 with value: -2.6625598760317395.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:14:26,088]\u001b[0m Trial 5 finished with value: -2.663056071547506 and parameters: {'max_depth': 38, 'num_leaves': 10, 'learning_rate': 0.03820682637995399, 'n_estimators': 226, 'reg_alpha': 843364.9800156603, 'reg_lambda': 5959.372037293259}. Best is trial 3 with value: -2.6625598760317395.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:14:37,612]\u001b[0m Trial 4 finished with value: -2.6543351225581224 and parameters: {'max_depth': 29, 'num_leaves': 26, 'learning_rate': 0.00010557988163419257, 'n_estimators': 186, 'reg_alpha': 4492.024655038478, 'reg_lambda': 21244.1920920908}. Best is trial 4 with value: -2.6543351225581224.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:14:37,854]\u001b[0m Trial 2 finished with value: -2.3548140743845343 and parameters: {'max_depth': 29, 'num_leaves': 45, 'learning_rate': 0.01985393113199431, 'n_estimators': 230, 'reg_alpha': 3.5593014320858622, 'reg_lambda': 108178.41784091365}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:14:49,338]\u001b[0m Trial 1 finished with value: -2.6541595244363547 and parameters: {'max_depth': 18, 'num_leaves': 47, 'learning_rate': 6.11817037269718e-05, 'n_estimators': 234, 'reg_alpha': 0.0034436689810013773, 'reg_lambda': 0.12358123672939099}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:14:50,609]\u001b[0m Trial 7 finished with value: -2.6629807074673346 and parameters: {'max_depth': 30, 'num_leaves': 28, 'learning_rate': 2.0344508506083555e-06, 'n_estimators': 70, 'reg_alpha': 0.5428073421569929, 'reg_lambda': 9667.250524211708}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:15:05,466]\u001b[0m Trial 9 finished with value: -2.6624743021863133 and parameters: {'max_depth': 46, 'num_leaves': 43, 'learning_rate': 1.3667512888935076e-05, 'n_estimators': 100, 'reg_alpha': 26981.17734643874, 'reg_lambda': 0.0001479138099312805}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:15:11,180]\u001b[0m Trial 11 finished with value: -2.663056071547506 and parameters: {'max_depth': 33, 'num_leaves': 35, 'learning_rate': 7.896100394223046e-07, 'n_estimators': 134, 'reg_alpha': 3374477.395602855, 'reg_lambda': 1.5153865394711876e-07}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:15:19,268]\u001b[0m Trial 10 finished with value: -2.389435437499916 and parameters: {'max_depth': 21, 'num_leaves': 8, 'learning_rate': 0.1338736142775598, 'n_estimators': 384, 'reg_alpha': 1.554863827163016, 'reg_lambda': 9295.29254707412}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:15:21,592]\u001b[0m Trial 13 finished with value: -2.6630053012346226 and parameters: {'max_depth': -1, 'num_leaves': 50, 'learning_rate': 0.00417112764144239, 'n_estimators': 1, 'reg_alpha': 6.728186749916794e-07, 'reg_lambda': 6324443.989136278}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:15:26,307]\u001b[0m Trial 6 finished with value: -2.6630256753130155 and parameters: {'max_depth': 47, 'num_leaves': 40, 'learning_rate': 1.7350918114906567e-07, 'n_estimators': 271, 'reg_alpha': 819.031575726775, 'reg_lambda': 6.654320949985107e-07}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:15:58,571]\u001b[0m Trial 14 finished with value: -2.635961028128872 and parameters: {'max_depth': 10, 'num_leaves': 18, 'learning_rate': 0.731555693670087, 'n_estimators': 381, 'reg_alpha': 19.940417676606423, 'reg_lambda': 105.84307433685696}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:15:58,609]\u001b[0m Trial 15 finished with value: -2.6762406770671907 and parameters: {'max_depth': 12, 'num_leaves': 16, 'learning_rate': 0.9654435484080457, 'n_estimators': 361, 'reg_alpha': 1.439653419082382, 'reg_lambda': 23.883324126235156}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:16:12,828]\u001b[0m Trial 8 finished with value: -2.6242716409052913 and parameters: {'max_depth': 35, 'num_leaves': 47, 'learning_rate': 0.00017048571730453335, 'n_estimators': 377, 'reg_alpha': 9.585826884294658, 'reg_lambda': 1.2139220025617924e-06}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:16:27,092]\u001b[0m Trial 12 finished with value: -2.607369511069697 and parameters: {'max_depth': 47, 'num_leaves': 34, 'learning_rate': 0.00025870452530671784, 'n_estimators': 374, 'reg_alpha': 1.3713876123533383e-05, 'reg_lambda': 1.2572594787648436e-06}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:16:50,556]\u001b[0m Trial 17 finished with value: -2.637056088918541 and parameters: {'max_depth': 22, 'num_leaves': 33, 'learning_rate': 0.0023739703711859648, 'n_estimators': 319, 'reg_alpha': 0.012065174042377655, 'reg_lambda': 1958568.4683814985}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:17:00,340]\u001b[0m Trial 18 finished with value: -2.657491471181209 and parameters: {'max_depth': 20, 'num_leaves': 32, 'learning_rate': 0.002212029346625935, 'n_estimators': 305, 'reg_alpha': 0.012817396765766688, 'reg_lambda': 9297537.475694759}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:17:03,955]\u001b[0m Trial 16 finished with value: -2.4214216776385866 and parameters: {'max_depth': 21, 'num_leaves': 34, 'learning_rate': 0.0030669764199956926, 'n_estimators': 334, 'reg_alpha': 0.034480601502673985, 'reg_lambda': 15.895441855096903}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:17:10,164]\u001b[0m Trial 19 finished with value: -2.64157369164988 and parameters: {'max_depth': 24, 'num_leaves': 26, 'learning_rate': 0.007493129534302893, 'n_estimators': 295, 'reg_alpha': 0.016980098466253136, 'reg_lambda': 7418905.993610272}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:17:40,042]\u001b[0m Trial 22 finished with value: -2.4263803842913463 and parameters: {'max_depth': 6, 'num_leaves': 12, 'learning_rate': 0.06812679317244248, 'n_estimators': 422, 'reg_alpha': 338.5315085117353, 'reg_lambda': 584.0849945756349}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:17:50,200]\u001b[0m Trial 23 finished with value: -2.4507015805615597 and parameters: {'max_depth': 5, 'num_leaves': 12, 'learning_rate': 0.10808118728790042, 'n_estimators': 495, 'reg_alpha': 214.96250851763313, 'reg_lambda': 893.1031970722703}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:17:57,367]\u001b[0m Trial 20 finished with value: -2.4431224800117186 and parameters: {'max_depth': 25, 'num_leaves': 26, 'learning_rate': 0.041771297937540745, 'n_estimators': 458, 'reg_alpha': 295.19033055035237, 'reg_lambda': 186.3041787858878}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:18:00,850]\u001b[0m Trial 21 finished with value: -2.4923418339035237 and parameters: {'max_depth': 6, 'num_leaves': 24, 'learning_rate': 0.0905161936793735, 'n_estimators': 497, 'reg_alpha': 239.58142509042622, 'reg_lambda': 537.0853494692983}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:18:54,761]\u001b[0m Trial 25 finished with value: -2.45071235541279 and parameters: {'max_depth': 26, 'num_leaves': 40, 'learning_rate': 0.017713755176394792, 'n_estimators': 340, 'reg_alpha': 0.3534780665572088, 'reg_lambda': 4.578894499450764}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:18:58,768]\u001b[0m Trial 24 finished with value: -2.4856500451855323 and parameters: {'max_depth': 25, 'num_leaves': 39, 'learning_rate': 0.05210649602022468, 'n_estimators': 479, 'reg_alpha': 0.3580511231894349, 'reg_lambda': 3.0777968481156535}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:19:05,345]\u001b[0m Trial 27 finished with value: -2.510992959363249 and parameters: {'max_depth': 17, 'num_leaves': 39, 'learning_rate': 0.0010137605897704188, 'n_estimators': 332, 'reg_alpha': 0.0001458418457445463, 'reg_lambda': 2.289758859003561}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:19:06,017]\u001b[0m Trial 26 finished with value: -2.5436643851278102 and parameters: {'max_depth': 16, 'num_leaves': 40, 'learning_rate': 0.0007065629779035444, 'n_estimators': 335, 'reg_alpha': 0.12299942359833213, 'reg_lambda': 5.925699252670419}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:19:46,914]\u001b[0m Trial 29 finished with value: -2.5843888657483327 and parameters: {'max_depth': 18, 'num_leaves': 22, 'learning_rate': 0.0013371158948138789, 'n_estimators': 409, 'reg_alpha': 0.0003583447595371123, 'reg_lambda': 281586.0374661543}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:19:53,889]\u001b[0m Trial 30 finished with value: -2.618674796257764 and parameters: {'max_depth': 40, 'num_leaves': 21, 'learning_rate': 0.000807949821445347, 'n_estimators': 421, 'reg_alpha': 0.092892795398561, 'reg_lambda': 366585.6683212252}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:19:55,614]\u001b[0m Trial 31 finished with value: -2.4085343181367094 and parameters: {'max_depth': 40, 'num_leaves': 22, 'learning_rate': 0.008176502622810887, 'n_estimators': 410, 'reg_alpha': 18.988008577700835, 'reg_lambda': 236534.62118694998}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:08,861]\u001b[0m Trial 32 finished with value: -2.4351909258343647 and parameters: {'max_depth': 29, 'num_leaves': 8, 'learning_rate': 0.008617066774206098, 'n_estimators': 277, 'reg_alpha': 9.026065671000051, 'reg_lambda': 219852.63785003405}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:13,994]\u001b[0m Trial 33 finished with value: -2.3682655450626746 and parameters: {'max_depth': 28, 'num_leaves': 7, 'learning_rate': 0.010319774115097225, 'n_estimators': 257, 'reg_alpha': 3.7419894479628097, 'reg_lambda': 5925.065190988751}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:21,800]\u001b[0m Trial 28 finished with value: -2.4803330912009045 and parameters: {'max_depth': 17, 'num_leaves': 38, 'learning_rate': 0.001103261081115267, 'n_estimators': 418, 'reg_alpha': 0.1662144757068526, 'reg_lambda': 0.6306390263079602}. Best is trial 2 with value: -2.3548140743845343.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:25,885]\u001b[0m Trial 34 finished with value: -2.3487477717580405 and parameters: {'max_depth': 42, 'num_leaves': 6, 'learning_rate': 0.013971453191810305, 'n_estimators': 443, 'reg_alpha': 4.486840803357777, 'reg_lambda': 67904.14232675871}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:26,315]\u001b[0m Trial 36 finished with value: -2.3644787652970414 and parameters: {'max_depth': 42, 'num_leaves': 6, 'learning_rate': 0.22880230915369895, 'n_estimators': 180, 'reg_alpha': 36.921781173080845, 'reg_lambda': 34103.71225494502}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:37,432]\u001b[0m Trial 38 finished with value: -2.3675738173843675 and parameters: {'max_depth': 34, 'num_leaves': 5, 'learning_rate': 0.23792255673756657, 'n_estimators': 170, 'reg_alpha': 1.6391889675854734, 'reg_lambda': 23508.1159581819}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:20:38,258]\u001b[0m Trial 39 finished with value: -2.3553403033614377 and parameters: {'max_depth': 43, 'num_leaves': 5, 'learning_rate': 0.02684117079773833, 'n_estimators': 175, 'reg_alpha': 48.90704436841821, 'reg_lambda': 84799.43102322635}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:47,314]\u001b[0m Trial 37 finished with value: -2.4337745602632745 and parameters: {'max_depth': 41, 'num_leaves': 16, 'learning_rate': 0.3171390999294556, 'n_estimators': 216, 'reg_alpha': 3.591570187401959, 'reg_lambda': 16724.568005132955}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:48,782]\u001b[0m Trial 40 finished with value: -2.3577231113127897 and parameters: {'max_depth': 43, 'num_leaves': 5, 'learning_rate': 0.20168794789317493, 'n_estimators': 181, 'reg_alpha': 59.007335796461945, 'reg_lambda': 63701.721801526044}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:58,860]\u001b[0m Trial 41 finished with value: -2.362266691347732 and parameters: {'max_depth': 43, 'num_leaves': 14, 'learning_rate': 0.022624364533229833, 'n_estimators': 174, 'reg_alpha': 41.87294010998942, 'reg_lambda': 44008.251365643904}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:20:59,642]\u001b[0m Trial 42 finished with value: -2.356958192680404 and parameters: {'max_depth': 44, 'num_leaves': 5, 'learning_rate': 0.021388475014770182, 'n_estimators': 171, 'reg_alpha': 39.681488525739255, 'reg_lambda': 57879.42946486185}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:03,962]\u001b[0m Trial 43 finished with value: -2.5168224336518015 and parameters: {'max_depth': 44, 'num_leaves': 12, 'learning_rate': 0.022607440023746362, 'n_estimators': 149, 'reg_alpha': 3225.7030217953356, 'reg_lambda': 1032597.8972612597}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:13,365]\u001b[0m Trial 45 finished with value: -2.509816323273471 and parameters: {'max_depth': 37, 'num_leaves': 11, 'learning_rate': 0.029464244471033383, 'n_estimators': 138, 'reg_alpha': 2527.672053435602, 'reg_lambda': 1189108.1283796711}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:13,525]\u001b[0m Trial 44 finished with value: -2.529893573723749 and parameters: {'max_depth': 45, 'num_leaves': 11, 'learning_rate': 0.01993598519055034, 'n_estimators': 147, 'reg_alpha': 3953.3340622908745, 'reg_lambda': 1018134.0681361625}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:25,244]\u001b[0m Trial 46 finished with value: -2.3612146328345927 and parameters: {'max_depth': 38, 'num_leaves': 10, 'learning_rate': 0.03342923926231453, 'n_estimators': 234, 'reg_alpha': 70.61991685974553, 'reg_lambda': 4135.33460834034}. Best is trial 34 with value: -2.3487477717580405.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:27,811]\u001b[0m Trial 48 finished with value: -2.320625112116302 and parameters: {'max_depth': 37, 'num_leaves': 5, 'learning_rate': 0.07442233103478489, 'n_estimators': 237, 'reg_alpha': 65.78599599402257, 'reg_lambda': 3908.393605212015}. Best is trial 48 with value: -2.320625112116302.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:31,642]\u001b[0m Trial 35 finished with value: -2.402815117125684 and parameters: {'max_depth': 39, 'num_leaves': 31, 'learning_rate': 0.010712349759823743, 'n_estimators': 458, 'reg_alpha': 1.621887912284875, 'reg_lambda': 4121.061782048783}. Best is trial 48 with value: -2.320625112116302.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:31,972]\u001b[0m Trial 47 finished with value: -2.356942651742069 and parameters: {'max_depth': 37, 'num_leaves': 9, 'learning_rate': 0.04596449402250127, 'n_estimators': 230, 'reg_alpha': 82.41352880658799, 'reg_lambda': 2387.551740850701}. Best is trial 48 with value: -2.320625112116302.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:33,372]\u001b[0m Trial 49 finished with value: -2.3610715192927167 and parameters: {'max_depth': 38, 'num_leaves': 9, 'learning_rate': 0.07094637843734865, 'n_estimators': 105, 'reg_alpha': 83.4617510610337, 'reg_lambda': 104548.33750706726}. Best is trial 48 with value: -2.320625112116302.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:21:37,211]\u001b[0m A new study created in memory with name: no-name-2e8bed02-2e53-4f19-9a8f-17183ef436c6\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:42,364]\u001b[0m Trial 1 finished with value: -2.631086560911791 and parameters: {'max_depth': 31, 'num_leaves': 35, 'learning_rate': 0.03219618651254797, 'n_estimators': 36, 'reg_alpha': 8.840569048764928, 'reg_lambda': 78467.36655754248}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:52,183]\u001b[0m Trial 4 finished with value: -2.6918845548844956 and parameters: {'max_depth': 27, 'num_leaves': 20, 'learning_rate': 0.00012677308324952823, 'n_estimators': 125, 'reg_alpha': 0.06287097147109667, 'reg_lambda': 147902.5194497606}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:21:59,707]\u001b[0m Trial 3 finished with value: -2.670806466159684 and parameters: {'max_depth': 14, 'num_leaves': 11, 'learning_rate': 0.0001380350769812438, 'n_estimators': 423, 'reg_alpha': 0.00031136702376179684, 'reg_lambda': 1053.3768334756041}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:04,775]\u001b[0m Trial 2 finished with value: -2.6931467084906573 and parameters: {'max_depth': 26, 'num_leaves': 39, 'learning_rate': 8.858929750025852e-07, 'n_estimators': 374, 'reg_alpha': 24.877605970854585, 'reg_lambda': 1645925.7624060735}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:09,810]\u001b[0m Trial 7 finished with value: -2.66358983657339 and parameters: {'max_depth': 2, 'num_leaves': 17, 'learning_rate': 0.0032820568071480778, 'n_estimators': 169, 'reg_alpha': 1215.5349502489187, 'reg_lambda': 7.021992596710747e-07}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:13,221]\u001b[0m Trial 8 finished with value: -2.693150385327737 and parameters: {'max_depth': 44, 'num_leaves': 37, 'learning_rate': 0.0003687693417189028, 'n_estimators': 212, 'reg_alpha': 1919544.549266383, 'reg_lambda': 0.8700106735598602}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:14,209]\u001b[0m Trial 6 finished with value: -2.6928385128370502 and parameters: {'max_depth': 40, 'num_leaves': 49, 'learning_rate': 0.0005298102055538143, 'n_estimators': 143, 'reg_alpha': 6.002771762409821e-05, 'reg_lambda': 4581658.820183668}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:29,118]\u001b[0m Trial 0 finished with value: -2.6930538599177014 and parameters: {'max_depth': 32, 'num_leaves': 44, 'learning_rate': 1.5929357813125214e-06, 'n_estimators': 463, 'reg_alpha': 0.0003291233371645292, 'reg_lambda': 69362.59175204937}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:36,464]\u001b[0m Trial 11 finished with value: -2.6904760825680616 and parameters: {'max_depth': 7, 'num_leaves': 25, 'learning_rate': 0.0005182107897755331, 'n_estimators': 91, 'reg_alpha': 14.841254339547126, 'reg_lambda': 208322.17079463587}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:39,362]\u001b[0m Trial 10 finished with value: -2.692975719995504 and parameters: {'max_depth': 22, 'num_leaves': 36, 'learning_rate': 5.541636929707915e-05, 'n_estimators': 429, 'reg_alpha': 453.22147428801964, 'reg_lambda': 2515911.1443527606}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:40,450]\u001b[0m Trial 13 finished with value: -2.7985534563836696 and parameters: {'max_depth': 36, 'num_leaves': 5, 'learning_rate': 0.6659907317001487, 'n_estimators': 2, 'reg_alpha': 1.365620192871415e-07, 'reg_lambda': 34.94545433520338}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:22:42,038]\u001b[0m Trial 14 finished with value: -2.6384850380007205 and parameters: {'max_depth': 0, 'num_leaves': 22, 'learning_rate': 0.043077785240998395, 'n_estimators': 4, 'reg_alpha': 2296.7088875270824, 'reg_lambda': 1.1138618444433039e-05}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:43,434]\u001b[0m Trial 15 finished with value: -2.6411114384686813 and parameters: {'max_depth': 16, 'num_leaves': 29, 'learning_rate': 0.07371601975001585, 'n_estimators': 10, 'reg_alpha': 53422.32755721679, 'reg_lambda': 0.0013761289089694229}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:44,571]\u001b[0m Trial 5 finished with value: -3.0676772776567782 and parameters: {'max_depth': 20, 'num_leaves': 50, 'learning_rate': 0.022223160484384816, 'n_estimators': 332, 'reg_alpha': 2.9545799470722805e-06, 'reg_lambda': 0.00015122254761474374}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:50,942]\u001b[0m Trial 9 finished with value: -2.6553553371744396 and parameters: {'max_depth': 15, 'num_leaves': 31, 'learning_rate': 0.05578175856938042, 'n_estimators': 415, 'reg_alpha': 989.4994927967604, 'reg_lambda': 747926.5232612689}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:51,382]\u001b[0m Trial 17 finished with value: -3.2016285325208758 and parameters: {'max_depth': -1, 'num_leaves': 30, 'learning_rate': 0.953482819950622, 'n_estimators': 61, 'reg_alpha': 0.22662256238067985, 'reg_lambda': 1.1282609777211114}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:57,389]\u001b[0m Trial 18 finished with value: -3.160206323485825 and parameters: {'max_depth': 7, 'num_leaves': 23, 'learning_rate': 0.7115778794150297, 'n_estimators': 64, 'reg_alpha': 0.04762688253154584, 'reg_lambda': 0.17345944196382523}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:57,425]\u001b[0m Trial 16 finished with value: -2.682551519548859 and parameters: {'max_depth': 12, 'num_leaves': 28, 'learning_rate': 0.028449600112903428, 'n_estimators': 295, 'reg_alpha': 21961.05903404694, 'reg_lambda': 1.6251174125764366e-07}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:22:59,178]\u001b[0m Trial 19 finished with value: -2.693150385327737 and parameters: {'max_depth': 47, 'num_leaves': 22, 'learning_rate': 0.007581644437897721, 'n_estimators': 287, 'reg_alpha': 3108440.1515838965, 'reg_lambda': 1.0761569866129767e-07}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:02,221]\u001b[0m Trial 20 finished with value: -2.693150385327737 and parameters: {'max_depth': 32, 'num_leaves': 15, 'learning_rate': 0.005911130326457306, 'n_estimators': 282, 'reg_alpha': 8571449.671637872, 'reg_lambda': 1.2303259289156098e-07}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:05,294]\u001b[0m Trial 12 finished with value: -2.6438621161511326 and parameters: {'max_depth': 17, 'num_leaves': 24, 'learning_rate': 0.0005495097799537493, 'n_estimators': 281, 'reg_alpha': 1098.811462901458, 'reg_lambda': 3.499345472985845e-06}. Best is trial 1 with value: -2.631086560911791.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:06,607]\u001b[0m Trial 24 finished with value: -2.629706239723473 and parameters: {'max_depth': 6, 'num_leaves': 34, 'learning_rate': 0.15016457954470377, 'n_estimators': 5, 'reg_alpha': 43725.628739394495, 'reg_lambda': 0.0032471808791998593}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:11,178]\u001b[0m Trial 25 finished with value: -2.9870049470920508 and parameters: {'max_depth': 6, 'num_leaves': 33, 'learning_rate': 0.14112551094774786, 'n_estimators': 38, 'reg_alpha': 3.5326441158954225, 'reg_lambda': 0.0025780191682139163}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:11,418]\u001b[0m Trial 22 finished with value: -3.0577496821700807 and parameters: {'max_depth': 33, 'num_leaves': 13, 'learning_rate': 0.15468456940059044, 'n_estimators': 203, 'reg_alpha': 6.033082369629006, 'reg_lambda': 2352.654968333114}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:13,548]\u001b[0m Trial 26 finished with value: -3.1213173176905284 and parameters: {'max_depth': -1, 'num_leaves': 41, 'learning_rate': 0.12253191695161701, 'n_estimators': 96, 'reg_alpha': 127786.33727416547, 'reg_lambda': 4469.924708431397}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:14,800]\u001b[0m Trial 21 finished with value: -2.674222548223007 and parameters: {'max_depth': 31, 'num_leaves': 16, 'learning_rate': 0.0051028506680074835, 'n_estimators': 225, 'reg_alpha': 5.1130354739156045, 'reg_lambda': 4925.472308552578}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:15,842]\u001b[0m Trial 27 finished with value: -2.6809597773792033 and parameters: {'max_depth': -1, 'num_leaves': 42, 'learning_rate': 0.21274804808327913, 'n_estimators': 98, 'reg_alpha': 22402.86521138828, 'reg_lambda': 1.8625094647777295e-05}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:16,872]\u001b[0m Trial 29 finished with value: -2.7389321393238113 and parameters: {'max_depth': 3, 'num_leaves': 34, 'learning_rate': 0.3052660662421704, 'n_estimators': 35, 'reg_alpha': 12985.275749406752, 'reg_lambda': 3.870468488731331e-05}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:17,501]\u001b[0m Trial 28 finished with value: -2.6342460965059735 and parameters: {'max_depth': 10, 'num_leaves': 34, 'learning_rate': 0.015287540937656465, 'n_estimators': 34, 'reg_alpha': 10760.513246596058, 'reg_lambda': 2.995189956396593e-05}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:18,119]\u001b[0m Trial 31 finished with value: -2.681247123659239 and parameters: {'max_depth': 10, 'num_leaves': 27, 'learning_rate': 0.024697637077111263, 'n_estimators': 1, 'reg_alpha': 98.14010780288788, 'reg_lambda': 0.01341420199572131}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:19,802]\u001b[0m Trial 30 finished with value: -3.0406343972227647 and parameters: {'max_depth': 8, 'num_leaves': 34, 'learning_rate': 0.3083478526334449, 'n_estimators': 26, 'reg_alpha': 92.83749642997377, 'reg_lambda': 0.01086517599206011}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:21,090]\u001b[0m Trial 33 finished with value: -2.693150385327737 and parameters: {'max_depth': 26, 'num_leaves': 45, 'learning_rate': 0.0020052782581447934, 'n_estimators': 160, 'reg_alpha': 947633.5947018496, 'reg_lambda': 0.00035054483669893013}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:21,590]\u001b[0m Trial 34 finished with value: -2.7922817359195307 and parameters: {'max_depth': 3, 'num_leaves': 38, 'learning_rate': 0.03634542124853287, 'n_estimators': 63, 'reg_alpha': 311411.32948597183, 'reg_lambda': 6.497909312002859e-05}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:24,916]\u001b[0m Trial 35 finished with value: -2.7474098879389026 and parameters: {'max_depth': 4, 'num_leaves': 38, 'learning_rate': 0.028864661292170437, 'n_estimators': 65, 'reg_alpha': 5023.452060251476, 'reg_lambda': 6.731430941999424e-06}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:27,117]\u001b[0m Trial 37 finished with value: -3.024055033408006 and parameters: {'max_depth': 10, 'num_leaves': 32, 'learning_rate': 0.013431340994652766, 'n_estimators': 103, 'reg_alpha': 163207.69578954735, 'reg_lambda': 2.2007221501634596e-06}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:28,483]\u001b[0m Trial 36 finished with value: -2.6482300200325564 and parameters: {'max_depth': 11, 'num_leaves': 32, 'learning_rate': 0.011744059964477119, 'n_estimators': 55, 'reg_alpha': 6391.761621887483, 'reg_lambda': 7.88583777991955e-06}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:30,540]\u001b[0m Trial 23 finished with value: -3.0763360689425747 and parameters: {'max_depth': 29, 'num_leaves': 33, 'learning_rate': 0.14823071297444448, 'n_estimators': 225, 'reg_alpha': 5.705624261448674, 'reg_lambda': 11772.338569175154}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:23:41,474]\u001b[0m Trial 40 finished with value: -3.0559374962625983 and parameters: {'max_depth': 19, 'num_leaves': 20, 'learning_rate': 0.08010648132469872, 'n_estimators': 127, 'reg_alpha': 110.52276647216426, 'reg_lambda': 0.00022175741610511128}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:41,628]\u001b[0m Trial 38 finished with value: -2.8147832643897837 and parameters: {'max_depth': 20, 'num_leaves': 20, 'learning_rate': 0.05856167744086685, 'n_estimators': 493, 'reg_alpha': 7386.178756051671, 'reg_lambda': 0.00013504642567803757}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:42,596]\u001b[0m Trial 32 finished with value: -2.9783733482200003 and parameters: {'max_depth': 10, 'num_leaves': 46, 'learning_rate': 0.017470235145788805, 'n_estimators': 158, 'reg_alpha': 108.2263064520673, 'reg_lambda': 0.02443536480242832}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:43,173]\u001b[0m Trial 42 finished with value: -2.724135312164038 and parameters: {'max_depth': 24, 'num_leaves': 46, 'learning_rate': 0.013262127852031553, 'n_estimators': 36, 'reg_alpha': 380341.391982289, 'reg_lambda': 470.7209561791164}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:44,023]\u001b[0m Trial 43 finished with value: -2.693150385327737 and parameters: {'max_depth': 24, 'num_leaves': 40, 'learning_rate': 0.0028366365686386067, 'n_estimators': 25, 'reg_alpha': 593319.7073964323, 'reg_lambda': 0.0008525118210854121}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:44,290]\u001b[0m Trial 44 finished with value: -2.686925131234243 and parameters: {'max_depth': 15, 'num_leaves': 29, 'learning_rate': 0.04429918164124541, 'n_estimators': 1, 'reg_alpha': 60702.4692018656, 'reg_lambda': 0.0008189793045520067}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:45,403]\u001b[0m Trial 45 finished with value: -2.6745007275572994 and parameters: {'max_depth': 13, 'num_leaves': 29, 'learning_rate': 0.06221112750652139, 'n_estimators': 16, 'reg_alpha': 80428.48050113517, 'reg_lambda': 0.0009579764084389748}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:46,987]\u001b[0m Trial 46 finished with value: -2.6892631417846067 and parameters: {'max_depth': 17, 'num_leaves': 26, 'learning_rate': 0.055929617777202886, 'n_estimators': 84, 'reg_alpha': 64114.628860243094, 'reg_lambda': 5769649.042515165}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:47,115]\u001b[0m Trial 39 finished with value: -3.0607098333340463 and parameters: {'max_depth': 19, 'num_leaves': 41, 'learning_rate': 0.06453418951140445, 'n_estimators': 126, 'reg_alpha': 43.8585912823685, 'reg_lambda': 0.0002461877657127814}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:47,421]\u001b[0m Trial 41 finished with value: -2.7485531305310107 and parameters: {'max_depth': 24, 'num_leaves': 45, 'learning_rate': 0.054622953945452295, 'n_estimators': 32, 'reg_alpha': 4307.973185573486, 'reg_lambda': 55.44603600088789}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:51,912]\u001b[0m Trial 48 finished with value: -3.021637705357145 and parameters: {'max_depth': 5, 'num_leaves': 27, 'learning_rate': 0.309265830953943, 'n_estimators': 126, 'reg_alpha': 1998.771773805714, 'reg_lambda': 3.827895937263385e-05}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:53,535]\u001b[0m Trial 47 finished with value: -2.9708456771665244 and parameters: {'max_depth': 16, 'num_leaves': 26, 'learning_rate': 0.08633190545341751, 'n_estimators': 83, 'reg_alpha': 1529.7921963459635, 'reg_lambda': 3.344045886468222e-05}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:23:54,029]\u001b[0m Trial 49 finished with value: -3.0128465120317474 and parameters: {'max_depth': 39, 'num_leaves': 36, 'learning_rate': 0.3854497566720019, 'n_estimators': 383, 'reg_alpha': 1836.209622984922, 'reg_lambda': 4.7639262295900334e-05}. Best is trial 24 with value: -2.629706239723473.\u001b[0m\n",
      " 88%|        | 14/16 [3:14:19<36:50, 1105.22s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:23:56,549]\u001b[0m A new study created in memory with name: no-name-ba66c4c9-cf15-4808-aa92-3b43f903ea93\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:24:01,223]\u001b[0m Trial 0 finished with value: -1.3850717350830506 and parameters: {'max_depth': 1, 'num_leaves': 38, 'learning_rate': 0.0004991211205096375, 'n_estimators': 73, 'reg_alpha': 1844.2791775260334, 'reg_lambda': 4.462166326100473e-05}. Best is trial 0 with value: -1.3850717350830506.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:24:48,158]\u001b[0m Trial 4 finished with value: -1.031471554586465 and parameters: {'max_depth': 17, 'num_leaves': 16, 'learning_rate': 0.009841361483692817, 'n_estimators': 391, 'reg_alpha': 0.00014662015494504418, 'reg_lambda': 131011.75689231309}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:24:51,836]\u001b[0m Trial 2 finished with value: -1.4034542795302272 and parameters: {'max_depth': 33, 'num_leaves': 14, 'learning_rate': 1.0409464288150947e-07, 'n_estimators': 472, 'reg_alpha': 4.257679951062308e-06, 'reg_lambda': 11819.804680363248}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:24:52,807]\u001b[0m Trial 1 finished with value: -1.1129031864654755 and parameters: {'max_depth': 37, 'num_leaves': 42, 'learning_rate': 0.05824185368830862, 'n_estimators': 260, 'reg_alpha': 610.6868648312261, 'reg_lambda': 2.2021825666704887e-07}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:24:57,793]\u001b[0m Trial 3 finished with value: -1.4022227024805753 and parameters: {'max_depth': 10, 'num_leaves': 33, 'learning_rate': 5.568266511777992e-06, 'n_estimators': 290, 'reg_alpha': 6.059318125734478e-06, 'reg_lambda': 179.77153008315622}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:25:02,873]\u001b[0m Trial 7 finished with value: -1.403471662049147 and parameters: {'max_depth': 43, 'num_leaves': 19, 'learning_rate': 3.8373786937338734e-07, 'n_estimators': 52, 'reg_alpha': 25.33956645127057, 'reg_lambda': 0.05426033074226859}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:25:22,246]\u001b[0m Trial 8 finished with value: -1.2518845149801532 and parameters: {'max_depth': 29, 'num_leaves': 29, 'learning_rate': 0.002226537141272514, 'n_estimators': 264, 'reg_alpha': 1.1129854363525793, 'reg_lambda': 169505.97473769807}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:25:31,501]\u001b[0m Trial 10 finished with value: -2.024681173897412 and parameters: {'max_depth': 46, 'num_leaves': 29, 'learning_rate': 0.18844117404387703, 'n_estimators': 255, 'reg_alpha': 202051.604735156, 'reg_lambda': 6.481518206267965e-07}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:25:35,728]\u001b[0m Trial 5 finished with value: -1.0978167439870872 and parameters: {'max_depth': 24, 'num_leaves': 21, 'learning_rate': 0.26234072313546486, 'n_estimators': 429, 'reg_alpha': 0.00011164173054310822, 'reg_lambda': 9.56263078483517e-05}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:25:44,003]\u001b[0m Trial 12 finished with value: -1.4034868021317108 and parameters: {'max_depth': 33, 'num_leaves': 38, 'learning_rate': 0.00019965293925127203, 'n_estimators': 239, 'reg_alpha': 518127.92419724027, 'reg_lambda': 3111637.570798087}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:25:56,669]\u001b[0m Trial 11 finished with value: -1.4020206345422124 and parameters: {'max_depth': 35, 'num_leaves': 49, 'learning_rate': 1.0484503094530282e-05, 'n_estimators': 186, 'reg_alpha': 8791.929985992776, 'reg_lambda': 0.003385769900086174}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:25:59,850]\u001b[0m Trial 6 finished with value: -1.2330403301502653 and parameters: {'max_depth': 15, 'num_leaves': 28, 'learning_rate': 0.0008329996606290892, 'n_estimators': 352, 'reg_alpha': 5.224435343003393e-05, 'reg_lambda': 0.007172378654443659}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:26:07,576]\u001b[0m Trial 13 finished with value: -1.0391575969688018 and parameters: {'max_depth': 13, 'num_leaves': 5, 'learning_rate': 0.007435215563335272, 'n_estimators': 366, 'reg_alpha': 0.003799526573778345, 'reg_lambda': 104.3202277764082}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:26:10,020]\u001b[0m Trial 9 finished with value: -1.339512443937572 and parameters: {'max_depth': 7, 'num_leaves': 30, 'learning_rate': 0.0002466115451458373, 'n_estimators': 368, 'reg_alpha': 0.08852881654780215, 'reg_lambda': 10.337637299231945}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:26:26,835]\u001b[0m Trial 14 finished with value: -1.4030585784924061 and parameters: {'max_depth': 18, 'num_leaves': 7, 'learning_rate': 0.9433226205468219, 'n_estimators': 445, 'reg_alpha': 0.0011437356121794466, 'reg_lambda': 11.590691868581334}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:26:28,179]\u001b[0m Trial 15 finished with value: -1.2751666533274566 and parameters: {'max_depth': 19, 'num_leaves': 5, 'learning_rate': 0.8067389771787872, 'n_estimators': 468, 'reg_alpha': 0.0017358521810778482, 'reg_lambda': 13.408770216387321}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:26:34,253]\u001b[0m Trial 16 finished with value: -1.0880675404388096 and parameters: {'max_depth': 15, 'num_leaves': 5, 'learning_rate': 0.012888780440076205, 'n_estimators': 382, 'reg_alpha': 0.0051459849340579735, 'reg_lambda': 34.63365113877177}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:26:44,091]\u001b[0m Trial 17 finished with value: -1.0850863869734608 and parameters: {'max_depth': 18, 'num_leaves': 5, 'learning_rate': 0.010411893760395951, 'n_estimators': 500, 'reg_alpha': 0.005082013802692326, 'reg_lambda': 982.7749982114087}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:26:53,396]\u001b[0m Trial 18 finished with value: -1.074393074884555 and parameters: {'max_depth': 21, 'num_leaves': 5, 'learning_rate': 0.012928889997150908, 'n_estimators': 371, 'reg_alpha': 1.2888460031607676e-07, 'reg_lambda': 1893.5635171383497}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:26:55,501]\u001b[0m Trial 20 finished with value: -1.042046257068105 and parameters: {'max_depth': 0, 'num_leaves': 13, 'learning_rate': 0.010656671880210564, 'n_estimators': 156, 'reg_alpha': 2.7989112551920023e-07, 'reg_lambda': 1887.5174633414842}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:04,389]\u001b[0m Trial 22 finished with value: -1.3981700420782284 and parameters: {'max_depth': 7, 'num_leaves': 14, 'learning_rate': 0.0032993672082313862, 'n_estimators': 143, 'reg_alpha': 0.08270212411322463, 'reg_lambda': 9470499.326802315}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:11,030]\u001b[0m Trial 21 finished with value: -1.2910234019137228 and parameters: {'max_depth': 0, 'num_leaves': 13, 'learning_rate': 0.02124045210371621, 'n_estimators': 326, 'reg_alpha': 1.2662551556374722e-07, 'reg_lambda': 5579307.187274964}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:12,204]\u001b[0m Trial 19 finished with value: -1.0916026821858373 and parameters: {'max_depth': 11, 'num_leaves': 12, 'learning_rate': 0.012954796956668659, 'n_estimators': 380, 'reg_alpha': 4.964222353249272e-07, 'reg_lambda': 3969.16231312029}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:23,385]\u001b[0m Trial 24 finished with value: -1.0777026569010597 and parameters: {'max_depth': -1, 'num_leaves': 11, 'learning_rate': 0.052466880908358986, 'n_estimators': 155, 'reg_alpha': 4.0749209746422714e-07, 'reg_lambda': 40601.47432558103}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:25,951]\u001b[0m Trial 27 finished with value: -1.3957517846398722 and parameters: {'max_depth': 24, 'num_leaves': 23, 'learning_rate': 0.0035199062689574606, 'n_estimators': 7, 'reg_alpha': 5.2426469363896934e-05, 'reg_lambda': 197408.01597469204}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:32,507]\u001b[0m Trial 26 finished with value: -1.0537964153181902 and parameters: {'max_depth': 26, 'num_leaves': 22, 'learning_rate': 0.054426163246363256, 'n_estimators': 133, 'reg_alpha': 2.3671401339610526e-05, 'reg_lambda': 108976.83828340891}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:33,145]\u001b[0m Trial 23 finished with value: -1.1184674970269781 and parameters: {'max_depth': 8, 'num_leaves': 12, 'learning_rate': 0.09562082205598527, 'n_estimators': 319, 'reg_alpha': 0.13013956919875683, 'reg_lambda': 55327.389859273244}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:34,283]\u001b[0m Trial 25 finished with value: -1.1056067061040808 and parameters: {'max_depth': 12, 'num_leaves': 22, 'learning_rate': 0.08303098318284097, 'n_estimators': 129, 'reg_alpha': 2.8472443644926526e-06, 'reg_lambda': 31382.147623809076}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:49,059]\u001b[0m Trial 30 finished with value: -1.2421542457898533 and parameters: {'max_depth': 3, 'num_leaves': 17, 'learning_rate': 0.0013293982822391818, 'n_estimators': 199, 'reg_alpha': 0.0005148768724284841, 'reg_lambda': 299.64318255687004}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:50,163]\u001b[0m Trial 31 finished with value: -1.21343675659866 and parameters: {'max_depth': 3, 'num_leaves': 16, 'learning_rate': 0.0016262537645530366, 'n_estimators': 202, 'reg_alpha': 0.00026491650193048553, 'reg_lambda': 277.00200097363586}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:54,770]\u001b[0m Trial 28 finished with value: -1.1293101898870666 and parameters: {'max_depth': 6, 'num_leaves': 18, 'learning_rate': 0.05895300110491749, 'n_estimators': 207, 'reg_alpha': 9.43626030904349e-06, 'reg_lambda': 717.7298756485661}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:27:59,359]\u001b[0m Trial 33 finished with value: -1.2133403160360468 and parameters: {'max_depth': 14, 'num_leaves': 9, 'learning_rate': 0.004839680667629377, 'n_estimators': 69, 'reg_alpha': 2.2430731151081248e-06, 'reg_lambda': 1.3870388954127923}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:28:00,233]\u001b[0m Trial 29 finished with value: -1.1873205109718359 and parameters: {'max_depth': 6, 'num_leaves': 17, 'learning_rate': 0.002090637723579094, 'n_estimators': 197, 'reg_alpha': 2.7992752249086935e-06, 'reg_lambda': 975.054852181584}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:28:08,635]\u001b[0m Trial 34 finished with value: -1.272874121279156 and parameters: {'max_depth': 30, 'num_leaves': 10, 'learning_rate': 0.0068295249903723675, 'n_estimators': 100, 'reg_alpha': 2.5710671512719473e-05, 'reg_lambda': 326527.1051849447}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:28:11,651]\u001b[0m Trial 35 finished with value: -1.0543579074021525 and parameters: {'max_depth': 27, 'num_leaves': 9, 'learning_rate': 0.03258213941822431, 'n_estimators': 104, 'reg_alpha': 2.649277022231614e-05, 'reg_lambda': 7501.569203193099}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:28:11,967]\u001b[0m Trial 36 finished with value: -1.1689913857490442 and parameters: {'max_depth': 28, 'num_leaves': 25, 'learning_rate': 0.029807495790843352, 'n_estimators': 111, 'reg_alpha': 2.995251713641802e-05, 'reg_lambda': 836164.4176888239}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:28:27,366]\u001b[0m Trial 37 finished with value: -1.033958070213351 and parameters: {'max_depth': 27, 'num_leaves': 25, 'learning_rate': 0.02729225620903072, 'n_estimators': 101, 'reg_alpha': 2.2619436813604715e-05, 'reg_lambda': 9086.093677413173}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:28:27,972]\u001b[0m Trial 32 finished with value: -1.2231242430821854 and parameters: {'max_depth': 4, 'num_leaves': 10, 'learning_rate': 0.0008047389884160306, 'n_estimators': 408, 'reg_alpha': 0.00015576949755178468, 'reg_lambda': 1.287706157529703}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:28:34,985]\u001b[0m Trial 41 finished with value: -1.2980730158641003 and parameters: {'max_depth': 39, 'num_leaves': 35, 'learning_rate': 0.006140656113901138, 'n_estimators': 28, 'reg_alpha': 1.068181556024758e-06, 'reg_lambda': 9769.265778262601}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:28:36,192]\u001b[0m Trial 40 finished with value: -1.3809317716582072 and parameters: {'max_depth': 39, 'num_leaves': 34, 'learning_rate': 0.0008539752311196256, 'n_estimators': 38, 'reg_alpha': 0.0001928333515934717, 'reg_lambda': 7907.754583759651}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:28:55,673]\u001b[0m Trial 39 finished with value: -1.1333842015755815 and parameters: {'max_depth': 25, 'num_leaves': 20, 'learning_rate': 0.2073794416637678, 'n_estimators': 403, 'reg_alpha': 0.0002664467393978344, 'reg_lambda': 7044.313124003784}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:29:09,935]\u001b[0m Trial 44 finished with value: -1.1695108278160968 and parameters: {'max_depth': 22, 'num_leaves': 25, 'learning_rate': 0.02574649598246579, 'n_estimators': 168, 'reg_alpha': 8.349094849694103e-06, 'reg_lambda': 1152454.4702190524}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:29:18,205]\u001b[0m Trial 42 finished with value: -1.1094370258681427 and parameters: {'max_depth': 22, 'num_leaves': 25, 'learning_rate': 0.19363578666483916, 'n_estimators': 289, 'reg_alpha': 0.00021467089299592135, 'reg_lambda': 9457.582235233012}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:29:20,933]\u001b[0m Trial 38 finished with value: -1.091158817458094 and parameters: {'max_depth': 22, 'num_leaves': 26, 'learning_rate': 0.033811057058906024, 'n_estimators': 402, 'reg_alpha': 0.00015080408278959808, 'reg_lambda': 8204.252109899175}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:29:22,604]\u001b[0m Trial 43 finished with value: -1.03480621129155 and parameters: {'max_depth': 23, 'num_leaves': 25, 'learning_rate': 0.19775449996450045, 'n_estimators': 296, 'reg_alpha': 3.3195091431850796e-06, 'reg_lambda': 664421.7341500617}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:29:24,579]\u001b[0m Trial 45 finished with value: -1.0538188700833366 and parameters: {'max_depth': 20, 'num_leaves': 26, 'learning_rate': 0.1641748161503074, 'n_estimators': 82, 'reg_alpha': 9.609583960272184e-06, 'reg_lambda': 94240.4151308409}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:29:29,296]\u001b[0m Trial 46 finished with value: -1.0408906008712775 and parameters: {'max_depth': 20, 'num_leaves': 15, 'learning_rate': 0.035436208686541966, 'n_estimators': 77, 'reg_alpha': 9.537103287788092e-06, 'reg_lambda': 74849.62911295188}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:29:32,427]\u001b[0m Trial 47 finished with value: -1.043471429512984 and parameters: {'max_depth': 32, 'num_leaves': 15, 'learning_rate': 0.10460470186836388, 'n_estimators': 88, 'reg_alpha': 8.323580413792369e-06, 'reg_lambda': 140240.11116638102}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:29:45,119]\u001b[0m Trial 48 finished with value: -1.1145718283013757 and parameters: {'max_depth': 16, 'num_leaves': 16, 'learning_rate': 0.33600936170451395, 'n_estimators': 336, 'reg_alpha': 8.713284620561719e-07, 'reg_lambda': 73.06980487062596}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:29:54,440]\u001b[0m Trial 49 finished with value: -1.1152539734632358 and parameters: {'max_depth': 31, 'num_leaves': 32, 'learning_rate': 0.4587807579742795, 'n_estimators': 339, 'reg_alpha': 9.484593395238379e-07, 'reg_lambda': 77.80968322650493}. Best is trial 4 with value: -1.031471554586465.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:01,967]\u001b[0m A new study created in memory with name: no-name-8f8123c2-889d-4bea-9855-90979b4f4ea2\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:02,466]\u001b[0m Trial 2 finished with value: -2.833342809939391 and parameters: {'max_depth': 36, 'num_leaves': 13, 'learning_rate': 0.13769470546194745, 'n_estimators': 81, 'reg_alpha': 3434519.4638225427, 'reg_lambda': 8.889911959380603e-05}. Best is trial 2 with value: -2.833342809939391.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:02,733]\u001b[0m Trial 4 finished with value: -2.8333427990036872 and parameters: {'max_depth': 39, 'num_leaves': 26, 'learning_rate': 9.383505774327305e-06, 'n_estimators': 11, 'reg_alpha': 3.573413983655975e-05, 'reg_lambda': 1217413.7510415989}. Best is trial 4 with value: -2.8333427990036872.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:03,594]\u001b[0m Trial 0 finished with value: -2.8329390088096638 and parameters: {'max_depth': 4, 'num_leaves': 27, 'learning_rate': 0.27920946292400906, 'n_estimators': 112, 'reg_alpha': 7.41371941276531e-05, 'reg_lambda': 9110101.83112074}. Best is trial 0 with value: -2.8329390088096638.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:04,527]\u001b[0m Trial 3 finished with value: -2.833289949693306 and parameters: {'max_depth': 23, 'num_leaves': 23, 'learning_rate': 3.53333243289238e-05, 'n_estimators': 89, 'reg_alpha': 11.317848137210754, 'reg_lambda': 712.4529220259739}. Best is trial 0 with value: -2.8329390088096638.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:06,087]\u001b[0m Trial 7 finished with value: -2.898685290337113 and parameters: {'max_depth': 44, 'num_leaves': 5, 'learning_rate': 0.8647957402642242, 'n_estimators': 122, 'reg_alpha': 1.272045561217696e-07, 'reg_lambda': 41819.44090005212}. Best is trial 0 with value: -2.8329390088096638.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:07,972]\u001b[0m Trial 5 finished with value: -2.8333418814569655 and parameters: {'max_depth': 10, 'num_leaves': 17, 'learning_rate': 0.0001327686282671696, 'n_estimators': 371, 'reg_alpha': 37.82488016528137, 'reg_lambda': 6750396.978963345}. Best is trial 0 with value: -2.8329390088096638.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:08,018]\u001b[0m Trial 6 finished with value: -2.828301450711652 and parameters: {'max_depth': 17, 'num_leaves': 34, 'learning_rate': 0.008739220933382124, 'n_estimators': 188, 'reg_alpha': 0.3066189346235241, 'reg_lambda': 30855.33222830023}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:08,782]\u001b[0m Trial 10 finished with value: -2.8329920298916713 and parameters: {'max_depth': 5, 'num_leaves': 37, 'learning_rate': 0.10944840259526828, 'n_estimators': 37, 'reg_alpha': 1.9286970043280546e-05, 'reg_lambda': 1377524.2164637302}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:30:12,425]\u001b[0m Trial 8 finished with value: -2.833342243821039 and parameters: {'max_depth': 46, 'num_leaves': 14, 'learning_rate': 1.1652615033963637e-07, 'n_estimators': 210, 'reg_alpha': 0.022636327895499516, 'reg_lambda': 87.03512209521506}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:13,801]\u001b[0m Trial 12 finished with value: -2.8328233983047753 and parameters: {'max_depth': 35, 'num_leaves': 47, 'learning_rate': 0.2311543739396899, 'n_estimators': 147, 'reg_alpha': 258.1302039429156, 'reg_lambda': 5871403.503072497}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:14,350]\u001b[0m Trial 11 finished with value: -2.833460476494615 and parameters: {'max_depth': 6, 'num_leaves': 22, 'learning_rate': 0.0022261062393539167, 'n_estimators': 114, 'reg_alpha': 0.11847161355825733, 'reg_lambda': 1.3970960824939487e-05}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:15,192]\u001b[0m Trial 1 finished with value: -2.8330289367310586 and parameters: {'max_depth': 24, 'num_leaves': 22, 'learning_rate': 7.450243766787128e-05, 'n_estimators': 251, 'reg_alpha': 3.3969018888533316, 'reg_lambda': 0.0008501246631622305}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:15,282]\u001b[0m Trial 9 finished with value: -2.9318186366574883 and parameters: {'max_depth': 22, 'num_leaves': 17, 'learning_rate': 0.19094197389016102, 'n_estimators': 171, 'reg_alpha': 0.0020518714317710575, 'reg_lambda': 373.07471846644626}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:16,296]\u001b[0m Trial 15 finished with value: -2.833342809939391 and parameters: {'max_depth': 23, 'num_leaves': 50, 'learning_rate': 0.009704749827237059, 'n_estimators': 227, 'reg_alpha': 12540.133018284663, 'reg_lambda': 2997.756910800942}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:17,544]\u001b[0m Trial 14 finished with value: -2.830696283519454 and parameters: {'max_depth': 24, 'num_leaves': 49, 'learning_rate': 0.00844952860857462, 'n_estimators': 260, 'reg_alpha': 1423.4327283674647, 'reg_lambda': 2416.678760357422}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:19,157]\u001b[0m Trial 16 finished with value: -2.840952095976837 and parameters: {'max_depth': 31, 'num_leaves': 50, 'learning_rate': 0.007552739056755212, 'n_estimators': 301, 'reg_alpha': 876.0250818305979, 'reg_lambda': 0.5548608285775615}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:21,986]\u001b[0m Trial 18 finished with value: -2.8345306078423262 and parameters: {'max_depth': 14, 'num_leaves': 37, 'learning_rate': 0.004554032388555736, 'n_estimators': 344, 'reg_alpha': 1123.0516961058613, 'reg_lambda': 2.3051483195574582}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:23,414]\u001b[0m Trial 17 finished with value: -2.8672037973394113 and parameters: {'max_depth': 31, 'num_leaves': 38, 'learning_rate': 0.014071368387230495, 'n_estimators': 313, 'reg_alpha': 247.80612261520346, 'reg_lambda': 1.5013610178121894}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:32,681]\u001b[0m Trial 20 finished with value: -2.832105835521202 and parameters: {'max_depth': 16, 'num_leaves': 37, 'learning_rate': 0.0008201329470110033, 'n_estimators': 497, 'reg_alpha': 0.9329018219802742, 'reg_lambda': 35460.42683542567}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:32,994]\u001b[0m Trial 21 finished with value: -2.832428055309733 and parameters: {'max_depth': 16, 'num_leaves': 42, 'learning_rate': 0.0005742849353216803, 'n_estimators': 478, 'reg_alpha': 0.5149870162846067, 'reg_lambda': 33234.28569766974}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:30:34,367]\u001b[0m Trial 22 finished with value: -2.833342809939391 and parameters: {'max_depth': 18, 'num_leaves': 44, 'learning_rate': 0.02557578842565578, 'n_estimators': 421, 'reg_alpha': 51903.93709563067, 'reg_lambda': 2.305022209807885e-07}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:35,009]\u001b[0m Trial 23 finished with value: -2.833342809939391 and parameters: {'max_depth': 28, 'num_leaves': 31, 'learning_rate': 0.01792958639070287, 'n_estimators': 430, 'reg_alpha': 2198917.9660058105, 'reg_lambda': 2.3360183079916166e-07}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:38,781]\u001b[0m Trial 13 finished with value: -2.8839718263815737 and parameters: {'max_depth': 18, 'num_leaves': 38, 'learning_rate': 0.004292404534678053, 'n_estimators': 342, 'reg_alpha': 0.030262961753634493, 'reg_lambda': 0.7118559993039071}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:43,553]\u001b[0m Trial 26 finished with value: -2.8319159921125867 and parameters: {'max_depth': -1, 'num_leaves': 33, 'learning_rate': 0.0009222438687514782, 'n_estimators': 255, 'reg_alpha': 1.7275096978608608, 'reg_lambda': 18365.616495611113}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:44,537]\u001b[0m Trial 24 finished with value: -2.83208439996697 and parameters: {'max_depth': 12, 'num_leaves': 33, 'learning_rate': 0.0009474393531614714, 'n_estimators': 478, 'reg_alpha': 1.8091158190348509, 'reg_lambda': 39087.3939516463}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:45,313]\u001b[0m Trial 25 finished with value: -2.831887744027095 and parameters: {'max_depth': 0, 'num_leaves': 32, 'learning_rate': 0.0011910375309498772, 'n_estimators': 500, 'reg_alpha': 1.066066876659851, 'reg_lambda': 43775.6187065884}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:48,706]\u001b[0m Trial 29 finished with value: -2.831192255209573 and parameters: {'max_depth': 9, 'num_leaves': 42, 'learning_rate': 0.02974862318265708, 'n_estimators': 205, 'reg_alpha': 20.741643635457088, 'reg_lambda': 270402.31053551007}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:51,515]\u001b[0m Trial 30 finished with value: -2.8315851365752547 and parameters: {'max_depth': 9, 'num_leaves': 42, 'learning_rate': 0.06838817417707581, 'n_estimators': 176, 'reg_alpha': 29.312103049749112, 'reg_lambda': 657233.5104005906}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:58,071]\u001b[0m Trial 27 finished with value: -2.838522226916523 and parameters: {'max_depth': -1, 'num_leaves': 32, 'learning_rate': 0.0015769154977793643, 'n_estimators': 254, 'reg_alpha': 15.501453980811055, 'reg_lambda': 31.567946958336165}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:58,276]\u001b[0m Trial 19 finished with value: -2.8536898570371805 and parameters: {'max_depth': 14, 'num_leaves': 36, 'learning_rate': 0.0016736751257763578, 'n_estimators': 464, 'reg_alpha': 0.6734275023879117, 'reg_lambda': 5.207640652072056}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:30:59,346]\u001b[0m Trial 32 finished with value: -2.833342809939391 and parameters: {'max_depth': 20, 'num_leaves': 46, 'learning_rate': 0.038802629880267704, 'n_estimators': 210, 'reg_alpha': 6093.25835323297, 'reg_lambda': 3506.420074766758}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:30:59,464]\u001b[0m Trial 33 finished with value: -2.833342809939391 and parameters: {'max_depth': 28, 'num_leaves': 46, 'learning_rate': 0.036238681430080105, 'n_estimators': 206, 'reg_alpha': 8734.09023123513, 'reg_lambda': 2168.972813875746}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:00,760]\u001b[0m Trial 28 finished with value: -2.9191883807996453 and parameters: {'max_depth': 8, 'num_leaves': 32, 'learning_rate': 0.03745869188842486, 'n_estimators': 266, 'reg_alpha': 29.247135788495846, 'reg_lambda': 39.091064551869856}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:02,194]\u001b[0m Trial 34 finished with value: -2.828686208020885 and parameters: {'max_depth': 9, 'num_leaves': 42, 'learning_rate': 0.08182342548323583, 'n_estimators': 172, 'reg_alpha': 36.66117406748207, 'reg_lambda': 269099.4372406457}. Best is trial 6 with value: -2.828301450711652.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:03,109]\u001b[0m Trial 35 finished with value: -2.827866433059956 and parameters: {'max_depth': 10, 'num_leaves': 42, 'learning_rate': 0.07175968439106607, 'n_estimators': 175, 'reg_alpha': 23.273770112938102, 'reg_lambda': 160860.64737485963}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:03,640]\u001b[0m Trial 37 finished with value: -2.8356430196053934 and parameters: {'max_depth': 2, 'num_leaves': 41, 'learning_rate': 0.8110367085896706, 'n_estimators': 167, 'reg_alpha': 116.54930727406608, 'reg_lambda': 426254.6725080973}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:04,259]\u001b[0m Trial 36 finished with value: -2.82821072568685 and parameters: {'max_depth': 3, 'num_leaves': 41, 'learning_rate': 0.08420690154374752, 'n_estimators': 287, 'reg_alpha': 21.280084052284625, 'reg_lambda': 412677.4283046182}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:04,681]\u001b[0m Trial 38 finished with value: -2.8403060159571205 and parameters: {'max_depth': 2, 'num_leaves': 40, 'learning_rate': 0.5221043905035418, 'n_estimators': 160, 'reg_alpha': 217.55630949376157, 'reg_lambda': 192536.36513689594}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:05,037]\u001b[0m Trial 40 finished with value: -2.8330430312597934 and parameters: {'max_depth': 3, 'num_leaves': 29, 'learning_rate': 0.28924322274931613, 'n_estimators': 60, 'reg_alpha': 3.76288030361265, 'reg_lambda': 7067249.113092527}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:05,961]\u001b[0m Trial 39 finished with value: -2.8291705502569897 and parameters: {'max_depth': 26, 'num_leaves': 47, 'learning_rate': 0.0818362152791082, 'n_estimators': 141, 'reg_alpha': 5.079413180196337, 'reg_lambda': 258615.57955990473}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:05,979]\u001b[0m Trial 41 finished with value: -2.8331278960680963 and parameters: {'max_depth': 12, 'num_leaves': 27, 'learning_rate': 0.09633862672821986, 'n_estimators': 71, 'reg_alpha': 6.137212949833445, 'reg_lambda': 4047991.163074817}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:07,239]\u001b[0m Trial 42 finished with value: -2.832428208593953 and parameters: {'max_depth': 12, 'num_leaves': 27, 'learning_rate': 0.08925450233855163, 'n_estimators': 135, 'reg_alpha': 4.850189756209191, 'reg_lambda': 1365611.250686307}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:07,414]\u001b[0m Trial 43 finished with value: -2.8326335823948936 and parameters: {'max_depth': 12, 'num_leaves': 26, 'learning_rate': 0.11740161704820602, 'n_estimators': 89, 'reg_alpha': 0.06968682203536047, 'reg_lambda': 1602631.241554826}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:09,381]\u001b[0m Trial 44 finished with value: -2.828356641954474 and parameters: {'max_depth': 7, 'num_leaves': 44, 'learning_rate': 0.07916413773470624, 'n_estimators': 139, 'reg_alpha': 0.1528046060385971, 'reg_lambda': 191971.9732096498}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:10,420]\u001b[0m Trial 45 finished with value: -2.830407694307657 and parameters: {'max_depth': 7, 'num_leaves': 44, 'learning_rate': 0.2961222140056211, 'n_estimators': 92, 'reg_alpha': 0.12865352666004518, 'reg_lambda': 137722.25222876153}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:11,700]\u001b[0m Trial 31 finished with value: -2.916051917430811 and parameters: {'max_depth': 27, 'num_leaves': 45, 'learning_rate': 0.039290059020792134, 'n_estimators': 280, 'reg_alpha': 33.22799248044214, 'reg_lambda': 34.50690950383165}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:13,112]\u001b[0m Trial 47 finished with value: -2.8323605695341803 and parameters: {'max_depth': 5, 'num_leaves': 44, 'learning_rate': 0.4143053417377655, 'n_estimators': 230, 'reg_alpha': 0.21798576539028833, 'reg_lambda': 9948789.93837593}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py\", line 48, in rmse\n",
      "    y_pred = estimator.predict(X_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 803, in predict\n",
      "    return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 3538, in predict\n",
      "    return predictor.predict(data, start_iteration, num_iteration,\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 820, in predict\n",
      "    data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/lightgbm/basic.py\", line 566, in _data_from_pandas\n",
      "    raise ValueError('Input data must be 2 dimensional and non empty.')\n",
      "ValueError: Input data must be 2 dimensional and non empty.\n",
      "\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:15,343]\u001b[0m Trial 46 finished with value: -2.84670099641214 and parameters: {'max_depth': 26, 'num_leaves': 44, 'learning_rate': 0.3365494822957637, 'n_estimators': 186, 'reg_alpha': 0.26901179167399136, 'reg_lambda': 159753.7725371911}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:15,563]\u001b[0m Trial 49 finished with value: -2.8290266627299534 and parameters: {'max_depth': 6, 'num_leaves': 40, 'learning_rate': 0.37836335085578543, 'n_estimators': 230, 'reg_alpha': 0.005453207515476377, 'reg_lambda': 1866724.2837808942}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:16,149]\u001b[0m Trial 48 finished with value: -2.9119230827892473 and parameters: {'max_depth': 5, 'num_leaves': 35, 'learning_rate': 0.5093380956952287, 'n_estimators': 188, 'reg_alpha': 0.015833759615043276, 'reg_lambda': 13249.539162359759}. Best is trial 35 with value: -2.827866433059956.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:31:19,085]\u001b[0m A new study created in memory with name: no-name-b77692b2-0b0f-4b52-b00b-a452a53098ac\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:35,819]\u001b[0m Trial 3 finished with value: -1.5663996651519274 and parameters: {'max_depth': 26, 'num_leaves': 49, 'learning_rate': 0.004359072270858835, 'n_estimators': 79, 'reg_alpha': 48.04668965966411, 'reg_lambda': 0.0001975958497017214}. Best is trial 3 with value: -1.5663996651519274.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:39,107]\u001b[0m Trial 0 finished with value: -1.5111563211956283 and parameters: {'max_depth': 16, 'num_leaves': 17, 'learning_rate': 0.0034235035747713022, 'n_estimators': 215, 'reg_alpha': 0.00015037391024958331, 'reg_lambda': 1.1605505065199706}. Best is trial 0 with value: -1.5111563211956283.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:41,217]\u001b[0m Trial 1 finished with value: -1.6407164344561305 and parameters: {'max_depth': 26, 'num_leaves': 7, 'learning_rate': 6.517293220780764e-06, 'n_estimators': 462, 'reg_alpha': 97.59571538476024, 'reg_lambda': 3649.322189295559}. Best is trial 0 with value: -1.5111563211956283.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:46,363]\u001b[0m Trial 4 finished with value: -1.5605909780356655 and parameters: {'max_depth': 13, 'num_leaves': 26, 'learning_rate': 0.02067453238702489, 'n_estimators': 83, 'reg_alpha': 0.04893057119175583, 'reg_lambda': 0.932836689759456}. Best is trial 0 with value: -1.5111563211956283.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:51,876]\u001b[0m Trial 5 finished with value: -1.6324032871068663 and parameters: {'max_depth': 9, 'num_leaves': 44, 'learning_rate': 0.00032590461922794763, 'n_estimators': 70, 'reg_alpha': 0.0087289535427238, 'reg_lambda': 3.6093922907819612e-06}. Best is trial 0 with value: -1.5111563211956283.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:54,506]\u001b[0m Trial 7 finished with value: -1.6417459110322632 and parameters: {'max_depth': 2, 'num_leaves': 37, 'learning_rate': 4.2433987448441684e-07, 'n_estimators': 257, 'reg_alpha': 0.06537216664629536, 'reg_lambda': 16191.89545887118}. Best is trial 0 with value: -1.5111563211956283.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:58,777]\u001b[0m Trial 6 finished with value: -1.6375920340894738 and parameters: {'max_depth': 42, 'num_leaves': 39, 'learning_rate': 9.856021903171916e-05, 'n_estimators': 102, 'reg_alpha': 0.009154133650861606, 'reg_lambda': 1.7394996401607834e-06}. Best is trial 0 with value: -1.5111563211956283.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:31:59,383]\u001b[0m Trial 2 finished with value: -1.4895179137308572 and parameters: {'max_depth': 42, 'num_leaves': 27, 'learning_rate': 0.17332342201771966, 'n_estimators': 368, 'reg_alpha': 3354.3436547278493, 'reg_lambda': 2728671.3137266287}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:32:05,499]\u001b[0m Trial 8 finished with value: -1.6415272192149661 and parameters: {'max_depth': 37, 'num_leaves': 10, 'learning_rate': 2.8237184232323595e-06, 'n_estimators': 232, 'reg_alpha': 0.11323414467688403, 'reg_lambda': 594.0032409700746}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:32:13,945]\u001b[0m Trial 12 finished with value: -1.9223549879016626 and parameters: {'max_depth': 7, 'num_leaves': 30, 'learning_rate': 0.28741517550413676, 'n_estimators': 492, 'reg_alpha': 252099.7741280536, 'reg_lambda': 0.042201670321005906}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:32:29,764]\u001b[0m Trial 10 finished with value: -1.6397751515668433 and parameters: {'max_depth': 20, 'num_leaves': 15, 'learning_rate': 1.0119531387873173e-05, 'n_estimators': 408, 'reg_alpha': 1.119481782106848e-07, 'reg_lambda': 1.9419216219177323e-05}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:32:35,244]\u001b[0m Trial 11 finished with value: -1.5389018426559897 and parameters: {'max_depth': 42, 'num_leaves': 26, 'learning_rate': 0.0035462186694890803, 'n_estimators': 311, 'reg_alpha': 0.03339288536007522, 'reg_lambda': 2.4822685154757074e-06}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:32:35,340]\u001b[0m Trial 14 finished with value: -1.6417805185952394 and parameters: {'max_depth': 47, 'num_leaves': 20, 'learning_rate': 0.8121057496445597, 'n_estimators': 303, 'reg_alpha': 116211.58695984966, 'reg_lambda': 5660973.073425224}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:32:41,284]\u001b[0m Trial 15 finished with value: -1.6417805185952394 and parameters: {'max_depth': 32, 'num_leaves': 17, 'learning_rate': 0.5744391879083414, 'n_estimators': 345, 'reg_alpha': 3667748.7490056874, 'reg_lambda': 1122832.7903685768}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:32:48,264]\u001b[0m Trial 16 finished with value: -1.6095817367718346 and parameters: {'max_depth': 31, 'num_leaves': 18, 'learning_rate': 0.04799263658780566, 'n_estimators': 165, 'reg_alpha': 1.2492460344083745e-05, 'reg_lambda': 8432510.667805025}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:32:48,998]\u001b[0m Trial 13 finished with value: -1.500234407769003 and parameters: {'max_depth': 46, 'num_leaves': 23, 'learning_rate': 0.6932163525150695, 'n_estimators': 379, 'reg_alpha': 1.490933104366807e-07, 'reg_lambda': 7985203.4596266085}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:33:04,860]\u001b[0m Trial 17 finished with value: -1.6550341396950592 and parameters: {'max_depth': 17, 'num_leaves': 32, 'learning_rate': 0.04328482736056926, 'n_estimators': 177, 'reg_alpha': 4.530973767349651e-05, 'reg_lambda': 41.99713679125889}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:33:10,649]\u001b[0m Trial 9 finished with value: -1.6345423468180116 and parameters: {'max_depth': 39, 'num_leaves': 43, 'learning_rate': 3.980981848542e-05, 'n_estimators': 454, 'reg_alpha': 8.869015920413485e-07, 'reg_lambda': 1.2120795060870799e-06}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:33:12,411]\u001b[0m Trial 18 finished with value: -1.679299638428917 and parameters: {'max_depth': 17, 'num_leaves': 33, 'learning_rate': 0.059698657575406294, 'n_estimators': 187, 'reg_alpha': 904.1172185752204, 'reg_lambda': 69.67448762857235}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:33:33,912]\u001b[0m Trial 19 finished with value: -1.6157999476342055 and parameters: {'max_depth': 47, 'num_leaves': 32, 'learning_rate': 0.1257093381582717, 'n_estimators': 361, 'reg_alpha': 25.817354591268877, 'reg_lambda': 110894.60322180139}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:33:44,915]\u001b[0m Trial 20 finished with value: -1.6201256817556895 and parameters: {'max_depth': 47, 'num_leaves': 23, 'learning_rate': 0.09261080951105544, 'n_estimators': 396, 'reg_alpha': 11.179518724350935, 'reg_lambda': 98490.69032813108}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:33:49,673]\u001b[0m Trial 21 finished with value: -1.6399445814894005 and parameters: {'max_depth': 47, 'num_leaves': 24, 'learning_rate': 0.17006262209263603, 'n_estimators': 377, 'reg_alpha': 12.734106169572327, 'reg_lambda': 81988.81017849628}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:33:50,119]\u001b[0m Trial 22 finished with value: -1.6598967650658918 and parameters: {'max_depth': 47, 'num_leaves': 23, 'learning_rate': 0.9042621566421987, 'n_estimators': 381, 'reg_alpha': 2.448731780742555, 'reg_lambda': 127171.43364344268}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:33:52,107]\u001b[0m Trial 25 finished with value: -1.4915473738058889 and parameters: {'max_depth': 34, 'num_leaves': 12, 'learning_rate': 0.6820388326068001, 'n_estimators': 17, 'reg_alpha': 0.0001225723746495744, 'reg_lambda': 624361.3153381003}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:33:52,282]\u001b[0m Trial 26 finished with value: -1.6406936863055264 and parameters: {'max_depth': 33, 'num_leaves': 10, 'learning_rate': 0.012534657409556312, 'n_estimators': 20, 'reg_alpha': 0.000280307776455108, 'reg_lambda': 8573342.273205006}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:34:03,572]\u001b[0m Trial 24 finished with value: -1.6036368533043226 and parameters: {'max_depth': 34, 'num_leaves': 13, 'learning_rate': 0.5323880638031018, 'n_estimators': 256, 'reg_alpha': 0.0004430359551540212, 'reg_lambda': 351998.3342529426}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:34:12,356]\u001b[0m Trial 28 finished with value: -1.5476081645052235 and parameters: {'max_depth': 36, 'num_leaves': 13, 'learning_rate': 0.3015127012478104, 'n_estimators': 282, 'reg_alpha': 3.513352720454723e-06, 'reg_lambda': 693521.6089263058}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:34:12,377]\u001b[0m Trial 27 finished with value: -1.585589905470124 and parameters: {'max_depth': 33, 'num_leaves': 13, 'learning_rate': 0.9448989511530007, 'n_estimators': 282, 'reg_alpha': 0.0007340147248390968, 'reg_lambda': 1342485.007441942}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:34:14,753]\u001b[0m Trial 23 finished with value: -1.6375647896071472 and parameters: {'max_depth': 33, 'num_leaves': 23, 'learning_rate': 0.5066827070995448, 'n_estimators': 398, 'reg_alpha': 1.4261771245956452, 'reg_lambda': 118089.59243606013}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:34:28,735]\u001b[0m Trial 31 finished with value: -1.6832331081186889 and parameters: {'max_depth': 41, 'num_leaves': 5, 'learning_rate': 0.19811895844672897, 'n_estimators': 437, 'reg_alpha': 1.6340068148853608e-07, 'reg_lambda': 11321.132859372417}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:34:30,990]\u001b[0m Trial 30 finished with value: -1.6264497347881177 and parameters: {'max_depth': 41, 'num_leaves': 6, 'learning_rate': 0.9663586354738153, 'n_estimators': 438, 'reg_alpha': 2.8600741174446566e-07, 'reg_lambda': 873448.6741799748}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:34:33,277]\u001b[0m Trial 29 finished with value: -1.5058321543890438 and parameters: {'max_depth': 41, 'num_leaves': 21, 'learning_rate': 0.16920086285729577, 'n_estimators': 316, 'reg_alpha': 2.9372350217826448e-06, 'reg_lambda': 909030.614954444}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:34:56,814]\u001b[0m Trial 34 finished with value: -1.6965703096073879 and parameters: {'max_depth': 28, 'num_leaves': 20, 'learning_rate': 0.14231003082505092, 'n_estimators': 321, 'reg_alpha': 3.7085549372198955e-06, 'reg_lambda': 1295.1614405596404}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:02,081]\u001b[0m Trial 35 finished with value: -1.6633499946009913 and parameters: {'max_depth': 28, 'num_leaves': 19, 'learning_rate': 0.1357419850948922, 'n_estimators': 341, 'reg_alpha': 2.3760275596656526e-06, 'reg_lambda': 8942.685992822937}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:04,621]\u001b[0m Trial 37 finished with value: -1.6414580041572449 and parameters: {'max_depth': 44, 'num_leaves': 27, 'learning_rate': 0.00620961647403995, 'n_estimators': 13, 'reg_alpha': 4.490866956182198e-05, 'reg_lambda': 9360909.332540488}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:05,251]\u001b[0m Trial 32 finished with value: -1.5371357297055264 and parameters: {'max_depth': 41, 'num_leaves': 29, 'learning_rate': 0.0010284668200081397, 'n_estimators': 431, 'reg_alpha': 1.0133604359151177e-07, 'reg_lambda': 5066.075299441493}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:09,729]\u001b[0m Trial 33 finished with value: -1.6440026290129404 and parameters: {'max_depth': 28, 'num_leaves': 29, 'learning_rate': 0.019127995080547484, 'n_estimators': 337, 'reg_alpha': 4.8903252650875396e-05, 'reg_lambda': 2189.926744271065}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:35:23,000]\u001b[0m Trial 38 finished with value: -1.5758192597518403 and parameters: {'max_depth': 38, 'num_leaves': 30, 'learning_rate': 0.022113950223437533, 'n_estimators': 145, 'reg_alpha': 1.718210454864042e-05, 'reg_lambda': 1402637.175625625}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:24,356]\u001b[0m Trial 40 finished with value: -1.5637083161177836 and parameters: {'max_depth': 38, 'num_leaves': 35, 'learning_rate': 0.03765608282522137, 'n_estimators': 116, 'reg_alpha': 1.2543437898584754e-06, 'reg_lambda': 1549514.4631981102}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:34,718]\u001b[0m Trial 36 finished with value: -1.577685027515304 and parameters: {'max_depth': 43, 'num_leaves': 28, 'learning_rate': 0.02283002997740961, 'n_estimators': 335, 'reg_alpha': 2.7210355232274557e-05, 'reg_lambda': 20769.12924398502}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:45,419]\u001b[0m Trial 42 finished with value: -1.6456245618539584 and parameters: {'max_depth': 44, 'num_leaves': 21, 'learning_rate': 0.3249415000480475, 'n_estimators': 216, 'reg_alpha': 0.001406604040434958, 'reg_lambda': 29134.919266797533}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:46,570]\u001b[0m Trial 43 finished with value: -1.6640113745612162 and parameters: {'max_depth': 24, 'num_leaves': 9, 'learning_rate': 0.3413451616174159, 'n_estimators': 219, 'reg_alpha': 0.003158691938233277, 'reg_lambda': 44881.340002041805}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:47,043]\u001b[0m Trial 39 finished with value: -1.5100154647518256 and parameters: {'max_depth': 37, 'num_leaves': 21, 'learning_rate': 0.023757885252346594, 'n_estimators': 489, 'reg_alpha': 9.171059833518639e-07, 'reg_lambda': 1782251.999601174}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:35:55,781]\u001b[0m Trial 41 finished with value: -1.597650947728241 and parameters: {'max_depth': 23, 'num_leaves': 35, 'learning_rate': 0.054108014846973834, 'n_estimators': 225, 'reg_alpha': 0.0012019250802457928, 'reg_lambda': 32627.14646352686}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:02,475]\u001b[0m Trial 44 finished with value: -1.6437454656922281 and parameters: {'max_depth': 22, 'num_leaves': 16, 'learning_rate': 0.07782989680250738, 'n_estimators': 216, 'reg_alpha': 5.205788794327884e-07, 'reg_lambda': 1.1076162369974704e-07}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:09,588]\u001b[0m Trial 45 finished with value: -1.507972486266568 and parameters: {'max_depth': 14, 'num_leaves': 17, 'learning_rate': 0.08377593600354108, 'n_estimators': 282, 'reg_alpha': 6.482357800839808e-07, 'reg_lambda': 319352.70934867894}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:23,836]\u001b[0m Trial 46 finished with value: -1.5333057993950845 and parameters: {'max_depth': 36, 'num_leaves': 16, 'learning_rate': 0.07612470049687327, 'n_estimators': 486, 'reg_alpha': 6.991950204322517e-07, 'reg_lambda': 320287.11134521646}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:32,879]\u001b[0m Trial 47 finished with value: -1.5709036131326317 and parameters: {'max_depth': 35, 'num_leaves': 16, 'learning_rate': 0.12674128819376423, 'n_estimators': 489, 'reg_alpha': 4.891971787894554e-07, 'reg_lambda': 337267.7659497917}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:36,167]\u001b[0m Trial 49 finished with value: -1.59519567468446 and parameters: {'max_depth': 12, 'num_leaves': 25, 'learning_rate': 0.2723104081425719, 'n_estimators': 288, 'reg_alpha': 5.035391003173188e-06, 'reg_lambda': 332249.2958673827}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:41,415]\u001b[0m Trial 48 finished with value: -1.5027436759679145 and parameters: {'max_depth': 36, 'num_leaves': 25, 'learning_rate': 0.2338987121831733, 'n_estimators': 495, 'reg_alpha': 9.454749908991801e-07, 'reg_lambda': 2385732.8838758357}. Best is trial 2 with value: -1.4895179137308572.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:36:48,670]\u001b[0m A new study created in memory with name: no-name-243a664f-585d-4d9b-985f-196d3f28d22a\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:51,189]\u001b[0m Trial 2 finished with value: -1.8531941617735108 and parameters: {'max_depth': 7, 'num_leaves': 19, 'learning_rate': 2.740534513505717e-07, 'n_estimators': 21, 'reg_alpha': 2598233.936459351, 'reg_lambda': 40.80436257809471}. Best is trial 2 with value: -1.8531941617735108.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:57,442]\u001b[0m Trial 1 finished with value: -1.718072897415852 and parameters: {'max_depth': 19, 'num_leaves': 48, 'learning_rate': 0.03823305207703883, 'n_estimators': 32, 'reg_alpha': 0.40728189238159046, 'reg_lambda': 0.0011649361933789276}. Best is trial 1 with value: -1.718072897415852.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:57,678]\u001b[0m Trial 0 finished with value: -1.8519077235473367 and parameters: {'max_depth': 42, 'num_leaves': 5, 'learning_rate': 2.2667610928922907e-05, 'n_estimators': 171, 'reg_alpha': 4.17560463024258e-06, 'reg_lambda': 0.0007945120926921047}. Best is trial 1 with value: -1.718072897415852.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:36:58,103]\u001b[0m Trial 4 finished with value: -1.7946158747591041 and parameters: {'max_depth': 27, 'num_leaves': 24, 'learning_rate': 0.3521485475774859, 'n_estimators': 50, 'reg_alpha': 4.954745049163978e-07, 'reg_lambda': 50.82162783372234}. Best is trial 1 with value: -1.718072897415852.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:37:02,936]\u001b[0m Trial 5 finished with value: -1.8531941617735108 and parameters: {'max_depth': 20, 'num_leaves': 49, 'learning_rate': 2.1041258475528262e-07, 'n_estimators': 263, 'reg_alpha': 1719164.0557874162, 'reg_lambda': 5264181.948803469}. Best is trial 1 with value: -1.718072897415852.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:37:08,458]\u001b[0m Trial 7 finished with value: -1.6906273289739349 and parameters: {'max_depth': 3, 'num_leaves': 19, 'learning_rate': 0.003741665314718749, 'n_estimators': 216, 'reg_alpha': 0.001284233066163363, 'reg_lambda': 0.008945986597428322}. Best is trial 7 with value: -1.6906273289739349.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:37:29,857]\u001b[0m Trial 9 finished with value: -1.7985268062133346 and parameters: {'max_depth': -1, 'num_leaves': 31, 'learning_rate': 0.00080865448864709, 'n_estimators': 156, 'reg_alpha': 0.0011730766773022177, 'reg_lambda': 0.027281193508943473}. Best is trial 7 with value: -1.6906273289739349.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:37:35,691]\u001b[0m Trial 3 finished with value: -1.8321008281583882 and parameters: {'max_depth': 42, 'num_leaves': 39, 'learning_rate': 0.00015339569997742522, 'n_estimators': 283, 'reg_alpha': 2.1298686614924698e-05, 'reg_lambda': 1.0475400139913515}. Best is trial 7 with value: -1.6906273289739349.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:37:41,710]\u001b[0m Trial 11 finished with value: -1.8525393581779 and parameters: {'max_depth': 19, 'num_leaves': 46, 'learning_rate': 5.7102527799709174e-05, 'n_estimators': 85, 'reg_alpha': 51701.076562287766, 'reg_lambda': 65619.84481874417}. Best is trial 7 with value: -1.6906273289739349.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:37:47,329]\u001b[0m Trial 8 finished with value: -1.9641980090850468 and parameters: {'max_depth': 20, 'num_leaves': 30, 'learning_rate': 0.6629426783733123, 'n_estimators': 468, 'reg_alpha': 0.005368466237060909, 'reg_lambda': 0.4588671475881169}. Best is trial 7 with value: -1.6906273289739349.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:37:54,171]\u001b[0m Trial 6 finished with value: -1.8530619433869822 and parameters: {'max_depth': 43, 'num_leaves': 33, 'learning_rate': 6.615651615118727e-07, 'n_estimators': 399, 'reg_alpha': 2.519234226437584e-07, 'reg_lambda': 4.15355522184066}. Best is trial 7 with value: -1.6906273289739349.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:38:10,228]\u001b[0m Trial 13 finished with value: -1.6796998571250863 and parameters: {'max_depth': 8, 'num_leaves': 10, 'learning_rate': 0.004804988883167562, 'n_estimators': 380, 'reg_alpha': 17.48823189222016, 'reg_lambda': 1.912196872094594e-07}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:11,933]\u001b[0m Trial 12 finished with value: -1.7320334022129305 and parameters: {'max_depth': 47, 'num_leaves': 25, 'learning_rate': 0.028432424122375306, 'n_estimators': 261, 'reg_alpha': 104.29899960914219, 'reg_lambda': 2447.8238052616216}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:19,734]\u001b[0m Trial 14 finished with value: -1.7186257513323437 and parameters: {'max_depth': 8, 'num_leaves': 13, 'learning_rate': 0.014223790290306819, 'n_estimators': 346, 'reg_alpha': 7.187711893430048, 'reg_lambda': 2.2512435210158488e-06}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:32,915]\u001b[0m Trial 10 finished with value: -1.7102322014707076 and parameters: {'max_depth': 27, 'num_leaves': 28, 'learning_rate': 0.0023680766570742836, 'n_estimators': 493, 'reg_alpha': 0.0007668653083601084, 'reg_lambda': 0.008125590603292696}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:35,952]\u001b[0m Trial 16 finished with value: -1.6909543504444273 and parameters: {'max_depth': 8, 'num_leaves': 11, 'learning_rate': 0.0037234992051156214, 'n_estimators': 345, 'reg_alpha': 3.883998415625551, 'reg_lambda': 2.1593016221566435e-06}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:37,081]\u001b[0m Trial 15 finished with value: -1.704136051251518 and parameters: {'max_depth': 7, 'num_leaves': 12, 'learning_rate': 0.006128738215547393, 'n_estimators': 393, 'reg_alpha': 36.058720386921664, 'reg_lambda': 5.523615703451793e-07}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:43,526]\u001b[0m Trial 20 finished with value: -1.8088992319425519 and parameters: {'max_depth': 2, 'num_leaves': 18, 'learning_rate': 0.0006506763614349199, 'n_estimators': 166, 'reg_alpha': 0.019835636769956873, 'reg_lambda': 1.8985374548702876e-05}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:43,588]\u001b[0m Trial 17 finished with value: -1.71227890168577 and parameters: {'max_depth': -1, 'num_leaves': 10, 'learning_rate': 0.001862603719760581, 'n_estimators': 362, 'reg_alpha': 0.07226702723196726, 'reg_lambda': 5.54931162540865e-07}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:53,521]\u001b[0m Trial 21 finished with value: -1.732014673350628 and parameters: {'max_depth': 13, 'num_leaves': 7, 'learning_rate': 0.10836578927588925, 'n_estimators': 203, 'reg_alpha': 0.09167183486194419, 'reg_lambda': 5.8907412719512636e-05}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:54,335]\u001b[0m Trial 19 finished with value: -1.8133347906110107 and parameters: {'max_depth': -1, 'num_leaves': 18, 'learning_rate': 0.0005371476331395507, 'n_estimators': 176, 'reg_alpha': 2509.1305320947727, 'reg_lambda': 4.4391865292775127e-07}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:57,278]\u001b[0m Trial 22 finished with value: -1.7445784922149394 and parameters: {'max_depth': 14, 'num_leaves': 19, 'learning_rate': 0.07046290645878324, 'n_estimators': 210, 'reg_alpha': 3858.7979063358543, 'reg_lambda': 5.4993205717305475e-05}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:38:59,754]\u001b[0m Trial 18 finished with value: -1.7005920238072272 and parameters: {'max_depth': -1, 'num_leaves': 12, 'learning_rate': 0.0034658350183159265, 'n_estimators': 352, 'reg_alpha': 0.2300161546537253, 'reg_lambda': 1.3154199565357124e-07}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:11,183]\u001b[0m Trial 23 finished with value: -1.754539712444607 and parameters: {'max_depth': 12, 'num_leaves': 18, 'learning_rate': 0.09192374001005343, 'n_estimators': 437, 'reg_alpha': 1987.0791693416313, 'reg_lambda': 4.612115085568323e-05}. Best is trial 13 with value: -1.6796998571250863.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:18,343]\u001b[0m Trial 26 finished with value: -1.6780729161879702 and parameters: {'max_depth': 12, 'num_leaves': 8, 'learning_rate': 0.006779218501493033, 'n_estimators': 313, 'reg_alpha': 2.310067428884358, 'reg_lambda': 8.494537236341689e-06}. Best is trial 26 with value: -1.6780729161879702.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:21,413]\u001b[0m Trial 24 finished with value: -1.713209606026254 and parameters: {'max_depth': 13, 'num_leaves': 15, 'learning_rate': 0.007583956793251578, 'n_estimators': 311, 'reg_alpha': 1.664509556587327, 'reg_lambda': 3.769484424340643e-05}. Best is trial 26 with value: -1.6780729161879702.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:24,865]\u001b[0m Trial 25 finished with value: -1.700321633418349 and parameters: {'max_depth': 12, 'num_leaves': 14, 'learning_rate': 0.005769505090322074, 'n_estimators': 321, 'reg_alpha': 3.2632495379167734, 'reg_lambda': 1.7085042842647396e-07}. Best is trial 26 with value: -1.6780729161879702.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:27,724]\u001b[0m Trial 27 finished with value: -1.685877711256036 and parameters: {'max_depth': 4, 'num_leaves': 8, 'learning_rate': 0.008703503325265018, 'n_estimators': 300, 'reg_alpha': 3.9250388540727243, 'reg_lambda': 3.966731743770785e-06}. Best is trial 26 with value: -1.6780729161879702.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:28,835]\u001b[0m Trial 29 finished with value: -1.6848871580228157 and parameters: {'max_depth': 4, 'num_leaves': 8, 'learning_rate': 0.01586675869057054, 'n_estimators': 113, 'reg_alpha': 0.00017436153839038988, 'reg_lambda': 7.1260123591001435e-06}. Best is trial 26 with value: -1.6780729161879702.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:34,349]\u001b[0m Trial 32 finished with value: -1.6748859944181926 and parameters: {'max_depth': 33, 'num_leaves': 6, 'learning_rate': 0.023570390800580467, 'n_estimators': 88, 'reg_alpha': 2.8259747204273893e-05, 'reg_lambda': 0.0003746944389985103}. Best is trial 32 with value: -1.6748859944181926.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:35,333]\u001b[0m Trial 28 finished with value: -1.7090703563037115 and parameters: {'max_depth': 4, 'num_leaves': 8, 'learning_rate': 0.011382385775163867, 'n_estimators': 299, 'reg_alpha': 0.9698273040484445, 'reg_lambda': 7.444423401064776e-06}. Best is trial 32 with value: -1.6748859944181926.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:35,660]\u001b[0m Trial 30 finished with value: -1.6771679337798429 and parameters: {'max_depth': 5, 'num_leaves': 7, 'learning_rate': 0.017356036455748673, 'n_estimators': 123, 'reg_alpha': 75.17157293882669, 'reg_lambda': 5.948305587120034e-06}. Best is trial 32 with value: -1.6748859944181926.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:40,945]\u001b[0m Trial 34 finished with value: -1.6660006459313754 and parameters: {'max_depth': 34, 'num_leaves': 5, 'learning_rate': 0.02410371853245874, 'n_estimators': 99, 'reg_alpha': 2.3735814659168797e-05, 'reg_lambda': 0.00031343605466390085}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:42,052]\u001b[0m Trial 35 finished with value: -1.695009818746712 and parameters: {'max_depth': 31, 'num_leaves': 5, 'learning_rate': 0.032321788467995154, 'n_estimators': 119, 'reg_alpha': 149.34191477720154, 'reg_lambda': 0.00045748373000730754}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:45,762]\u001b[0m Trial 37 finished with value: -1.7367570124489244 and parameters: {'max_depth': 37, 'num_leaves': 5, 'learning_rate': 0.16696808317241896, 'n_estimators': 58, 'reg_alpha': 4.023319230884736e-06, 'reg_lambda': 0.000504880675760319}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:47,006]\u001b[0m Trial 38 finished with value: -1.8400656330082714 and parameters: {'max_depth': 35, 'num_leaves': 5, 'learning_rate': 0.04051134926762086, 'n_estimators': 1, 'reg_alpha': 9.461993892637042e-05, 'reg_lambda': 0.00024261815741355466}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:47,473]\u001b[0m Trial 36 finished with value: -1.707532562304115 and parameters: {'max_depth': 34, 'num_leaves': 5, 'learning_rate': 0.0370546221771912, 'n_estimators': 115, 'reg_alpha': 1.1770761789534566e-05, 'reg_lambda': 0.00041539200670939335}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:39:50,112]\u001b[0m Trial 31 finished with value: -1.7313766744317505 and parameters: {'max_depth': 4, 'num_leaves': 8, 'learning_rate': 0.019110218340461605, 'n_estimators': 425, 'reg_alpha': 90.79204543490422, 'reg_lambda': 3.883335810698204e-06}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:51,095]\u001b[0m Trial 33 finished with value: -1.7820885286099144 and parameters: {'max_depth': 34, 'num_leaves': 5, 'learning_rate': 0.21992712371691528, 'n_estimators': 412, 'reg_alpha': 1.0906002861250804e-05, 'reg_lambda': 0.00037838077690848816}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:55,680]\u001b[0m Trial 39 finished with value: -1.789557129035493 and parameters: {'max_depth': 25, 'num_leaves': 15, 'learning_rate': 0.21944644022305237, 'n_estimators': 105, 'reg_alpha': 3.8077895922019057e-06, 'reg_lambda': 0.001907098893971074}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:57,043]\u001b[0m Trial 41 finished with value: -1.7733650365844231 and parameters: {'max_depth': 24, 'num_leaves': 15, 'learning_rate': 0.28969403684854683, 'n_estimators': 83, 'reg_alpha': 1.3372687060669923e-07, 'reg_lambda': 0.005700927018046045}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:58,919]\u001b[0m Trial 42 finished with value: -1.9206253774757533 and parameters: {'max_depth': 24, 'num_leaves': 22, 'learning_rate': 0.4954117888299835, 'n_estimators': 78, 'reg_alpha': 4.815523634818479e-07, 'reg_lambda': 0.003031810296926208}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:39:59,899]\u001b[0m Trial 40 finished with value: -1.8167833459899423 and parameters: {'max_depth': 26, 'num_leaves': 37, 'learning_rate': 0.32041594580928207, 'n_estimators': 83, 'reg_alpha': 3.5019998410013925e-07, 'reg_lambda': 0.002388586560984675}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:06,498]\u001b[0m Trial 44 finished with value: -1.7956566779335823 and parameters: {'max_depth': 38, 'num_leaves': 9, 'learning_rate': 0.0012584877160511708, 'n_estimators': 141, 'reg_alpha': 7.52992038973185e-07, 'reg_lambda': 1.0762450690778699e-07}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:06,921]\u001b[0m Trial 43 finished with value: -1.756338836756607 and parameters: {'max_depth': 40, 'num_leaves': 39, 'learning_rate': 0.06595297811849458, 'n_estimators': 61, 'reg_alpha': 5.855186410160569e-07, 'reg_lambda': 0.056164022497366295}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:09,287]\u001b[0m Trial 45 finished with value: -1.772763468397805 and parameters: {'max_depth': 16, 'num_leaves': 10, 'learning_rate': 0.0017577763325952527, 'n_estimators': 143, 'reg_alpha': 0.6510548321034596, 'reg_lambda': 1.1424267334422672e-07}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:10,132]\u001b[0m Trial 46 finished with value: -1.7910256030540406 and parameters: {'max_depth': 16, 'num_leaves': 9, 'learning_rate': 0.0014333736520376725, 'n_estimators': 140, 'reg_alpha': 0.42216069078076757, 'reg_lambda': 1.2125897942238273e-06}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:10,448]\u001b[0m Trial 48 finished with value: -1.8500096642605302 and parameters: {'max_depth': 16, 'num_leaves': 10, 'learning_rate': 0.00022995790142351735, 'n_estimators': 34, 'reg_alpha': 0.601266496880898, 'reg_lambda': 9.016019971638749e-05}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:11,207]\u001b[0m Trial 47 finished with value: -1.8492877139103812 and parameters: {'max_depth': 30, 'num_leaves': 10, 'learning_rate': 0.00024651121918028843, 'n_estimators': 40, 'reg_alpha': 0.008593705186651293, 'reg_lambda': 0.08548214924366355}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:16,264]\u001b[0m Trial 49 finished with value: -1.8303582421519697 and parameters: {'max_depth': 30, 'num_leaves': 7, 'learning_rate': 0.000320570757461959, 'n_estimators': 240, 'reg_alpha': 0.016780971764308865, 'reg_lambda': 0.00010189357615269045}. Best is trial 34 with value: -1.6660006459313754.\u001b[0m\n",
      " 94%|    | 15/16 [3:30:42<17:48, 1068.33s/it]/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:40:18,788]\u001b[0m A new study created in memory with name: no-name-86ffc73a-9669-45c2-be30-1517af282a66\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:24,174]\u001b[0m Trial 2 finished with value: -1.3948735801162 and parameters: {'max_depth': 38, 'num_leaves': 7, 'learning_rate': 1.7339180258180122e-07, 'n_estimators': 60, 'reg_alpha': 85277.87776252799, 'reg_lambda': 5587.769096405412}. Best is trial 2 with value: -1.3948735801162.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:25,267]\u001b[0m Trial 1 finished with value: -1.175612720897717 and parameters: {'max_depth': 1, 'num_leaves': 43, 'learning_rate': 0.30318109444809777, 'n_estimators': 169, 'reg_alpha': 597.9486291561003, 'reg_lambda': 3192265.296195886}. Best is trial 1 with value: -1.175612720897717.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:26,362]\u001b[0m Trial 0 finished with value: -1.3835391138417903 and parameters: {'max_depth': 17, 'num_leaves': 14, 'learning_rate': 0.00027156423679415364, 'n_estimators': 56, 'reg_alpha': 0.9648253010942592, 'reg_lambda': 0.0063342523331216295}. Best is trial 1 with value: -1.175612720897717.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:30,265]\u001b[0m Trial 4 finished with value: -0.9718200808825319 and parameters: {'max_depth': 39, 'num_leaves': 5, 'learning_rate': 0.056643961429877, 'n_estimators': 114, 'reg_alpha': 10.710746688659022, 'reg_lambda': 0.21201717636758466}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:36,837]\u001b[0m Trial 3 finished with value: -1.3948661061087753 and parameters: {'max_depth': 42, 'num_leaves': 18, 'learning_rate': 2.1964112810923753e-06, 'n_estimators': 425, 'reg_alpha': 0.0077989817542977475, 'reg_lambda': 6689254.947724461}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:45,773]\u001b[0m Trial 8 finished with value: -1.3948752900368446 and parameters: {'max_depth': 43, 'num_leaves': 41, 'learning_rate': 0.005063267913312642, 'n_estimators': 390, 'reg_alpha': 1269781.5858459806, 'reg_lambda': 155.026385293467}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:40:56,712]\u001b[0m Trial 6 finished with value: -1.0599924508006797 and parameters: {'max_depth': 0, 'num_leaves': 15, 'learning_rate': 0.013909050081926102, 'n_estimators': 329, 'reg_alpha': 0.06313013896364526, 'reg_lambda': 15.98703252460615}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:41:02,875]\u001b[0m Trial 9 finished with value: -1.3874055915618084 and parameters: {'max_depth': 7, 'num_leaves': 21, 'learning_rate': 7.960689404150168e-05, 'n_estimators': 294, 'reg_alpha': 6.839162208456016e-06, 'reg_lambda': 81423.48737118504}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:41:13,182]\u001b[0m Trial 7 finished with value: -1.0385028085991084 and parameters: {'max_depth': 27, 'num_leaves': 44, 'learning_rate': 0.01689969762947827, 'n_estimators': 401, 'reg_alpha': 3436.456526757904, 'reg_lambda': 0.08505286892338057}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:41:27,218]\u001b[0m Trial 12 finished with value: -1.394631913303967 and parameters: {'max_depth': 31, 'num_leaves': 27, 'learning_rate': 3.380215855198933e-06, 'n_estimators': 102, 'reg_alpha': 0.0001890526018185255, 'reg_lambda': 3.3306518177742044e-07}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:41:29,697]\u001b[0m Trial 5 finished with value: -1.3921903793393202 and parameters: {'max_depth': 20, 'num_leaves': 50, 'learning_rate': 1.3070269505467781e-05, 'n_estimators': 289, 'reg_alpha': 0.0013791744702757187, 'reg_lambda': 1.8089748760747622e-06}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:41:33,799]\u001b[0m Trial 13 finished with value: -1.1790196141047364 and parameters: {'max_depth': 19, 'num_leaves': 5, 'learning_rate': 0.9704115560696056, 'n_estimators': 184, 'reg_alpha': 458.5175316895456, 'reg_lambda': 0.0003757295381893269}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:41:54,536]\u001b[0m Trial 14 finished with value: -1.2696156224522746 and parameters: {'max_depth': 29, 'num_leaves': 34, 'learning_rate': 0.3709593024434252, 'n_estimators': 495, 'reg_alpha': 75.94558232111268, 'reg_lambda': 0.029329875621029938}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:06,145]\u001b[0m Trial 10 finished with value: -1.1913470486684883 and parameters: {'max_depth': 33, 'num_leaves': 49, 'learning_rate': 0.0026357756506362367, 'n_estimators': 332, 'reg_alpha': 6.583961678373859e-07, 'reg_lambda': 0.0051184387334183784}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:09,127]\u001b[0m Trial 11 finished with value: -1.0934752617790815 and parameters: {'max_depth': 14, 'num_leaves': 42, 'learning_rate': 0.5068944822403485, 'n_estimators': 464, 'reg_alpha': 7.931865790729065e-07, 'reg_lambda': 1392010.8501893268}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:23,139]\u001b[0m Trial 16 finished with value: -1.179786921412771 and parameters: {'max_depth': 31, 'num_leaves': 31, 'learning_rate': 0.014538286466550462, 'n_estimators': 193, 'reg_alpha': 6.31535990203763, 'reg_lambda': 1.3294766484781857}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:33,521]\u001b[0m Trial 19 finished with value: -1.0377914594629 and parameters: {'max_depth': 47, 'num_leaves': 26, 'learning_rate': 0.04875782792330284, 'n_estimators': 119, 'reg_alpha': 7000.1470327145435, 'reg_lambda': 0.7287451739773219}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:35,104]\u001b[0m Trial 20 finished with value: -1.3948752900368446 and parameters: {'max_depth': 47, 'num_leaves': 25, 'learning_rate': 0.07361004373845023, 'n_estimators': 18, 'reg_alpha': 8970835.343279459, 'reg_lambda': 68.31123833809819}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:39,997]\u001b[0m Trial 17 finished with value: -1.1923923954340787 and parameters: {'max_depth': 26, 'num_leaves': 31, 'learning_rate': 0.026909568977807573, 'n_estimators': 229, 'reg_alpha': 9.496956126400866, 'reg_lambda': 0.4012062767777448}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:41,056]\u001b[0m Trial 21 finished with value: -1.085084141113683 and parameters: {'max_depth': 38, 'num_leaves': 11, 'learning_rate': 0.07700152262378777, 'n_estimators': 121, 'reg_alpha': 23322.260655178612, 'reg_lambda': 1.384341626835737}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:46,764]\u001b[0m Trial 15 finished with value: -1.1637275814050343 and parameters: {'max_depth': 32, 'num_leaves': 33, 'learning_rate': 0.010565818747147179, 'n_estimators': 490, 'reg_alpha': 56.017095183905255, 'reg_lambda': 0.12355203776984408}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:48,211]\u001b[0m Trial 18 finished with value: -1.191689879011633 and parameters: {'max_depth': 27, 'num_leaves': 32, 'learning_rate': 0.023838944236837592, 'n_estimators': 199, 'reg_alpha': 7.971163611423561, 'reg_lambda': 0.7332511335874952}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:49,564]\u001b[0m Trial 22 finished with value: -1.306727704188983 and parameters: {'max_depth': 37, 'num_leaves': 11, 'learning_rate': 0.001629817892881007, 'n_estimators': 123, 'reg_alpha': 10279.606533055148, 'reg_lambda': 0.00020859779944785192}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:50,579]\u001b[0m Trial 23 finished with value: -1.2909743017145168 and parameters: {'max_depth': 36, 'num_leaves': 24, 'learning_rate': 0.0022660160303024975, 'n_estimators': 127, 'reg_alpha': 20505.560517640308, 'reg_lambda': 0.0003949267559684656}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:42:57,943]\u001b[0m Trial 24 finished with value: -1.3272476550966092 and parameters: {'max_depth': 47, 'num_leaves': 38, 'learning_rate': 0.001068149674310706, 'n_estimators': 124, 'reg_alpha': 6341.648511147156, 'reg_lambda': 0.0002532391482537735}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:00,223]\u001b[0m Trial 28 finished with value: -1.172747544020203 and parameters: {'max_depth': 42, 'num_leaves': 46, 'learning_rate': 0.07311698648133766, 'n_estimators': 6, 'reg_alpha': 1646.9625581167886, 'reg_lambda': 10.494540602100193}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:03,361]\u001b[0m Trial 27 finished with value: -1.0191689239781836 and parameters: {'max_depth': 47, 'num_leaves': 45, 'learning_rate': 0.11835777106974892, 'n_estimators': 67, 'reg_alpha': 1103.3592763329636, 'reg_lambda': 4.42983024338814}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:03,831]\u001b[0m Trial 25 finished with value: -1.3224886738123376 and parameters: {'max_depth': 47, 'num_leaves': 39, 'learning_rate': 0.0008957300015405825, 'n_estimators': 135, 'reg_alpha': 2925.7099573556175, 'reg_lambda': 0.002021366593400582}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:06,599]\u001b[0m Trial 30 finished with value: -1.3948752900368446 and parameters: {'max_depth': 44, 'num_leaves': 37, 'learning_rate': 0.19887617386992815, 'n_estimators': 75, 'reg_alpha': 236436.38706601036, 'reg_lambda': 667.7933541475682}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:06,672]\u001b[0m Trial 31 finished with value: -1.3948752900368446 and parameters: {'max_depth': 43, 'num_leaves': 37, 'learning_rate': 0.254048732615446, 'n_estimators': 66, 'reg_alpha': 160282.99033211757, 'reg_lambda': 978.7235680949491}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:06,790]\u001b[0m Trial 26 finished with value: -1.025818774936013 and parameters: {'max_depth': 43, 'num_leaves': 38, 'learning_rate': 0.11628821163325669, 'n_estimators': 146, 'reg_alpha': 1252.7212216442633, 'reg_lambda': 9.72999324117484}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:07,096]\u001b[0m Trial 29 finished with value: -1.3948752900368446 and parameters: {'max_depth': 24, 'num_leaves': 37, 'learning_rate': 0.1270296957095172, 'n_estimators': 257, 'reg_alpha': 319225.4402887782, 'reg_lambda': 706.2184367364579}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:11,699]\u001b[0m Trial 32 finished with value: -1.1218239590965013 and parameters: {'max_depth': 40, 'num_leaves': 19, 'learning_rate': 0.13618555774431462, 'n_estimators': 38, 'reg_alpha': 0.657440387267967, 'reg_lambda': 0.01956428754306916}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:12,113]\u001b[0m Trial 33 finished with value: -1.1113835474366542 and parameters: {'max_depth': 38, 'num_leaves': 19, 'learning_rate': 0.10422624517243768, 'n_estimators': 39, 'reg_alpha': 0.7109545472528747, 'reg_lambda': 9.938083593271706}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:15,118]\u001b[0m Trial 34 finished with value: -1.2137071320476878 and parameters: {'max_depth': 40, 'num_leaves': 47, 'learning_rate': 0.10416857718982875, 'n_estimators': 26, 'reg_alpha': 0.8322783059108791, 'reg_lambda': 7.231076368753315}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:15,305]\u001b[0m Trial 35 finished with value: -1.1252236402377596 and parameters: {'max_depth': 40, 'num_leaves': 47, 'learning_rate': 0.04851751774467984, 'n_estimators': 34, 'reg_alpha': 263.4069739581886, 'reg_lambda': 6.505659664585174}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:22,314]\u001b[0m Trial 37 finished with value: -1.326871037708396 and parameters: {'max_depth': 45, 'num_leaves': 46, 'learning_rate': 0.9946994546006802, 'n_estimators': 156, 'reg_alpha': 229.96034887053236, 'reg_lambda': 2.9792271090282}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:43:22,910]\u001b[0m Trial 39 finished with value: -1.0466249802286065 and parameters: {'max_depth': 35, 'num_leaves': 11, 'learning_rate': 0.6415227526006875, 'n_estimators': 156, 'reg_alpha': 483.1146805463328, 'reg_lambda': 0.10524563853521764}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:25,712]\u001b[0m Trial 38 finished with value: -1.2268979031673197 and parameters: {'max_depth': 45, 'num_leaves': 45, 'learning_rate': 0.8243319627833878, 'n_estimators': 154, 'reg_alpha': 357.1399618067286, 'reg_lambda': 0.1874352709490666}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:27,763]\u001b[0m Trial 41 finished with value: -1.2481987927662002 and parameters: {'max_depth': 45, 'num_leaves': 14, 'learning_rate': 0.007081079425795596, 'n_estimators': 82, 'reg_alpha': 38326.75021571517, 'reg_lambda': 25.577990221645408}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:30,992]\u001b[0m Trial 40 finished with value: -1.0228386451367353 and parameters: {'max_depth': 35, 'num_leaves': 14, 'learning_rate': 0.035634997290885595, 'n_estimators': 80, 'reg_alpha': 823.2828588416033, 'reg_lambda': 0.2410014036468242}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:32,003]\u001b[0m Trial 42 finished with value: -1.1155276607047362 and parameters: {'max_depth': 41, 'num_leaves': 16, 'learning_rate': 0.03901959829120379, 'n_estimators': 82, 'reg_alpha': 26961.647455828188, 'reg_lambda': 62.426228815308306}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:37,438]\u001b[0m Trial 44 finished with value: -0.9743303859445356 and parameters: {'max_depth': 43, 'num_leaves': 7, 'learning_rate': 0.037372096856860874, 'n_estimators': 94, 'reg_alpha': 1841.0348743451577, 'reg_lambda': 0.8026926718290649}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:38,926]\u001b[0m Trial 45 finished with value: -0.9784717686709943 and parameters: {'max_depth': 35, 'num_leaves': 8, 'learning_rate': 0.031000449789204323, 'n_estimators': 98, 'reg_alpha': 1860.1481993218192, 'reg_lambda': 0.6253933282889677}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:41,825]\u001b[0m Trial 43 finished with value: -1.0451430511136781 and parameters: {'max_depth': 12, 'num_leaves': 41, 'learning_rate': 0.035408697979793916, 'n_estimators': 89, 'reg_alpha': 2233.8321144965994, 'reg_lambda': 128.5673919642497}. Best is trial 4 with value: -0.9718200808825319.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:42,464]\u001b[0m Trial 46 finished with value: -0.9671398528104536 and parameters: {'max_depth': 34, 'num_leaves': 8, 'learning_rate': 0.29176742881571716, 'n_estimators': 94, 'reg_alpha': 2182.399133756266, 'reg_lambda': 2.5070858620674645}. Best is trial 46 with value: -0.9671398528104536.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:46,233]\u001b[0m Trial 47 finished with value: -1.1192532220507585 and parameters: {'max_depth': 33, 'num_leaves': 8, 'learning_rate': 0.006767725555623901, 'n_estimators': 98, 'reg_alpha': 49.61476842504213, 'reg_lambda': 0.025262832448136978}. Best is trial 46 with value: -0.9671398528104536.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:47,226]\u001b[0m Trial 36 finished with value: -1.1212840633381005 and parameters: {'max_depth': 45, 'num_leaves': 47, 'learning_rate': 0.0443119364758513, 'n_estimators': 159, 'reg_alpha': 274.06973654315135, 'reg_lambda': 6.236067613763648}. Best is trial 46 with value: -0.9671398528104536.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:48,782]\u001b[0m Trial 48 finished with value: -1.1492782696750286 and parameters: {'max_depth': 35, 'num_leaves': 8, 'learning_rate': 0.005484532535111136, 'n_estimators': 101, 'reg_alpha': 47.569349025262994, 'reg_lambda': 0.03806736881593684}. Best is trial 46 with value: -0.9671398528104536.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:49,880]\u001b[0m Trial 49 finished with value: -0.9949918315299127 and parameters: {'max_depth': 34, 'num_leaves': 8, 'learning_rate': 0.26017806679891825, 'n_estimators': 103, 'reg_alpha': 18.24370214974766, 'reg_lambda': 1.8006456787266247}. Best is trial 46 with value: -0.9671398528104536.\u001b[0m\n",
      "/var/folders/6v/12r4qnjx54zgmfy66mv7j0rr0000gn/T/ipykernel_49269/2838603844.py:51: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  optuna_search = optuna.integration.OptunaSearchCV(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.10/site-packages/sklearn/model_selection/_split.py:885: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-25 20:43:51,863]\u001b[0m A new study created in memory with name: no-name-c0583682-041c-469e-8a19-3777a30d64aa\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:54,030]\u001b[0m Trial 0 finished with value: -2.4779539609639447 and parameters: {'max_depth': 4, 'num_leaves': 5, 'learning_rate': 0.00027110791463756185, 'n_estimators': 85, 'reg_alpha': 0.041906410059280454, 'reg_lambda': 0.001058479386459438}. Best is trial 0 with value: -2.4779539609639447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:56,739]\u001b[0m Trial 4 finished with value: -2.482609105510271 and parameters: {'max_depth': 32, 'num_leaves': 27, 'learning_rate': 3.9493324902880814e-05, 'n_estimators': 283, 'reg_alpha': 5852838.729396214, 'reg_lambda': 7.666960542422693e-07}. Best is trial 0 with value: -2.4779539609639447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:43:57,954]\u001b[0m Trial 5 finished with value: -2.4826073239155555 and parameters: {'max_depth': 19, 'num_leaves': 42, 'learning_rate': 1.060696243816491e-06, 'n_estimators': 6, 'reg_alpha': 3.6273734717397543e-06, 'reg_lambda': 0.00020683624277665965}. Best is trial 0 with value: -2.4779539609639447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:05,597]\u001b[0m Trial 2 finished with value: -2.4802491136201574 and parameters: {'max_depth': 46, 'num_leaves': 10, 'learning_rate': 3.1323978318948576e-05, 'n_estimators': 391, 'reg_alpha': 0.20221426245206284, 'reg_lambda': 0.09826358979947736}. Best is trial 0 with value: -2.4779539609639447.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:07,763]\u001b[0m Trial 1 finished with value: -2.477145014124483 and parameters: {'max_depth': 37, 'num_leaves': 18, 'learning_rate': 9.92374624697574e-05, 'n_estimators': 353, 'reg_alpha': 9310.489154334662, 'reg_lambda': 3.642322449975877e-07}. Best is trial 1 with value: -2.477145014124483.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:12,926]\u001b[0m Trial 8 finished with value: -2.4819059401287547 and parameters: {'max_depth': 5, 'num_leaves': 26, 'learning_rate': 2.708527626583356e-05, 'n_estimators': 84, 'reg_alpha': 9.063874480202196, 'reg_lambda': 3.4269968574291636}. Best is trial 1 with value: -2.477145014124483.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:13,579]\u001b[0m Trial 3 finished with value: -2.4807829502212746 and parameters: {'max_depth': 17, 'num_leaves': 38, 'learning_rate': 2.4116958149734576e-05, 'n_estimators': 422, 'reg_alpha': 5792.821713552501, 'reg_lambda': 2.290210254660744e-07}. Best is trial 1 with value: -2.477145014124483.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:26,627]\u001b[0m Trial 6 finished with value: -2.4824412344590643 and parameters: {'max_depth': 15, 'num_leaves': 50, 'learning_rate': 6.868910001529942e-06, 'n_estimators': 230, 'reg_alpha': 0.0002423285137684165, 'reg_lambda': 34264.1745626388}. Best is trial 1 with value: -2.477145014124483.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:30,008]\u001b[0m Trial 11 finished with value: -2.4764552827379607 and parameters: {'max_depth': 8, 'num_leaves': 7, 'learning_rate': 0.0002674852481646383, 'n_estimators': 121, 'reg_alpha': 0.006083616210674627, 'reg_lambda': 0.0005472833083097676}. Best is trial 11 with value: -2.4764552827379607.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:38,015]\u001b[0m Trial 10 finished with value: -2.5150034027634653 and parameters: {'max_depth': 44, 'num_leaves': 20, 'learning_rate': 0.002841130629832025, 'n_estimators': 428, 'reg_alpha': 2.3291954384478143e-06, 'reg_lambda': 0.0001828376920018994}. Best is trial 11 with value: -2.4764552827379607.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:39,574]\u001b[0m Trial 7 finished with value: -2.4553536923657777 and parameters: {'max_depth': 18, 'num_leaves': 38, 'learning_rate': 0.0005960483386348856, 'n_estimators': 339, 'reg_alpha': 434.08960263066035, 'reg_lambda': 5213.481312631707}. Best is trial 7 with value: -2.4553536923657777.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:44:41,118]\u001b[0m Trial 12 finished with value: -2.4821282122958515 and parameters: {'max_depth': 39, 'num_leaves': 20, 'learning_rate': 0.00010919450739471236, 'n_estimators': 189, 'reg_alpha': 4.23444701073929e-06, 'reg_lambda': 317569.67935870634}. Best is trial 7 with value: -2.4553536923657777.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:44,818]\u001b[0m Trial 13 finished with value: -2.8756547896241553 and parameters: {'max_depth': 0, 'num_leaves': 13, 'learning_rate': 0.1289507146279756, 'n_estimators': 166, 'reg_alpha': 1.264736604493388e-07, 'reg_lambda': 134.7073936262077}. Best is trial 7 with value: -2.4553536923657777.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:49,854]\u001b[0m Trial 9 finished with value: -2.4423871705634723 and parameters: {'max_depth': 35, 'num_leaves': 32, 'learning_rate': 0.0010130643531487764, 'n_estimators': 427, 'reg_alpha': 977.3523437723962, 'reg_lambda': 0.0003210304450351808}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:44:56,880]\u001b[0m Trial 14 finished with value: -2.4732117226975 and parameters: {'max_depth': 9, 'num_leaves': 35, 'learning_rate': 0.02904936567474059, 'n_estimators': 232, 'reg_alpha': 0.005979955019509858, 'reg_lambda': 5812014.551104381}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:45:06,482]\u001b[0m Trial 16 finished with value: -2.4806225906901007 and parameters: {'max_depth': 10, 'num_leaves': 36, 'learning_rate': 0.002779169471825035, 'n_estimators': 307, 'reg_alpha': 0.004720997937059935, 'reg_lambda': 3406454.3023875393}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:45:10,179]\u001b[0m Trial 17 finished with value: -2.482084160321633 and parameters: {'max_depth': 27, 'num_leaves': 35, 'learning_rate': 0.001965781107209338, 'n_estimators': 322, 'reg_alpha': 46.76994328921276, 'reg_lambda': 9715660.1467828}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:45:17,116]\u001b[0m Trial 20 finished with value: -2.8363642029128675 and parameters: {'max_depth': 25, 'num_leaves': 45, 'learning_rate': 0.9647061548926403, 'n_estimators': 491, 'reg_alpha': 291.17947702797414, 'reg_lambda': 948.2893229372055}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:45:28,142]\u001b[0m Trial 15 finished with value: -2.938872310684965 and parameters: {'max_depth': 10, 'num_leaves': 38, 'learning_rate': 0.07632777469018931, 'n_estimators': 500, 'reg_alpha': 0.002408582690655165, 'reg_lambda': 229.4499407902407}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:45:40,317]\u001b[0m Trial 18 finished with value: -2.5049571998674085 and parameters: {'max_depth': 26, 'num_leaves': 33, 'learning_rate': 0.0024669772768148752, 'n_estimators': 495, 'reg_alpha': 22.896748127072954, 'reg_lambda': 1218.082321752137}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:45:58,497]\u001b[0m Trial 21 finished with value: -2.4825830858454316 and parameters: {'max_depth': 28, 'num_leaves': 32, 'learning_rate': 2.0609601841901995e-07, 'n_estimators': 480, 'reg_alpha': 3.694619027237677, 'reg_lambda': 0.7828183076742286}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:45:58,903]\u001b[0m Trial 22 finished with value: -2.4453648379773005 and parameters: {'max_depth': 30, 'num_leaves': 31, 'learning_rate': 0.001375891737353432, 'n_estimators': 367, 'reg_alpha': 1.7976280427435176, 'reg_lambda': 0.37995657356465956}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:46:04,340]\u001b[0m Trial 19 finished with value: -2.4781361086730866 and parameters: {'max_depth': 27, 'num_leaves': 47, 'learning_rate': 0.0022035982237590427, 'n_estimators': 484, 'reg_alpha': 11.902768706213712, 'reg_lambda': 1986.4812056707347}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:46:11,694]\u001b[0m Trial 23 finished with value: -2.482593710480282 and parameters: {'max_depth': 31, 'num_leaves': 30, 'learning_rate': 1.5273523990222913e-07, 'n_estimators': 371, 'reg_alpha': 2.1681155108877257, 'reg_lambda': 0.15697188215632712}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:46:26,062]\u001b[0m Trial 24 finished with value: -2.455303260896512 and parameters: {'max_depth': 20, 'num_leaves': 30, 'learning_rate': 0.0010005147520214229, 'n_estimators': 355, 'reg_alpha': 0.18875256150490383, 'reg_lambda': 43789.40627685923}. Best is trial 9 with value: -2.4423871705634723.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:46:28,598]\u001b[0m Trial 25 finished with value: -2.441043129758407 and parameters: {'max_depth': 33, 'num_leaves': 29, 'learning_rate': 0.0008652474950713874, 'n_estimators': 367, 'reg_alpha': 1.3577049679048605, 'reg_lambda': 0.03354063362352153}. Best is trial 25 with value: -2.441043129758407.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:46:35,641]\u001b[0m Trial 26 finished with value: -2.440995292882166 and parameters: {'max_depth': 34, 'num_leaves': 30, 'learning_rate': 0.0006996445401640998, 'n_estimators': 370, 'reg_alpha': 0.3676075009294134, 'reg_lambda': 12.325094687128981}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:46:56,303]\u001b[0m Trial 27 finished with value: -2.4505451872269175 and parameters: {'max_depth': 21, 'num_leaves': 41, 'learning_rate': 0.0005436893321691342, 'n_estimators': 416, 'reg_alpha': 880.2937525438861, 'reg_lambda': 14.865432696036038}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:46:56,499]\u001b[0m Trial 28 finished with value: -2.800600747866106 and parameters: {'max_depth': 37, 'num_leaves': 25, 'learning_rate': 0.01210431866093731, 'n_estimators': 436, 'reg_alpha': 0.2978548022481472, 'reg_lambda': 14.731496078889075}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:46:57,385]\u001b[0m Trial 29 finished with value: -2.7530868613763606 and parameters: {'max_depth': 36, 'num_leaves': 24, 'learning_rate': 0.009315943611583454, 'n_estimators': 421, 'reg_alpha': 0.7322608433666382, 'reg_lambda': 0.036194293207132126}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:04,382]\u001b[0m Trial 30 finished with value: -2.74358023238716 and parameters: {'max_depth': 36, 'num_leaves': 24, 'learning_rate': 0.008878159472872809, 'n_estimators': 422, 'reg_alpha': 0.3738012767475757, 'reg_lambda': 0.018642759857543524}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:14,861]\u001b[0m Trial 32 finished with value: -2.636984112587051 and parameters: {'max_depth': 41, 'num_leaves': 23, 'learning_rate': 0.0086049330607554, 'n_estimators': 276, 'reg_alpha': 0.09011585905342932, 'reg_lambda': 0.010558351004732005}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:15,758]\u001b[0m Trial 33 finished with value: -2.469127818070058 and parameters: {'max_depth': 42, 'num_leaves': 22, 'learning_rate': 0.0002078831412602119, 'n_estimators': 281, 'reg_alpha': 0.11191787530548225, 'reg_lambda': 0.022728047237272682}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:26,181]\u001b[0m Trial 31 finished with value: -2.764544926275392 and parameters: {'max_depth': 36, 'num_leaves': 24, 'learning_rate': 0.009745485011589127, 'n_estimators': 433, 'reg_alpha': 0.454336398918707, 'reg_lambda': 0.019184790133138726}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:26,203]\u001b[0m Trial 34 finished with value: -2.462099716982976 and parameters: {'max_depth': 41, 'num_leaves': 29, 'learning_rate': 0.0003277516086321771, 'n_estimators': 275, 'reg_alpha': 0.029625307276492773, 'reg_lambda': 0.015269702638770795}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:43,768]\u001b[0m Trial 38 finished with value: -2.4483076344705177 and parameters: {'max_depth': 32, 'num_leaves': 15, 'learning_rate': 0.001002327125570281, 'n_estimators': 383, 'reg_alpha': 2.2000344796138647, 'reg_lambda': 0.0020936859220592897}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:45,504]\u001b[0m Trial 35 finished with value: -2.461395118727083 and parameters: {'max_depth': 32, 'num_leaves': 29, 'learning_rate': 0.000243047447505604, 'n_estimators': 387, 'reg_alpha': 0.031759421940768195, 'reg_lambda': 0.004056139363735933}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-25 20:47:46,981]\u001b[0m Trial 36 finished with value: -2.4419645601120346 and parameters: {'max_depth': 33, 'num_leaves': 29, 'learning_rate': 0.0007514681418119728, 'n_estimators': 382, 'reg_alpha': 2.680803068005249, 'reg_lambda': 0.0021082704297634525}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:51,291]\u001b[0m Trial 41 finished with value: -2.482840734393983 and parameters: {'max_depth': 47, 'num_leaves': 28, 'learning_rate': 8.677704764663178e-05, 'n_estimators': 456, 'reg_alpha': 42458.11280900164, 'reg_lambda': 2.093011893360949e-05}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:52,767]\u001b[0m Trial 40 finished with value: -2.481087361599238 and parameters: {'max_depth': 47, 'num_leaves': 32, 'learning_rate': 5.7895850455702966e-05, 'n_estimators': 314, 'reg_alpha': 20408.062455187403, 'reg_lambda': 0.22150488025318682}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:54,007]\u001b[0m Trial 39 finished with value: -2.4790123346579174 and parameters: {'max_depth': 31, 'num_leaves': 32, 'learning_rate': 9.514535518369375e-05, 'n_estimators': 388, 'reg_alpha': 17525.499456136662, 'reg_lambda': 0.38103820493450297}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:47:57,221]\u001b[0m Trial 37 finished with value: -2.4415656637258163 and parameters: {'max_depth': 32, 'num_leaves': 29, 'learning_rate': 0.0006369060080590994, 'n_estimators': 378, 'reg_alpha': 73.98775154950239, 'reg_lambda': 0.6409686433940346}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:48:20,420]\u001b[0m Trial 44 finished with value: -2.441251575093202 and parameters: {'max_depth': 34, 'num_leaves': 27, 'learning_rate': 0.0007845971644826428, 'n_estimators': 355, 'reg_alpha': 59.89173325318014, 'reg_lambda': 2.2950307604586095}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:48:20,483]\u001b[0m Trial 42 finished with value: -2.4509695403676357 and parameters: {'max_depth': 34, 'num_leaves': 33, 'learning_rate': 0.000582053517373239, 'n_estimators': 322, 'reg_alpha': 105.34602751188194, 'reg_lambda': 8.475814414399006e-05}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:48:22,260]\u001b[0m Trial 45 finished with value: -2.449249880402404 and parameters: {'max_depth': 33, 'num_leaves': 27, 'learning_rate': 0.0005167380590066677, 'n_estimators': 334, 'reg_alpha': 123.68094077945163, 'reg_lambda': 4.320627228803766e-05}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:48:30,523]\u001b[0m Trial 43 finished with value: -2.462023847420509 and parameters: {'max_depth': 34, 'num_leaves': 40, 'learning_rate': 0.0004933872703014202, 'n_estimators': 344, 'reg_alpha': 235.29311279554346, 'reg_lambda': 6.376070356971007e-05}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:48:44,376]\u001b[0m Trial 48 finished with value: -2.4811312594529533 and parameters: {'max_depth': 23, 'num_leaves': 21, 'learning_rate': 1.4699293438116192e-05, 'n_estimators': 345, 'reg_alpha': 9.357698067984915, 'reg_lambda': 2.326458520607977}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:48:45,863]\u001b[0m Trial 46 finished with value: -2.4500444431266306 and parameters: {'max_depth': 33, 'num_leaves': 26, 'learning_rate': 0.00047066530195850794, 'n_estimators': 348, 'reg_alpha': 63.868412169358216, 'reg_lambda': 2.456905694937186}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:48:46,228]\u001b[0m Trial 47 finished with value: -2.4811629659800296 and parameters: {'max_depth': 23, 'num_leaves': 27, 'learning_rate': 1.5490243382986957e-05, 'n_estimators': 339, 'reg_alpha': 15.672271042574469, 'reg_lambda': 2.932385632443694}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-25 20:48:49,479]\u001b[0m Trial 49 finished with value: -2.4670921439897286 and parameters: {'max_depth': 39, 'num_leaves': 21, 'learning_rate': 0.0001795064283831823, 'n_estimators': 400, 'reg_alpha': 7.481219660184009, 'reg_lambda': 2.3817843274944823}. Best is trial 26 with value: -2.440995292882166.\u001b[0m\n",
      "100%|| 16/16 [3:39:18<00:00, 822.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# This fits sites 0-7\n",
    "N_TRIALS = 50\n",
    "models = defaultdict(dict)\n",
    "\n",
    "for site in tqdm(X_train[\"site_id\"].unique()):\n",
    "    for meter in X_train[\"meter\"].unique():\n",
    "        \n",
    "        optuna_search = run_optuna_search_cv(site, meter, X_train, y_train, features, N_TRIALS)\n",
    "        \n",
    "        model_identifier = \"_\".join([str(site), str(meter)])\n",
    "        models[model_identifier] = optuna_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380ae66",
   "metadata": {},
   "source": [
    "#### Dump the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b751f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models.keys():\n",
    "    if models[key]:\n",
    "        with open(f\"./models/v2/{key}.pkl\", \"wb\") as f:\n",
    "            pickle.dump(models[key].best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1183283",
   "metadata": {},
   "source": [
    "#### Load all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "554c9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = sorted(glob('models/v2/*.pkl'))\n",
    "estimators = []\n",
    "for model_file in model_files:\n",
    "    estimators.append((re.search(r\"/(\\d+_\\d+)\\.pkl$\", model_file).group(1) ,pickle.load(open(model_file,'rb'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af200afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_dict = dict(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69c2a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_using_individual_estimators(X_test, y_test, estimators_dict):\n",
    "    results_df = pd.DataFrame(columns=['y_true', 'y_pred'])\n",
    "    for site_meter in estimators_dict.keys():\n",
    "\n",
    "        site_id, meter = list(map(lambda x:int(x) ,site_meter.split(\"_\")))\n",
    "        # Filter input data for the specific site_id and meter\n",
    "        site_meter_filter = (X_test['site_id'] == site_id) & (X_test['meter'] == meter)\n",
    "\n",
    "        X_test_subset = X_test[site_meter_filter].drop(['meter', 'site_id', 'building_id'], axis=1)\n",
    "\n",
    "        # Get the true values for the subset of input data\n",
    "        y_true = y_test[site_meter_filter]\n",
    "\n",
    "        if(X_test_subset.shape[0] == 0):\n",
    "            continue\n",
    "\n",
    "        # Make predictions for the subset of input data\n",
    "        y_pred = estimators_dict[site_meter].predict(X_test_subset)\n",
    "\n",
    "        # Add true values and predictions to results_df\n",
    "        results_df = pd.concat([results_df, pd.DataFrame({'y_true': y_true, 'y_pred': y_pred})], ignore_index=True)\n",
    "\n",
    "        # Compute RMSE for the predictions and print the results\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        print(f\"Site ID: {site_id}, Meter: {meter}, RMSE: {rmse}\")\n",
    "    overall_rmse = mean_squared_error(results_df[\"y_true\"], results_df[\"y_pred\"], squared=False)\n",
    "    print(f\"Overall RMSE: {overall_rmse}\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c637ac82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site ID: 0, Meter: 0, RMSE: 0.8958462019889623\n",
      "Site ID: 0, Meter: 1, RMSE: 2.1661646078983527\n",
      "Site ID: 10, Meter: 0, RMSE: 0.6435512253155503\n",
      "Site ID: 10, Meter: 1, RMSE: 1.6477769444738206\n",
      "Site ID: 10, Meter: 3, RMSE: 3.711565236249415\n",
      "Site ID: 11, Meter: 0, RMSE: 0.8100198832108814\n",
      "Site ID: 11, Meter: 1, RMSE: 1.0053629865051774\n",
      "Site ID: 12, Meter: 0, RMSE: 0.8324606322487913\n",
      "Site ID: 13, Meter: 0, RMSE: 1.0598314861107465\n",
      "Site ID: 13, Meter: 1, RMSE: 1.8940835594066505\n",
      "Site ID: 13, Meter: 2, RMSE: 3.0453410591345853\n",
      "Site ID: 14, Meter: 0, RMSE: 1.2125531676504986\n",
      "Site ID: 14, Meter: 1, RMSE: 2.141097753867811\n",
      "Site ID: 14, Meter: 2, RMSE: 2.5810472416465533\n",
      "Site ID: 14, Meter: 3, RMSE: 2.4446364198503847\n",
      "Site ID: 15, Meter: 0, RMSE: 1.0624144124662596\n",
      "Site ID: 15, Meter: 1, RMSE: 1.6748270926643025\n",
      "Site ID: 15, Meter: 2, RMSE: 1.87421251439107\n",
      "Site ID: 1, Meter: 0, RMSE: 1.4796705873505094\n",
      "Site ID: 1, Meter: 3, RMSE: 2.431672659759725\n",
      "Site ID: 2, Meter: 0, RMSE: 0.969575755492034\n",
      "Site ID: 2, Meter: 1, RMSE: 1.987885058706924\n",
      "Site ID: 2, Meter: 3, RMSE: 1.9107724716525578\n",
      "Site ID: 3, Meter: 0, RMSE: 1.0733271969617337\n",
      "Site ID: 4, Meter: 0, RMSE: 0.9280358002721655\n",
      "Site ID: 5, Meter: 0, RMSE: 1.13867756493974\n",
      "Site ID: 6, Meter: 0, RMSE: 1.1898364685480898\n",
      "Site ID: 6, Meter: 1, RMSE: 2.9794873934756634\n",
      "Site ID: 6, Meter: 2, RMSE: 3.409197351857246\n",
      "Site ID: 7, Meter: 0, RMSE: 3.9759476454894647\n",
      "Site ID: 7, Meter: 1, RMSE: 3.139345767869723\n",
      "Site ID: 7, Meter: 2, RMSE: 1.5882461885434054\n",
      "Site ID: 8, Meter: 0, RMSE: 1.1480201003886985\n",
      "Site ID: 9, Meter: 0, RMSE: 0.7913224117629892\n",
      "Site ID: 9, Meter: 1, RMSE: 1.304406440803661\n",
      "Site ID: 9, Meter: 2, RMSE: 1.6818132733062137\n",
      "Overall RMSE: 1.6316082223724242\n"
     ]
    }
   ],
   "source": [
    "results_df = predict_using_individual_estimators(X_test, y_test, estimators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61bf972e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site ID: 0, Meter: 0, RMSE: 0.4370975006650308\n",
      "Site ID: 0, Meter: 1, RMSE: 2.1872053854320357\n",
      "Site ID: 10, Meter: 0, RMSE: 0.6082265475033243\n",
      "Site ID: 10, Meter: 1, RMSE: 1.8204013366918306\n",
      "Site ID: 10, Meter: 3, RMSE: 2.035142421851524\n",
      "Site ID: 11, Meter: 0, RMSE: 0.048857680003833164\n",
      "Site ID: 11, Meter: 1, RMSE: 0.940267095748208\n",
      "Site ID: 11, Meter: 3, RMSE: 1.0118834799747936\n",
      "Site ID: 12, Meter: 0, RMSE: 0.6368874353024025\n",
      "Site ID: 13, Meter: 0, RMSE: 0.6528128522219188\n",
      "Site ID: 13, Meter: 1, RMSE: 1.5982944312383787\n",
      "Site ID: 13, Meter: 2, RMSE: 1.8684257375013353\n",
      "Site ID: 14, Meter: 0, RMSE: 1.088136540136423\n",
      "Site ID: 14, Meter: 1, RMSE: 1.782384007456194\n",
      "Site ID: 14, Meter: 2, RMSE: 2.4408351029646567\n",
      "Site ID: 14, Meter: 3, RMSE: 2.227791638106526\n",
      "Site ID: 15, Meter: 0, RMSE: 0.7422330514745354\n",
      "Site ID: 15, Meter: 1, RMSE: 1.1990100136117974\n",
      "Site ID: 15, Meter: 2, RMSE: 1.3754276357079414\n",
      "Site ID: 15, Meter: 3, RMSE: 1.1578740694339213\n",
      "Site ID: 1, Meter: 0, RMSE: 1.0528043116838346\n",
      "Site ID: 1, Meter: 3, RMSE: 1.8059776294273766\n",
      "Site ID: 2, Meter: 0, RMSE: 0.6748124867068876\n",
      "Site ID: 2, Meter: 1, RMSE: 1.3143027513414878\n",
      "Site ID: 2, Meter: 3, RMSE: 1.5533043174999976\n",
      "Site ID: 3, Meter: 0, RMSE: 0.6527305567314753\n",
      "Site ID: 4, Meter: 0, RMSE: 0.22664453424640238\n",
      "Site ID: 5, Meter: 0, RMSE: 0.5882937201651538\n",
      "Site ID: 6, Meter: 0, RMSE: 0.49518475731003225\n",
      "Site ID: 6, Meter: 1, RMSE: 2.421018336533386\n",
      "Site ID: 6, Meter: 2, RMSE: 2.9542363924343378\n",
      "Site ID: 7, Meter: 0, RMSE: 1.683745927214995\n",
      "Site ID: 7, Meter: 1, RMSE: 1.2491341381205672\n",
      "Site ID: 7, Meter: 2, RMSE: 1.473144418250731\n",
      "Site ID: 7, Meter: 3, RMSE: 2.039711794617425\n",
      "Site ID: 8, Meter: 0, RMSE: 0.8913020995316628\n",
      "Site ID: 9, Meter: 0, RMSE: 0.8514952616432409\n",
      "Site ID: 9, Meter: 1, RMSE: 0.9638461095773581\n",
      "Site ID: 9, Meter: 2, RMSE: 1.5159676930924109\n",
      "Overall RMSE: 1.2234145129311362\n"
     ]
    }
   ],
   "source": [
    "results_df = predict_using_individual_estimators(X_train, y_train, estimators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3783844a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_params_df = pd.DataFrame()\n",
    "for key in models.keys():\n",
    "    if models[key]:\n",
    "        try:\n",
    "            params = models[key].best_params_\n",
    "            params[\"best_score\"] = models[key].best_score_\n",
    "        except:\n",
    "            params = {}\n",
    "        params[\"site_id\"] = key.split(\"_\")[0]\n",
    "        params[\"meter\"] = key.split(\"_\")[1]\n",
    "        best_params_df = pd.concat([best_params_df, pd.DataFrame(params, index=[key])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "199c68cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>num_leaves</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>reg_alpha</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>best_score</th>\n",
       "      <th>site_id</th>\n",
       "      <th>meter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1_0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>282.0</td>\n",
       "      <td>1.008666e-04</td>\n",
       "      <td>9.375840e-02</td>\n",
       "      <td>-1.131032</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>444.0</td>\n",
       "      <td>2.557156e-01</td>\n",
       "      <td>2.064281e-01</td>\n",
       "      <td>-2.123030</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.190963</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.437325e+00</td>\n",
       "      <td>4.692658e+05</td>\n",
       "      <td>-0.943938</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.013899</td>\n",
       "      <td>161.0</td>\n",
       "      <td>5.014057e-04</td>\n",
       "      <td>1.570336e-03</td>\n",
       "      <td>-1.613363</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.016610</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.100183e-02</td>\n",
       "      <td>2.201556e-06</td>\n",
       "      <td>-1.653434</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.377659</td>\n",
       "      <td>91.0</td>\n",
       "      <td>8.965814e-07</td>\n",
       "      <td>8.689344e+05</td>\n",
       "      <td>-0.913410</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.188002</td>\n",
       "      <td>392.0</td>\n",
       "      <td>7.462068e+02</td>\n",
       "      <td>1.416566e-01</td>\n",
       "      <td>-0.869348</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.068284</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3.058060e+03</td>\n",
       "      <td>5.408897e-01</td>\n",
       "      <td>-0.932333</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.084916</td>\n",
       "      <td>499.0</td>\n",
       "      <td>1.057952e-07</td>\n",
       "      <td>9.799330e+05</td>\n",
       "      <td>-0.900117</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>400.0</td>\n",
       "      <td>6.107786e+01</td>\n",
       "      <td>1.910842e-06</td>\n",
       "      <td>-2.553161</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>302.0</td>\n",
       "      <td>1.728881e-02</td>\n",
       "      <td>1.113131e+04</td>\n",
       "      <td>-3.015326</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.064938</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.896760e+02</td>\n",
       "      <td>1.204988e+05</td>\n",
       "      <td>-1.889023</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.093251</td>\n",
       "      <td>371.0</td>\n",
       "      <td>2.964183e+03</td>\n",
       "      <td>1.920707e+00</td>\n",
       "      <td>-2.344397</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.053407</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2.283548e-06</td>\n",
       "      <td>1.771068e+04</td>\n",
       "      <td>-2.298223</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>329.0</td>\n",
       "      <td>3.231659e+01</td>\n",
       "      <td>3.261210e+01</td>\n",
       "      <td>-2.361556</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8_0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.435728</td>\n",
       "      <td>370.0</td>\n",
       "      <td>7.110335e-03</td>\n",
       "      <td>9.939175e+05</td>\n",
       "      <td>-1.245966</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_0</th>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.138318</td>\n",
       "      <td>256.0</td>\n",
       "      <td>1.103466e+01</td>\n",
       "      <td>1.966634e+05</td>\n",
       "      <td>-1.166651</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.017991</td>\n",
       "      <td>219.0</td>\n",
       "      <td>3.769769e-07</td>\n",
       "      <td>1.499928e-01</td>\n",
       "      <td>-1.399159</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9_2</th>\n",
       "      <td>28.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.071847</td>\n",
       "      <td>387.0</td>\n",
       "      <td>1.202087e-05</td>\n",
       "      <td>9.945964e+05</td>\n",
       "      <td>-1.678153</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>374.0</td>\n",
       "      <td>6.174443e+00</td>\n",
       "      <td>3.702082e+06</td>\n",
       "      <td>-0.841505</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.100663</td>\n",
       "      <td>440.0</td>\n",
       "      <td>1.660583e+03</td>\n",
       "      <td>1.115252e+01</td>\n",
       "      <td>-2.494434</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>357.0</td>\n",
       "      <td>6.871153e-06</td>\n",
       "      <td>8.102682e-02</td>\n",
       "      <td>-2.276024</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_3</th>\n",
       "      <td>45.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>272.0</td>\n",
       "      <td>1.000788e-06</td>\n",
       "      <td>1.177984e+04</td>\n",
       "      <td>-1.391705</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>316.0</td>\n",
       "      <td>1.505329e-04</td>\n",
       "      <td>9.846349e-02</td>\n",
       "      <td>-1.243719</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.548954</td>\n",
       "      <td>418.0</td>\n",
       "      <td>1.182520e+04</td>\n",
       "      <td>1.144009e+02</td>\n",
       "      <td>-0.882432</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_0</th>\n",
       "      <td>29.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.590832</td>\n",
       "      <td>359.0</td>\n",
       "      <td>1.539448e-02</td>\n",
       "      <td>2.650123e+06</td>\n",
       "      <td>-1.032666</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.706461</td>\n",
       "      <td>404.0</td>\n",
       "      <td>3.023164e+03</td>\n",
       "      <td>6.765587e+06</td>\n",
       "      <td>-1.906788</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_2</th>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>399.0</td>\n",
       "      <td>5.072170e-05</td>\n",
       "      <td>4.449017e-01</td>\n",
       "      <td>-2.459754</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.974901</td>\n",
       "      <td>63.0</td>\n",
       "      <td>5.518147e+02</td>\n",
       "      <td>1.673307e+06</td>\n",
       "      <td>-1.231768</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.252106</td>\n",
       "      <td>143.0</td>\n",
       "      <td>3.096313e-01</td>\n",
       "      <td>1.870686e+06</td>\n",
       "      <td>-2.443076</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_1</th>\n",
       "      <td>37.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.074422</td>\n",
       "      <td>237.0</td>\n",
       "      <td>6.578600e+01</td>\n",
       "      <td>3.908394e+03</td>\n",
       "      <td>-2.320625</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.150165</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.372563e+04</td>\n",
       "      <td>3.247181e-03</td>\n",
       "      <td>-2.629706</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.009841</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1.466202e-04</td>\n",
       "      <td>1.310118e+05</td>\n",
       "      <td>-1.031472</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.071760</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2.327377e+01</td>\n",
       "      <td>1.608606e+05</td>\n",
       "      <td>-2.827866</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.173323</td>\n",
       "      <td>368.0</td>\n",
       "      <td>3.354344e+03</td>\n",
       "      <td>2.728671e+06</td>\n",
       "      <td>-1.489518</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_2</th>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.373581e-05</td>\n",
       "      <td>3.134361e-04</td>\n",
       "      <td>-1.666001</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_0</th>\n",
       "      <td>34.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.291767</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.182399e+03</td>\n",
       "      <td>2.507086e+00</td>\n",
       "      <td>-0.967140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0_1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>370.0</td>\n",
       "      <td>3.676075e-01</td>\n",
       "      <td>1.232509e+01</td>\n",
       "      <td>-2.440995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      max_depth  num_leaves  learning_rate  n_estimators     reg_alpha  \\\n",
       "1_0        42.0         5.0       0.001265         282.0  1.008666e-04   \n",
       "1_3        12.0        21.0       0.000779         444.0  2.557156e-01   \n",
       "2_0         2.0        47.0       0.190963         330.0  1.437325e+00   \n",
       "2_3         1.0        34.0       0.013899         161.0  5.014057e-04   \n",
       "2_1        25.0         7.0       0.016610         256.0  1.100183e-02   \n",
       "3_0        -1.0        15.0       0.377659          91.0  8.965814e-07   \n",
       "4_0        26.0        28.0       0.188002         392.0  7.462068e+02   \n",
       "5_0        31.0        16.0       0.068284         218.0  3.058060e+03   \n",
       "6_0        12.0        34.0       0.084916         499.0  1.057952e-07   \n",
       "6_1         2.0         8.0       0.001208         400.0  6.107786e+01   \n",
       "6_2         2.0        22.0       0.000710         302.0  1.728881e-02   \n",
       "7_0        25.0        20.0       0.064938         204.0  1.896760e+02   \n",
       "7_3        16.0        31.0       0.093251         371.0  2.964183e+03   \n",
       "7_1        16.0        34.0       0.053407         139.0  2.283548e-06   \n",
       "7_2        45.0         5.0       0.011778         329.0  3.231659e+01   \n",
       "8_0         1.0        29.0       0.435728         370.0  7.110335e-03   \n",
       "9_0        30.0        21.0       0.138318         256.0  1.103466e+01   \n",
       "9_1        36.0        20.0       0.017991         219.0  3.769769e-07   \n",
       "9_2        28.0        22.0       0.071847         387.0  1.202087e-05   \n",
       "10_0       37.0        46.0       0.609195         374.0  6.174443e+00   \n",
       "10_3        2.0        47.0       0.100663         440.0  1.660583e+03   \n",
       "10_1       34.0        20.0       0.000992         357.0  6.871153e-06   \n",
       "11_0        NaN         NaN            NaN           NaN           NaN   \n",
       "11_3       45.0        24.0       0.013865         272.0  1.000788e-06   \n",
       "11_1        4.0        20.0       0.007646         316.0  1.505329e-04   \n",
       "12_0       21.0        25.0       0.548954         418.0  1.182520e+04   \n",
       "13_0       29.0        35.0       0.590832         359.0  1.539448e-02   \n",
       "13_1       10.0        13.0       0.706461         404.0  3.023164e+03   \n",
       "13_2       27.0        13.0       0.003813         399.0  5.072170e-05   \n",
       "14_0       18.0         9.0       0.974901          63.0  5.518147e+02   \n",
       "14_3        4.0        32.0       0.252106         143.0  3.096313e-01   \n",
       "14_1       37.0         5.0       0.074422         237.0  6.578600e+01   \n",
       "14_2        6.0        34.0       0.150165           5.0  4.372563e+04   \n",
       "15_0       17.0        16.0       0.009841         391.0  1.466202e-04   \n",
       "15_3       10.0        42.0       0.071760         175.0  2.327377e+01   \n",
       "15_1       42.0        27.0       0.173323         368.0  3.354344e+03   \n",
       "15_2       34.0         5.0       0.024104          99.0  2.373581e-05   \n",
       "0_0        34.0         8.0       0.291767          94.0  2.182399e+03   \n",
       "0_1        34.0        30.0       0.000700         370.0  3.676075e-01   \n",
       "\n",
       "        reg_lambda  best_score site_id meter  \n",
       "1_0   9.375840e-02   -1.131032       1     0  \n",
       "1_3   2.064281e-01   -2.123030       1     3  \n",
       "2_0   4.692658e+05   -0.943938       2     0  \n",
       "2_3   1.570336e-03   -1.613363       2     3  \n",
       "2_1   2.201556e-06   -1.653434       2     1  \n",
       "3_0   8.689344e+05   -0.913410       3     0  \n",
       "4_0   1.416566e-01   -0.869348       4     0  \n",
       "5_0   5.408897e-01   -0.932333       5     0  \n",
       "6_0   9.799330e+05   -0.900117       6     0  \n",
       "6_1   1.910842e-06   -2.553161       6     1  \n",
       "6_2   1.113131e+04   -3.015326       6     2  \n",
       "7_0   1.204988e+05   -1.889023       7     0  \n",
       "7_3   1.920707e+00   -2.344397       7     3  \n",
       "7_1   1.771068e+04   -2.298223       7     1  \n",
       "7_2   3.261210e+01   -2.361556       7     2  \n",
       "8_0   9.939175e+05   -1.245966       8     0  \n",
       "9_0   1.966634e+05   -1.166651       9     0  \n",
       "9_1   1.499928e-01   -1.399159       9     1  \n",
       "9_2   9.945964e+05   -1.678153       9     2  \n",
       "10_0  3.702082e+06   -0.841505      10     0  \n",
       "10_3  1.115252e+01   -2.494434      10     3  \n",
       "10_1  8.102682e-02   -2.276024      10     1  \n",
       "11_0           NaN         NaN      11     0  \n",
       "11_3  1.177984e+04   -1.391705      11     3  \n",
       "11_1  9.846349e-02   -1.243719      11     1  \n",
       "12_0  1.144009e+02   -0.882432      12     0  \n",
       "13_0  2.650123e+06   -1.032666      13     0  \n",
       "13_1  6.765587e+06   -1.906788      13     1  \n",
       "13_2  4.449017e-01   -2.459754      13     2  \n",
       "14_0  1.673307e+06   -1.231768      14     0  \n",
       "14_3  1.870686e+06   -2.443076      14     3  \n",
       "14_1  3.908394e+03   -2.320625      14     1  \n",
       "14_2  3.247181e-03   -2.629706      14     2  \n",
       "15_0  1.310118e+05   -1.031472      15     0  \n",
       "15_3  1.608606e+05   -2.827866      15     3  \n",
       "15_1  2.728671e+06   -1.489518      15     1  \n",
       "15_2  3.134361e-04   -1.666001      15     2  \n",
       "0_0   2.507086e+00   -0.967140       0     0  \n",
       "0_1   1.232509e+01   -2.440995       0     1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b02042c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_complete</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_n_estimators</th>\n",
       "      <th>params_num_leaves</th>\n",
       "      <th>params_reg_alpha</th>\n",
       "      <th>...</th>\n",
       "      <th>user_attrs_mean_score_time</th>\n",
       "      <th>user_attrs_mean_test_score</th>\n",
       "      <th>user_attrs_split0_test_score</th>\n",
       "      <th>user_attrs_split1_test_score</th>\n",
       "      <th>user_attrs_split2_test_score</th>\n",
       "      <th>user_attrs_split3_test_score</th>\n",
       "      <th>user_attrs_std_fit_time</th>\n",
       "      <th>user_attrs_std_score_time</th>\n",
       "      <th>user_attrs_std_test_score</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:15:52.843865</td>\n",
       "      <td>2023-04-25 19:15:57.533979</td>\n",
       "      <td>0 days 00:00:04.690114</td>\n",
       "      <td>2.853813e-06</td>\n",
       "      <td>43</td>\n",
       "      <td>385</td>\n",
       "      <td>18</td>\n",
       "      <td>9.046719e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.681406</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:15:52.850513</td>\n",
       "      <td>2023-04-25 19:16:04.086423</td>\n",
       "      <td>0 days 00:00:11.235910</td>\n",
       "      <td>6.392680e-03</td>\n",
       "      <td>39</td>\n",
       "      <td>298</td>\n",
       "      <td>24</td>\n",
       "      <td>1.626622e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.613155</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:15:52.852508</td>\n",
       "      <td>2023-04-25 19:15:54.727451</td>\n",
       "      <td>0 days 00:00:01.874943</td>\n",
       "      <td>7.453219e-03</td>\n",
       "      <td>34</td>\n",
       "      <td>415</td>\n",
       "      <td>46</td>\n",
       "      <td>2.997876e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.278675</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:15:52.854734</td>\n",
       "      <td>2023-04-25 19:16:20.864823</td>\n",
       "      <td>0 days 00:00:28.010089</td>\n",
       "      <td>3.160354e-03</td>\n",
       "      <td>14</td>\n",
       "      <td>443</td>\n",
       "      <td>35</td>\n",
       "      <td>3.560444e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.073371</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:15:54.730126</td>\n",
       "      <td>2023-04-25 19:15:55.835744</td>\n",
       "      <td>0 days 00:00:01.105618</td>\n",
       "      <td>1.172477e-02</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>25</td>\n",
       "      <td>2.412308e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.168333</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:15:55.838492</td>\n",
       "      <td>2023-04-25 19:15:59.059942</td>\n",
       "      <td>0 days 00:00:03.221450</td>\n",
       "      <td>8.678914e-04</td>\n",
       "      <td>42</td>\n",
       "      <td>268</td>\n",
       "      <td>50</td>\n",
       "      <td>1.215929e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.485249</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:15:57.536587</td>\n",
       "      <td>2023-04-25 19:16:13.816861</td>\n",
       "      <td>0 days 00:00:16.280274</td>\n",
       "      <td>7.936785e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>239</td>\n",
       "      <td>37</td>\n",
       "      <td>2.898895e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.354601</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:15:59.062499</td>\n",
       "      <td>2023-04-25 19:16:07.901796</td>\n",
       "      <td>0 days 00:00:08.839297</td>\n",
       "      <td>1.353845e-02</td>\n",
       "      <td>30</td>\n",
       "      <td>298</td>\n",
       "      <td>16</td>\n",
       "      <td>1.704116e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.276135</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:04.088592</td>\n",
       "      <td>2023-04-25 19:16:04.250656</td>\n",
       "      <td>0 days 00:00:00.162064</td>\n",
       "      <td>2.408493e-04</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>8.211615e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:04.252953</td>\n",
       "      <td>2023-04-25 19:16:17.565311</td>\n",
       "      <td>0 days 00:00:13.312358</td>\n",
       "      <td>1.024572e-04</td>\n",
       "      <td>39</td>\n",
       "      <td>459</td>\n",
       "      <td>19</td>\n",
       "      <td>1.019510e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.922425</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:07.904440</td>\n",
       "      <td>2023-04-25 19:16:09.108762</td>\n",
       "      <td>0 days 00:00:01.204322</td>\n",
       "      <td>9.958787e-04</td>\n",
       "      <td>35</td>\n",
       "      <td>362</td>\n",
       "      <td>24</td>\n",
       "      <td>3.576990e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.172511</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:09.111583</td>\n",
       "      <td>2023-04-25 19:16:24.688577</td>\n",
       "      <td>0 days 00:00:15.576994</td>\n",
       "      <td>9.103200e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>40</td>\n",
       "      <td>4.172585e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.251447</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:13.819014</td>\n",
       "      <td>2023-04-25 19:16:19.118960</td>\n",
       "      <td>0 days 00:00:05.299946</td>\n",
       "      <td>7.837994e-07</td>\n",
       "      <td>16</td>\n",
       "      <td>148</td>\n",
       "      <td>19</td>\n",
       "      <td>1.898154e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771833</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:17.567463</td>\n",
       "      <td>2023-04-25 19:16:24.307148</td>\n",
       "      <td>0 days 00:00:06.739685</td>\n",
       "      <td>2.259721e-03</td>\n",
       "      <td>8</td>\n",
       "      <td>110</td>\n",
       "      <td>39</td>\n",
       "      <td>5.735774e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.973112</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:19.121427</td>\n",
       "      <td>2023-04-25 19:16:37.033069</td>\n",
       "      <td>0 days 00:00:17.911642</td>\n",
       "      <td>2.210140e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>313</td>\n",
       "      <td>31</td>\n",
       "      <td>6.515564e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.637614</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:20.866819</td>\n",
       "      <td>2023-04-25 19:16:22.381922</td>\n",
       "      <td>0 days 00:00:01.515103</td>\n",
       "      <td>7.693470e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>309</td>\n",
       "      <td>7</td>\n",
       "      <td>2.269253e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232843</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:22.384136</td>\n",
       "      <td>2023-04-25 19:16:25.446360</td>\n",
       "      <td>0 days 00:00:03.062224</td>\n",
       "      <td>3.264663e-05</td>\n",
       "      <td>40</td>\n",
       "      <td>288</td>\n",
       "      <td>5</td>\n",
       "      <td>8.473230e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456704</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:24.309428</td>\n",
       "      <td>2023-04-25 19:16:27.172685</td>\n",
       "      <td>0 days 00:00:02.863257</td>\n",
       "      <td>1.095755e-07</td>\n",
       "      <td>46</td>\n",
       "      <td>234</td>\n",
       "      <td>8</td>\n",
       "      <td>1.145773e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416351</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:24.690829</td>\n",
       "      <td>2023-04-25 19:16:26.480539</td>\n",
       "      <td>0 days 00:00:01.789710</td>\n",
       "      <td>5.484209e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>497</td>\n",
       "      <td>37</td>\n",
       "      <td>6.338693e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260050</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:25.448059</td>\n",
       "      <td>2023-04-25 19:16:29.836356</td>\n",
       "      <td>0 days 00:00:04.388297</td>\n",
       "      <td>5.817378e-07</td>\n",
       "      <td>19</td>\n",
       "      <td>293</td>\n",
       "      <td>8</td>\n",
       "      <td>1.640148e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635784</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:26.482052</td>\n",
       "      <td>2023-04-25 19:16:36.145299</td>\n",
       "      <td>0 days 00:00:09.663247</td>\n",
       "      <td>4.732655e-06</td>\n",
       "      <td>9</td>\n",
       "      <td>259</td>\n",
       "      <td>18</td>\n",
       "      <td>4.995949e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.405422</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:27.174591</td>\n",
       "      <td>2023-04-25 19:16:27.813665</td>\n",
       "      <td>0 days 00:00:00.639074</td>\n",
       "      <td>4.496621e-07</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>6.825637e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092498</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:27.815845</td>\n",
       "      <td>2023-04-25 19:16:28.038248</td>\n",
       "      <td>0 days 00:00:00.222403</td>\n",
       "      <td>3.634812e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>2.888925e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032474</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:28.039897</td>\n",
       "      <td>2023-04-25 19:16:28.128468</td>\n",
       "      <td>0 days 00:00:00.088571</td>\n",
       "      <td>7.172092e-05</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>4.357801e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011213</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:28.130675</td>\n",
       "      <td>2023-04-25 19:16:28.447377</td>\n",
       "      <td>0 days 00:00:00.316702</td>\n",
       "      <td>4.077367e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>97</td>\n",
       "      <td>47</td>\n",
       "      <td>2.671282e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044525</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:28.450107</td>\n",
       "      <td>2023-04-25 19:16:29.840945</td>\n",
       "      <td>0 days 00:00:01.390838</td>\n",
       "      <td>3.986427e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>499</td>\n",
       "      <td>11</td>\n",
       "      <td>2.896479e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.199458</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:29.839018</td>\n",
       "      <td>2023-04-25 19:16:43.905503</td>\n",
       "      <td>0 days 00:00:14.066485</td>\n",
       "      <td>2.173191e-07</td>\n",
       "      <td>21</td>\n",
       "      <td>165</td>\n",
       "      <td>48</td>\n",
       "      <td>2.257131e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.051277</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:29.844241</td>\n",
       "      <td>2023-04-25 19:16:37.568866</td>\n",
       "      <td>0 days 00:00:07.724625</td>\n",
       "      <td>3.622372e-07</td>\n",
       "      <td>28</td>\n",
       "      <td>331</td>\n",
       "      <td>13</td>\n",
       "      <td>2.338562e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.137816</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:36.147434</td>\n",
       "      <td>2023-04-25 19:16:37.981572</td>\n",
       "      <td>0 days 00:00:01.834138</td>\n",
       "      <td>3.144001e-07</td>\n",
       "      <td>35</td>\n",
       "      <td>159</td>\n",
       "      <td>26</td>\n",
       "      <td>1.184091e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.271588</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:37.035625</td>\n",
       "      <td>2023-04-25 19:16:47.199724</td>\n",
       "      <td>0 days 00:00:10.164099</td>\n",
       "      <td>2.617107e-01</td>\n",
       "      <td>17</td>\n",
       "      <td>465</td>\n",
       "      <td>12</td>\n",
       "      <td>9.799774e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.475542</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:37.571212</td>\n",
       "      <td>2023-04-25 19:16:40.950319</td>\n",
       "      <td>0 days 00:00:03.379107</td>\n",
       "      <td>2.295502e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>208</td>\n",
       "      <td>10</td>\n",
       "      <td>9.477288e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.487989</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:37.983873</td>\n",
       "      <td>2023-04-25 19:16:47.215402</td>\n",
       "      <td>0 days 00:00:09.231529</td>\n",
       "      <td>2.583494e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>238</td>\n",
       "      <td>41</td>\n",
       "      <td>4.800750e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.333110</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:40.953522</td>\n",
       "      <td>2023-04-25 19:16:41.242596</td>\n",
       "      <td>0 days 00:00:00.289074</td>\n",
       "      <td>2.245838e-06</td>\n",
       "      <td>35</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>1.501725e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042288</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:41.244575</td>\n",
       "      <td>2023-04-25 19:16:42.135419</td>\n",
       "      <td>0 days 00:00:00.890844</td>\n",
       "      <td>1.394289e-06</td>\n",
       "      <td>28</td>\n",
       "      <td>276</td>\n",
       "      <td>42</td>\n",
       "      <td>2.640100e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:42.137911</td>\n",
       "      <td>2023-04-25 19:16:42.468793</td>\n",
       "      <td>0 days 00:00:00.330882</td>\n",
       "      <td>2.709134e-03</td>\n",
       "      <td>33</td>\n",
       "      <td>104</td>\n",
       "      <td>25</td>\n",
       "      <td>2.101013e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046714</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:42.471390</td>\n",
       "      <td>2023-04-25 19:16:44.925072</td>\n",
       "      <td>0 days 00:00:02.453682</td>\n",
       "      <td>1.212239e-05</td>\n",
       "      <td>23</td>\n",
       "      <td>183</td>\n",
       "      <td>34</td>\n",
       "      <td>3.813888e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.353937</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:43.907387</td>\n",
       "      <td>2023-04-25 19:16:49.343376</td>\n",
       "      <td>0 days 00:00:05.435989</td>\n",
       "      <td>5.702464e-03</td>\n",
       "      <td>32</td>\n",
       "      <td>388</td>\n",
       "      <td>24</td>\n",
       "      <td>4.308188e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793126</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:44.927467</td>\n",
       "      <td>2023-04-25 19:16:58.614113</td>\n",
       "      <td>0 days 00:00:13.686646</td>\n",
       "      <td>1.008698e-05</td>\n",
       "      <td>26</td>\n",
       "      <td>332</td>\n",
       "      <td>29</td>\n",
       "      <td>4.322391e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.134998</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:47.201499</td>\n",
       "      <td>2023-04-25 19:16:48.505278</td>\n",
       "      <td>0 days 00:00:01.303779</td>\n",
       "      <td>1.025489e-04</td>\n",
       "      <td>24</td>\n",
       "      <td>421</td>\n",
       "      <td>24</td>\n",
       "      <td>8.776533e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193317</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:47.218526</td>\n",
       "      <td>2023-04-25 19:16:48.851728</td>\n",
       "      <td>0 days 00:00:01.633202</td>\n",
       "      <td>1.913239e-05</td>\n",
       "      <td>35</td>\n",
       "      <td>491</td>\n",
       "      <td>14</td>\n",
       "      <td>7.327819e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.238044</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:48.507653</td>\n",
       "      <td>2023-04-25 19:16:49.824110</td>\n",
       "      <td>0 days 00:00:01.316457</td>\n",
       "      <td>1.641388e-02</td>\n",
       "      <td>30</td>\n",
       "      <td>353</td>\n",
       "      <td>48</td>\n",
       "      <td>2.795190e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193668</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:48.854271</td>\n",
       "      <td>2023-04-25 19:16:49.126555</td>\n",
       "      <td>0 days 00:00:00.272284</td>\n",
       "      <td>1.901228e-02</td>\n",
       "      <td>28</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>9.502073e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045981</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:49.128527</td>\n",
       "      <td>2023-04-25 19:16:49.472155</td>\n",
       "      <td>0 days 00:00:00.343628</td>\n",
       "      <td>3.642222e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>27</td>\n",
       "      <td>1.502579e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052829</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:49.345180</td>\n",
       "      <td>2023-04-25 19:16:55.067138</td>\n",
       "      <td>0 days 00:00:05.721958</td>\n",
       "      <td>3.224328e-03</td>\n",
       "      <td>32</td>\n",
       "      <td>306</td>\n",
       "      <td>27</td>\n",
       "      <td>1.081104e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825426</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:49.474148</td>\n",
       "      <td>2023-04-25 19:16:50.203639</td>\n",
       "      <td>0 days 00:00:00.729491</td>\n",
       "      <td>2.267472e-01</td>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>44</td>\n",
       "      <td>2.939023e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105681</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:49.826800</td>\n",
       "      <td>2023-04-25 19:16:50.684783</td>\n",
       "      <td>0 days 00:00:00.857983</td>\n",
       "      <td>6.904985e-03</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>8</td>\n",
       "      <td>1.079810e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124382</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:50.205625</td>\n",
       "      <td>2023-04-25 19:17:01.985828</td>\n",
       "      <td>0 days 00:00:11.780203</td>\n",
       "      <td>7.058548e-07</td>\n",
       "      <td>13</td>\n",
       "      <td>322</td>\n",
       "      <td>34</td>\n",
       "      <td>1.674755e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.486985</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:50.688145</td>\n",
       "      <td>2023-04-25 19:16:53.188285</td>\n",
       "      <td>0 days 00:00:02.500140</td>\n",
       "      <td>2.963666e-06</td>\n",
       "      <td>7</td>\n",
       "      <td>113</td>\n",
       "      <td>14</td>\n",
       "      <td>1.960060e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.363217</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:53.190934</td>\n",
       "      <td>2023-04-25 19:16:53.859267</td>\n",
       "      <td>0 days 00:00:00.668333</td>\n",
       "      <td>1.063198e-05</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>45</td>\n",
       "      <td>2.298809e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094609</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>None</td>\n",
       "      <td>2023-04-25 19:16:53.862858</td>\n",
       "      <td>2023-04-25 19:16:58.920731</td>\n",
       "      <td>0 days 00:00:05.057873</td>\n",
       "      <td>4.732463e-05</td>\n",
       "      <td>18</td>\n",
       "      <td>113</td>\n",
       "      <td>32</td>\n",
       "      <td>2.412559e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.749063</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    number value             datetime_start          datetime_complete  \\\n",
       "0        0  None 2023-04-25 19:15:52.843865 2023-04-25 19:15:57.533979   \n",
       "1        1  None 2023-04-25 19:15:52.850513 2023-04-25 19:16:04.086423   \n",
       "2        2  None 2023-04-25 19:15:52.852508 2023-04-25 19:15:54.727451   \n",
       "3        3  None 2023-04-25 19:15:52.854734 2023-04-25 19:16:20.864823   \n",
       "4        4  None 2023-04-25 19:15:54.730126 2023-04-25 19:15:55.835744   \n",
       "5        5  None 2023-04-25 19:15:55.838492 2023-04-25 19:15:59.059942   \n",
       "6        6  None 2023-04-25 19:15:57.536587 2023-04-25 19:16:13.816861   \n",
       "7        7  None 2023-04-25 19:15:59.062499 2023-04-25 19:16:07.901796   \n",
       "8        8  None 2023-04-25 19:16:04.088592 2023-04-25 19:16:04.250656   \n",
       "9        9  None 2023-04-25 19:16:04.252953 2023-04-25 19:16:17.565311   \n",
       "10      10  None 2023-04-25 19:16:07.904440 2023-04-25 19:16:09.108762   \n",
       "11      11  None 2023-04-25 19:16:09.111583 2023-04-25 19:16:24.688577   \n",
       "12      12  None 2023-04-25 19:16:13.819014 2023-04-25 19:16:19.118960   \n",
       "13      13  None 2023-04-25 19:16:17.567463 2023-04-25 19:16:24.307148   \n",
       "14      14  None 2023-04-25 19:16:19.121427 2023-04-25 19:16:37.033069   \n",
       "15      15  None 2023-04-25 19:16:20.866819 2023-04-25 19:16:22.381922   \n",
       "16      16  None 2023-04-25 19:16:22.384136 2023-04-25 19:16:25.446360   \n",
       "17      17  None 2023-04-25 19:16:24.309428 2023-04-25 19:16:27.172685   \n",
       "18      18  None 2023-04-25 19:16:24.690829 2023-04-25 19:16:26.480539   \n",
       "19      19  None 2023-04-25 19:16:25.448059 2023-04-25 19:16:29.836356   \n",
       "20      20  None 2023-04-25 19:16:26.482052 2023-04-25 19:16:36.145299   \n",
       "21      21  None 2023-04-25 19:16:27.174591 2023-04-25 19:16:27.813665   \n",
       "22      22  None 2023-04-25 19:16:27.815845 2023-04-25 19:16:28.038248   \n",
       "23      23  None 2023-04-25 19:16:28.039897 2023-04-25 19:16:28.128468   \n",
       "24      24  None 2023-04-25 19:16:28.130675 2023-04-25 19:16:28.447377   \n",
       "25      25  None 2023-04-25 19:16:28.450107 2023-04-25 19:16:29.840945   \n",
       "26      26  None 2023-04-25 19:16:29.839018 2023-04-25 19:16:43.905503   \n",
       "27      27  None 2023-04-25 19:16:29.844241 2023-04-25 19:16:37.568866   \n",
       "28      28  None 2023-04-25 19:16:36.147434 2023-04-25 19:16:37.981572   \n",
       "29      29  None 2023-04-25 19:16:37.035625 2023-04-25 19:16:47.199724   \n",
       "30      30  None 2023-04-25 19:16:37.571212 2023-04-25 19:16:40.950319   \n",
       "31      31  None 2023-04-25 19:16:37.983873 2023-04-25 19:16:47.215402   \n",
       "32      32  None 2023-04-25 19:16:40.953522 2023-04-25 19:16:41.242596   \n",
       "33      33  None 2023-04-25 19:16:41.244575 2023-04-25 19:16:42.135419   \n",
       "34      34  None 2023-04-25 19:16:42.137911 2023-04-25 19:16:42.468793   \n",
       "35      35  None 2023-04-25 19:16:42.471390 2023-04-25 19:16:44.925072   \n",
       "36      36  None 2023-04-25 19:16:43.907387 2023-04-25 19:16:49.343376   \n",
       "37      37  None 2023-04-25 19:16:44.927467 2023-04-25 19:16:58.614113   \n",
       "38      38  None 2023-04-25 19:16:47.201499 2023-04-25 19:16:48.505278   \n",
       "39      39  None 2023-04-25 19:16:47.218526 2023-04-25 19:16:48.851728   \n",
       "40      40  None 2023-04-25 19:16:48.507653 2023-04-25 19:16:49.824110   \n",
       "41      41  None 2023-04-25 19:16:48.854271 2023-04-25 19:16:49.126555   \n",
       "42      42  None 2023-04-25 19:16:49.128527 2023-04-25 19:16:49.472155   \n",
       "43      43  None 2023-04-25 19:16:49.345180 2023-04-25 19:16:55.067138   \n",
       "44      44  None 2023-04-25 19:16:49.474148 2023-04-25 19:16:50.203639   \n",
       "45      45  None 2023-04-25 19:16:49.826800 2023-04-25 19:16:50.684783   \n",
       "46      46  None 2023-04-25 19:16:50.205625 2023-04-25 19:17:01.985828   \n",
       "47      47  None 2023-04-25 19:16:50.688145 2023-04-25 19:16:53.188285   \n",
       "48      48  None 2023-04-25 19:16:53.190934 2023-04-25 19:16:53.859267   \n",
       "49      49  None 2023-04-25 19:16:53.862858 2023-04-25 19:16:58.920731   \n",
       "\n",
       "                 duration  params_learning_rate  params_max_depth  \\\n",
       "0  0 days 00:00:04.690114          2.853813e-06                43   \n",
       "1  0 days 00:00:11.235910          6.392680e-03                39   \n",
       "2  0 days 00:00:01.874943          7.453219e-03                34   \n",
       "3  0 days 00:00:28.010089          3.160354e-03                14   \n",
       "4  0 days 00:00:01.105618          1.172477e-02                 3   \n",
       "5  0 days 00:00:03.221450          8.678914e-04                42   \n",
       "6  0 days 00:00:16.280274          7.936785e-04                31   \n",
       "7  0 days 00:00:08.839297          1.353845e-02                30   \n",
       "8  0 days 00:00:00.162064          2.408493e-04                31   \n",
       "9  0 days 00:00:13.312358          1.024572e-04                39   \n",
       "10 0 days 00:00:01.204322          9.958787e-04                35   \n",
       "11 0 days 00:00:15.576994          9.103200e-05                 0   \n",
       "12 0 days 00:00:05.299946          7.837994e-07                16   \n",
       "13 0 days 00:00:06.739685          2.259721e-03                 8   \n",
       "14 0 days 00:00:17.911642          2.210140e-04                13   \n",
       "15 0 days 00:00:01.515103          7.693470e-02                 1   \n",
       "16 0 days 00:00:03.062224          3.264663e-05                40   \n",
       "17 0 days 00:00:02.863257          1.095755e-07                46   \n",
       "18 0 days 00:00:01.789710          5.484209e-04                 5   \n",
       "19 0 days 00:00:04.388297          5.817378e-07                19   \n",
       "20 0 days 00:00:09.663247          4.732655e-06                 9   \n",
       "21 0 days 00:00:00.639074          4.496621e-07                 6   \n",
       "22 0 days 00:00:00.222403          3.634812e-02                 1   \n",
       "23 0 days 00:00:00.088571          7.172092e-05                 4   \n",
       "24 0 days 00:00:00.316702          4.077367e-04                13   \n",
       "25 0 days 00:00:01.390838          3.986427e-03                 3   \n",
       "26 0 days 00:00:14.066485          2.173191e-07                21   \n",
       "27 0 days 00:00:07.724625          3.622372e-07                28   \n",
       "28 0 days 00:00:01.834138          3.144001e-07                35   \n",
       "29 0 days 00:00:10.164099          2.617107e-01                17   \n",
       "30 0 days 00:00:03.379107          2.295502e-04                 5   \n",
       "31 0 days 00:00:09.231529          2.583494e-01                 5   \n",
       "32 0 days 00:00:00.289074          2.245838e-06                35   \n",
       "33 0 days 00:00:00.890844          1.394289e-06                28   \n",
       "34 0 days 00:00:00.330882          2.709134e-03                33   \n",
       "35 0 days 00:00:02.453682          1.212239e-05                23   \n",
       "36 0 days 00:00:05.435989          5.702464e-03                32   \n",
       "37 0 days 00:00:13.686646          1.008698e-05                26   \n",
       "38 0 days 00:00:01.303779          1.025489e-04                24   \n",
       "39 0 days 00:00:01.633202          1.913239e-05                35   \n",
       "40 0 days 00:00:01.316457          1.641388e-02                30   \n",
       "41 0 days 00:00:00.272284          1.901228e-02                28   \n",
       "42 0 days 00:00:00.343628          3.642222e-06                 2   \n",
       "43 0 days 00:00:05.721958          3.224328e-03                32   \n",
       "44 0 days 00:00:00.729491          2.267472e-01                 2   \n",
       "45 0 days 00:00:00.857983          6.904985e-03                23   \n",
       "46 0 days 00:00:11.780203          7.058548e-07                13   \n",
       "47 0 days 00:00:02.500140          2.963666e-06                 7   \n",
       "48 0 days 00:00:00.668333          1.063198e-05                 7   \n",
       "49 0 days 00:00:05.057873          4.732463e-05                18   \n",
       "\n",
       "    params_n_estimators  params_num_leaves  params_reg_alpha  ...  \\\n",
       "0                   385                 18      9.046719e+02  ...   \n",
       "1                   298                 24      1.626622e-01  ...   \n",
       "2                   415                 46      2.997876e+05  ...   \n",
       "3                   443                 35      3.560444e+00  ...   \n",
       "4                    70                 25      2.412308e-05  ...   \n",
       "5                   268                 50      1.215929e+03  ...   \n",
       "6                   239                 37      2.898895e-06  ...   \n",
       "7                   298                 16      1.704116e-06  ...   \n",
       "8                    40                 46      8.211615e+04  ...   \n",
       "9                   459                 19      1.019510e+01  ...   \n",
       "10                  362                 24      3.576990e+06  ...   \n",
       "11                  214                 40      4.172585e-06  ...   \n",
       "12                  148                 19      1.898154e-06  ...   \n",
       "13                  110                 39      5.735774e-07  ...   \n",
       "14                  313                 31      6.515564e+00  ...   \n",
       "15                  309                  7      2.269253e-06  ...   \n",
       "16                  288                  5      8.473230e+01  ...   \n",
       "17                  234                  8      1.145773e+03  ...   \n",
       "18                  497                 37      6.338693e+03  ...   \n",
       "19                  293                  8      1.640148e+02  ...   \n",
       "20                  259                 18      4.995949e-06  ...   \n",
       "21                   16                 20      6.825637e-07  ...   \n",
       "22                   47                  5      2.888925e-06  ...   \n",
       "23                   13                 26      4.357801e+04  ...   \n",
       "24                   97                 47      2.671282e+03  ...   \n",
       "25                  499                 11      2.896479e+04  ...   \n",
       "26                  165                 48      2.257131e+00  ...   \n",
       "27                  331                 13      2.338562e-02  ...   \n",
       "28                  159                 26      1.184091e+03  ...   \n",
       "29                  465                 12      9.799774e-02  ...   \n",
       "30                  208                 10      9.477288e-03  ...   \n",
       "31                  238                 41      4.800750e-07  ...   \n",
       "32                   90                 11      1.501725e+06  ...   \n",
       "33                  276                 42      2.640100e+05  ...   \n",
       "34                  104                 25      2.101013e+03  ...   \n",
       "35                  183                 34      3.813888e+02  ...   \n",
       "36                  388                 24      4.308188e+02  ...   \n",
       "37                  332                 29      4.322391e-07  ...   \n",
       "38                  421                 24      8.776533e+05  ...   \n",
       "39                  491                 14      7.327819e+06  ...   \n",
       "40                  353                 48      2.795190e+05  ...   \n",
       "41                   41                 43      9.502073e+05  ...   \n",
       "42                   83                 27      1.502579e+04  ...   \n",
       "43                  306                 27      1.081104e-02  ...   \n",
       "44                   95                 44      2.939023e-04  ...   \n",
       "45                   56                  8      1.079810e-03  ...   \n",
       "46                  322                 34      1.674755e-04  ...   \n",
       "47                  113                 14      1.960060e+00  ...   \n",
       "48                  172                 45      2.298809e+03  ...   \n",
       "49                  113                 32      2.412559e-06  ...   \n",
       "\n",
       "    user_attrs_mean_score_time  user_attrs_mean_test_score  \\\n",
       "0                     0.000227                         NaN   \n",
       "1                     0.000510                         NaN   \n",
       "2                     0.000710                         NaN   \n",
       "3                     0.000177                         NaN   \n",
       "4                     0.000223                         NaN   \n",
       "5                     0.000179                         NaN   \n",
       "6                     0.000162                         NaN   \n",
       "7                     0.000538                         NaN   \n",
       "8                     0.000193                         NaN   \n",
       "9                     0.000165                         NaN   \n",
       "10                    0.000389                         NaN   \n",
       "11                    0.000173                         NaN   \n",
       "12                    0.000169                         NaN   \n",
       "13                    0.000170                         NaN   \n",
       "14                    0.000188                         NaN   \n",
       "15                    0.000184                         NaN   \n",
       "16                    0.000966                         NaN   \n",
       "17                    0.000182                         NaN   \n",
       "18                    0.000189                         NaN   \n",
       "19                    0.000174                         NaN   \n",
       "20                    0.000172                         NaN   \n",
       "21                    0.000219                         NaN   \n",
       "22                    0.000182                         NaN   \n",
       "23                    0.000160                         NaN   \n",
       "24                    0.000176                         NaN   \n",
       "25                    0.000188                         NaN   \n",
       "26                    0.000234                         NaN   \n",
       "27                    0.000161                         NaN   \n",
       "28                    0.000183                         NaN   \n",
       "29                    0.000207                         NaN   \n",
       "30                    0.000532                         NaN   \n",
       "31                    0.000200                         NaN   \n",
       "32                    0.000172                         NaN   \n",
       "33                    0.000179                         NaN   \n",
       "34                    0.000165                         NaN   \n",
       "35                    0.000203                         NaN   \n",
       "36                    0.000323                         NaN   \n",
       "37                    0.000169                         NaN   \n",
       "38                    0.000163                         NaN   \n",
       "39                    0.000190                         NaN   \n",
       "40                    0.000176                         NaN   \n",
       "41                    0.000193                         NaN   \n",
       "42                    0.000138                         NaN   \n",
       "43                    0.000212                         NaN   \n",
       "44                    0.000172                         NaN   \n",
       "45                    0.000170                         NaN   \n",
       "46                    0.000168                         NaN   \n",
       "47                    0.000191                         NaN   \n",
       "48                    0.001274                         NaN   \n",
       "49                    0.000201                         NaN   \n",
       "\n",
       "    user_attrs_split0_test_score  user_attrs_split1_test_score  \\\n",
       "0                            NaN                           NaN   \n",
       "1                            NaN                           NaN   \n",
       "2                            NaN                           NaN   \n",
       "3                            NaN                           NaN   \n",
       "4                            NaN                           NaN   \n",
       "5                            NaN                           NaN   \n",
       "6                            NaN                           NaN   \n",
       "7                            NaN                           NaN   \n",
       "8                            NaN                           NaN   \n",
       "9                            NaN                           NaN   \n",
       "10                           NaN                           NaN   \n",
       "11                           NaN                           NaN   \n",
       "12                           NaN                           NaN   \n",
       "13                           NaN                           NaN   \n",
       "14                           NaN                           NaN   \n",
       "15                           NaN                           NaN   \n",
       "16                           NaN                           NaN   \n",
       "17                           NaN                           NaN   \n",
       "18                           NaN                           NaN   \n",
       "19                           NaN                           NaN   \n",
       "20                           NaN                           NaN   \n",
       "21                           NaN                           NaN   \n",
       "22                           NaN                           NaN   \n",
       "23                           NaN                           NaN   \n",
       "24                           NaN                           NaN   \n",
       "25                           NaN                           NaN   \n",
       "26                           NaN                           NaN   \n",
       "27                           NaN                           NaN   \n",
       "28                           NaN                           NaN   \n",
       "29                           NaN                           NaN   \n",
       "30                           NaN                           NaN   \n",
       "31                           NaN                           NaN   \n",
       "32                           NaN                           NaN   \n",
       "33                           NaN                           NaN   \n",
       "34                           NaN                           NaN   \n",
       "35                           NaN                           NaN   \n",
       "36                           NaN                           NaN   \n",
       "37                           NaN                           NaN   \n",
       "38                           NaN                           NaN   \n",
       "39                           NaN                           NaN   \n",
       "40                           NaN                           NaN   \n",
       "41                           NaN                           NaN   \n",
       "42                           NaN                           NaN   \n",
       "43                           NaN                           NaN   \n",
       "44                           NaN                           NaN   \n",
       "45                           NaN                           NaN   \n",
       "46                           NaN                           NaN   \n",
       "47                           NaN                           NaN   \n",
       "48                           NaN                           NaN   \n",
       "49                           NaN                           NaN   \n",
       "\n",
       "    user_attrs_split2_test_score  user_attrs_split3_test_score  \\\n",
       "0                            NaN                           NaN   \n",
       "1                            NaN                           NaN   \n",
       "2                            NaN                           NaN   \n",
       "3                            NaN                           NaN   \n",
       "4                            NaN                           NaN   \n",
       "5                            NaN                           NaN   \n",
       "6                            NaN                           NaN   \n",
       "7                            NaN                           NaN   \n",
       "8                            NaN                           NaN   \n",
       "9                            NaN                           NaN   \n",
       "10                           NaN                           NaN   \n",
       "11                           NaN                           NaN   \n",
       "12                           NaN                           NaN   \n",
       "13                           NaN                           NaN   \n",
       "14                           NaN                           NaN   \n",
       "15                           NaN                           NaN   \n",
       "16                           NaN                           NaN   \n",
       "17                           NaN                           NaN   \n",
       "18                           NaN                           NaN   \n",
       "19                           NaN                           NaN   \n",
       "20                           NaN                           NaN   \n",
       "21                           NaN                           NaN   \n",
       "22                           NaN                           NaN   \n",
       "23                           NaN                           NaN   \n",
       "24                           NaN                           NaN   \n",
       "25                           NaN                           NaN   \n",
       "26                           NaN                           NaN   \n",
       "27                           NaN                           NaN   \n",
       "28                           NaN                           NaN   \n",
       "29                           NaN                           NaN   \n",
       "30                           NaN                           NaN   \n",
       "31                           NaN                           NaN   \n",
       "32                           NaN                           NaN   \n",
       "33                           NaN                           NaN   \n",
       "34                           NaN                           NaN   \n",
       "35                           NaN                           NaN   \n",
       "36                           NaN                           NaN   \n",
       "37                           NaN                           NaN   \n",
       "38                           NaN                           NaN   \n",
       "39                           NaN                           NaN   \n",
       "40                           NaN                           NaN   \n",
       "41                           NaN                           NaN   \n",
       "42                           NaN                           NaN   \n",
       "43                           NaN                           NaN   \n",
       "44                           NaN                           NaN   \n",
       "45                           NaN                           NaN   \n",
       "46                           NaN                           NaN   \n",
       "47                           NaN                           NaN   \n",
       "48                           NaN                           NaN   \n",
       "49                           NaN                           NaN   \n",
       "\n",
       "    user_attrs_std_fit_time  user_attrs_std_score_time  \\\n",
       "0                  0.681406                   0.000168   \n",
       "1                  1.613155                   0.000602   \n",
       "2                  0.278675                   0.000984   \n",
       "3                  4.073371                   0.000104   \n",
       "4                  0.168333                   0.000162   \n",
       "5                  0.485249                   0.000106   \n",
       "6                  2.354601                   0.000094   \n",
       "7                  1.276135                   0.000653   \n",
       "8                  0.022451                   0.000114   \n",
       "9                  1.922425                   0.000095   \n",
       "10                 0.172511                   0.000347   \n",
       "11                 2.251447                   0.000100   \n",
       "12                 0.771833                   0.000098   \n",
       "13                 0.973112                   0.000099   \n",
       "14                 2.637614                   0.000113   \n",
       "15                 0.232843                   0.000110   \n",
       "16                 0.456704                   0.001438   \n",
       "17                 0.416351                   0.000108   \n",
       "18                 0.260050                   0.000110   \n",
       "19                 0.635784                   0.000101   \n",
       "20                 1.405422                   0.000099   \n",
       "21                 0.092498                   0.000161   \n",
       "22                 0.032474                   0.000110   \n",
       "23                 0.011213                   0.000092   \n",
       "24                 0.044525                   0.000103   \n",
       "25                 0.199458                   0.000110   \n",
       "26                 2.051277                   0.000152   \n",
       "27                 1.137816                   0.000093   \n",
       "28                 0.271588                   0.000110   \n",
       "29                 1.475542                   0.000130   \n",
       "30                 0.487989                   0.000610   \n",
       "31                 1.333110                   0.000127   \n",
       "32                 0.042288                   0.000100   \n",
       "33                 0.127755                   0.000105   \n",
       "34                 0.046714                   0.000096   \n",
       "35                 0.353937                   0.000121   \n",
       "36                 0.793126                   0.000316   \n",
       "37                 2.134998                   0.000098   \n",
       "38                 0.193317                   0.000094   \n",
       "39                 0.238044                   0.000114   \n",
       "40                 0.193668                   0.000103   \n",
       "41                 0.045981                   0.000116   \n",
       "42                 0.052829                   0.000093   \n",
       "43                 0.825426                   0.000139   \n",
       "44                 0.105681                   0.000099   \n",
       "45                 0.124382                   0.000100   \n",
       "46                 2.486985                   0.000097   \n",
       "47                 0.363217                   0.000112   \n",
       "48                 0.094609                   0.001960   \n",
       "49                 0.749063                   0.000124   \n",
       "\n",
       "    user_attrs_std_test_score  state  \n",
       "0                         NaN   FAIL  \n",
       "1                         NaN   FAIL  \n",
       "2                         NaN   FAIL  \n",
       "3                         NaN   FAIL  \n",
       "4                         NaN   FAIL  \n",
       "5                         NaN   FAIL  \n",
       "6                         NaN   FAIL  \n",
       "7                         NaN   FAIL  \n",
       "8                         NaN   FAIL  \n",
       "9                         NaN   FAIL  \n",
       "10                        NaN   FAIL  \n",
       "11                        NaN   FAIL  \n",
       "12                        NaN   FAIL  \n",
       "13                        NaN   FAIL  \n",
       "14                        NaN   FAIL  \n",
       "15                        NaN   FAIL  \n",
       "16                        NaN   FAIL  \n",
       "17                        NaN   FAIL  \n",
       "18                        NaN   FAIL  \n",
       "19                        NaN   FAIL  \n",
       "20                        NaN   FAIL  \n",
       "21                        NaN   FAIL  \n",
       "22                        NaN   FAIL  \n",
       "23                        NaN   FAIL  \n",
       "24                        NaN   FAIL  \n",
       "25                        NaN   FAIL  \n",
       "26                        NaN   FAIL  \n",
       "27                        NaN   FAIL  \n",
       "28                        NaN   FAIL  \n",
       "29                        NaN   FAIL  \n",
       "30                        NaN   FAIL  \n",
       "31                        NaN   FAIL  \n",
       "32                        NaN   FAIL  \n",
       "33                        NaN   FAIL  \n",
       "34                        NaN   FAIL  \n",
       "35                        NaN   FAIL  \n",
       "36                        NaN   FAIL  \n",
       "37                        NaN   FAIL  \n",
       "38                        NaN   FAIL  \n",
       "39                        NaN   FAIL  \n",
       "40                        NaN   FAIL  \n",
       "41                        NaN   FAIL  \n",
       "42                        NaN   FAIL  \n",
       "43                        NaN   FAIL  \n",
       "44                        NaN   FAIL  \n",
       "45                        NaN   FAIL  \n",
       "46                        NaN   FAIL  \n",
       "47                        NaN   FAIL  \n",
       "48                        NaN   FAIL  \n",
       "49                        NaN   FAIL  \n",
       "\n",
       "[50 rows x 22 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[\"11_0\"].trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b34dade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = pd.DataFrame()\n",
    "for key in models.keys():\n",
    "    if models[key]:\n",
    "        trial_df = models[key].trials_dataframe()\n",
    "        trial_df[\"key\"] = key\n",
    "        trials_df = pd.concat([trials_df, trial_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "773b9bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df.to_csv(\"OptunaStudyTrialsAll.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1315c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlp]",
   "language": "python",
   "name": "conda-env-mlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
