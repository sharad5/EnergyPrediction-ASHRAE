{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af59f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "# from utils import load_data, get_train_val_split, get_stratified_splitter\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedGroupKFold, train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import kstest, kruskal, mannwhitneyu\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import re\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import optuna\n",
    "import pickle\n",
    "\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f663bf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\johns\\\\Desktop\\\\probstats2\\\\EnergyPrediction-ASHRAE\\\\code\\\\utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c2569b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.88%\n",
      "Memory usage of dataframe is 9.60 MB\n",
      "Memory usage after optimization is: 3.07 MB\n",
      "Decreased by 68.05%\n",
      "Memory usage of dataframe is 19.04 MB\n",
      "Memory usage after optimization is: 5.13 MB\n",
      "Decreased by 73.04%\n",
      "Memory usage of dataframe is 616.95 MB\n",
      "Memory usage after optimization is: 289.19 MB\n",
      "Decreased by 53.12%\n",
      "Memory usage of dataframe is 1272.51 MB\n",
      "Memory usage after optimization is: 358.53 MB\n",
      "Decreased by 71.82%\n"
     ]
    }
   ],
   "source": [
    "data_dict = utils.load_data('ashrae-energy-prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aea63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weather features \n",
    "weather_features = ['cloud_coverage', 'dew_temperature', 'air_temperature', \n",
    "                    'sea_level_pressure', 'wind_direction', 'wind_speed', 'precip_depth_1_hr',]\n",
    "\n",
    "hourly_by_site = data_dict[\"X_train\"].groupby(['hour', 'month', 'site_id'])[weather_features].mean().reset_index()\n",
    "\n",
    "data_dict[\"X_train\"] = data_dict[\"X_train\"].merge(\n",
    "    hourly_by_site, \n",
    "    on=['hour', 'month', 'site_id'], \n",
    "    how='left', \n",
    "    suffixes=(None, '_hourly_by_site')\n",
    ")\n",
    "\n",
    "del hourly_by_site\n",
    "\n",
    "for feature in weather_features:\n",
    "    # Fill in NA values from weather with hourly by site columns \n",
    "    data_dict[\"X_train\"][feature].fillna(\n",
    "        data_dict[\"X_train\"][feature + \"_hourly_by_site\"],\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    # Fill in the rest with the median \n",
    "    data_dict[\"X_train\"][feature].fillna(\n",
    "        data_dict[\"X_train\"][feature].median(),\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    data_dict[\"X_train\"][feature + \"_diff_hourly_from_mean\"] = data_dict[\"X_train\"][feature] - \\\n",
    "        data_dict[\"X_train\"][feature + \"_hourly_by_site\"]\n",
    "    \n",
    "data_dict[\"X_train\"] = data_dict[\"X_train\"].drop(columns = [feat + \"_hourly_by_site\" for feat in weather_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ad44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in NA with median values for floor count and year_built\n",
    "for feature in ['year_built', 'floor_count']:\n",
    "    data_dict[\"X_train\"][feature].fillna(\n",
    "        data_dict[\"X_train\"][feature].median(), \n",
    "        inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86eb2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['year_built', 'floor_count', 'air_temperature',\n",
    "       'cloud_coverage', 'dew_temperature', 'precip_depth_1_hr',\n",
    "       'sea_level_pressure', 'wind_direction', 'wind_speed',\n",
    "       'air_temperature_mean_lag7', 'air_temperature_max_lag7',\n",
    "       'air_temperature_min_lag7', 'air_temperature_std_lag7',\n",
    "       'cloud_coverage_mean_lag7', 'cloud_coverage_max_lag7',\n",
    "       'cloud_coverage_min_lag7', 'cloud_coverage_std_lag7',\n",
    "       'dew_temperature_mean_lag7', 'dew_temperature_max_lag7',\n",
    "       'dew_temperature_min_lag7', 'dew_temperature_std_lag7',\n",
    "       'precip_depth_1_hr_mean_lag7', 'precip_depth_1_hr_max_lag7',\n",
    "       'precip_depth_1_hr_min_lag7', 'precip_depth_1_hr_std_lag7',\n",
    "       'sea_level_pressure_mean_lag7', 'sea_level_pressure_max_lag7',\n",
    "       'sea_level_pressure_min_lag7', 'sea_level_pressure_std_lag7',\n",
    "       'wind_direction_mean_lag7', 'wind_direction_max_lag7',\n",
    "       'wind_direction_min_lag7', 'wind_direction_std_lag7',\n",
    "       'wind_speed_mean_lag7', 'wind_speed_max_lag7', 'wind_speed_min_lag7',\n",
    "       'wind_speed_std_lag7', 'log_square_feet', 'weekday', 'hour', 'day',\n",
    "       'weekend', 'month', 'primary_use_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7da9895",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_full = data_dict['X_train'].loc[:, features+['meter', 'site_id', 'building_id', 'timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff04b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 2 2\n",
      "1 3 2 2\n",
      "2 0 2 2\n",
      "2 3 2 2\n",
      "2 1 2 2\n",
      "3 0 2 4\n",
      "4 0 2 2\n",
      "5 0 2 2\n",
      "6 0 2 4\n",
      "6 1 2 3\n",
      "6 2 2 4\n",
      "7 0 2 2\n",
      "7 3 2 1\n",
      "7 1 2 2\n",
      "7 2 2 3\n",
      "8 0 2 2\n",
      "9 0 2 2\n",
      "9 1 2 3\n",
      "9 2 2 4\n",
      "10 0 2 2\n",
      "10 3 2 2\n",
      "10 1 2 2\n",
      "11 0 2 3\n",
      "11 3 2 2\n",
      "11 1 2 2\n",
      "12 0 2 3\n",
      "13 0 2 2\n",
      "13 1 2 2\n",
      "13 2 2 2\n",
      "14 0 2 4\n",
      "14 3 2 2\n",
      "14 1 2 2\n",
      "14 2 2 2\n",
      "15 0 2 2\n",
      "15 3 2 1\n",
      "15 1 2 2\n",
      "15 2 2 4\n",
      "0 0 2 3\n",
      "0 1 2 3\n"
     ]
    }
   ],
   "source": [
    "building_cluster_mapping = pd.DataFrame()\n",
    "\n",
    "silhouette_scores = {}\n",
    "for site in X_full['site_id'].unique():\n",
    "    for meter in X_full['meter'].unique():\n",
    "        X = X_full[(X_full[\"site_id\"]==site)&(X_full[\"meter\"]==meter)]\n",
    "        y = data_dict['y_train'][(X_full[\"site_id\"]==site)&(X_full[\"meter\"]==meter)]\n",
    "        X[\"meter_reading\"] = y\n",
    "\n",
    "        X[\"YMD\"] = X[\"timestamp\"].dt.strftime(\"%Y-%m-%d\")\n",
    "        day_level_df = X.groupby([\"building_id\", \"YMD\"]).agg(meter_reading = (\"meter_reading\", \"mean\")).reset_index()\n",
    "        day_level_pivot = pd.pivot_table(day_level_df, values=\"meter_reading\", columns=\"YMD\", index=\"building_id\").fillna(0)\n",
    "        if X.shape[0]==0:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        key = \"_\".join([str(site), str(meter)])\n",
    "        \n",
    "        silhouette_scores[key] = []\n",
    "        n_buildings = day_level_pivot.shape[0]\n",
    "        n_pc_range = range(2, min(n_buildings - 1, 10))\n",
    "        k_range = range(2, min(5, n_buildings - 1))\n",
    "        #Default best_k, best_pc values\n",
    "        best_k, best_pc, best_score, best_labels = 1, 2, 0, np.ones(n_buildings)\n",
    "        for n_pc in n_pc_range:\n",
    "            pca = PCA(n_pc)\n",
    "            t = pca.fit_transform(day_level_pivot)\n",
    "            for k in k_range:\n",
    "                kmeans_labels = KMeans(n_clusters=k, random_state=0).fit(t[:, :n_pc]).labels_\n",
    "                ss = silhouette_score(t[:, :n_pc], kmeans_labels)\n",
    "                if ss > best_score:\n",
    "                    best_pc, best_k, best_score = n_pc, k, ss\n",
    "                    best_labels = kmeans_labels\n",
    "        \n",
    "        print(site, meter, best_pc, best_k)\n",
    "        \n",
    "        day_level_pivot[\"cluster\"] = best_labels\n",
    "        day_level_pivot = day_level_pivot.reset_index()\n",
    "        bc_mapping = day_level_pivot[[\"building_id\", \"cluster\"]]\n",
    "        bc_mapping[\"meter\"] = meter\n",
    "        building_cluster_mapping = pd.concat([building_cluster_mapping, bc_mapping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a59c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2e06024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1299"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "236d9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_dict['weather_test']\n",
    "del data_dict['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ffc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X_full.merge(building_cluster_mapping, on=[\"building_id\", \"meter\"], how=\"left\").set_index('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7b7548b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter_gen = utils.get_stratified_splitter(X_full, data_dict['y_train'])\n",
    "train_index, test_index = next(splitter_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15f3c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = X_full.loc[test_index, :], data_dict['y_train'][test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "554c9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = os.listdir('models/v4/')# sorted(glob('models/v4/*.pkl'))\n",
    "estimators = []\n",
    "for model_file in model_files:\n",
    "    if '.pkl' in model_file:\n",
    "        estimators.append((model_file.split(\".\")[0], pickle.load(open('models/v4/' + model_file,'rb'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3135335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_dict = dict(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "392af520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SHAP_individual_estimators(X_test, y_test, estimators_dict):\n",
    "#     results_df = pd.DataFrame(columns=['y_true', 'y_pred'])\n",
    "    for site_meter_cluster in estimators_dict.keys():\n",
    "\n",
    "        site_id, meter, cluster = list(map(lambda x:int(x) ,site_meter_cluster.split(\"_\")))\n",
    "        # Filter input data for the specific site_id and meter\n",
    "        site_meter_filter = (X_test['site_id'] == site_id) & (X_test['meter'] == meter) & (X_test['cluster'] == cluster)\n",
    "\n",
    "        X_test_subset = X_test[site_meter_filter].drop(['meter', 'site_id', 'building_id', 'timestamp', 'cluster'], axis=1)\n",
    "        \n",
    "        try:\n",
    "            shap_values = shap.TreeExplainer(estimators_dict[site_meter_cluster]).shap_values(X_test_subset)\n",
    "            plt.title(f\"Site: {site}, Meter: {meter}, Cluster: {cluster}\")\n",
    "            shap.summary_plot(shap_values, X_test_subset, show=False)\n",
    "            plt.savefig(f\"./shap_plots/{site_meter_cluster}.png\", dpi=150, bbox_inches='tight')\n",
    "            plt.clf()\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd3b849",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x950 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SHAP_individual_estimators(X_test, y_test, estimators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06a01b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_id, meter, cluster = list(map(lambda x:int(x), list(estimators_dict.keys())[0].split(\"_\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
