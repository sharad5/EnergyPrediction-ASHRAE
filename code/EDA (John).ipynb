{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9286f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from scipy.stats import kruskal\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d6790",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir ashrae-energy-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f97a930",
   "metadata": {},
   "source": [
    "# Load and Merge Data \n",
    "This code assumes that the data folder is located in the same directory as the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "building = pd.read_csv(\"./ashrae-energy-prediction/building_metadata.csv\")\n",
    "train = pd.read_csv(\"./ashrae-energy-prediction/train.csv\")\n",
    "weather_train = pd.read_csv(\"./ashrae-energy-prediction/weather_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb95ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "building.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8011c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = building.copy()\n",
    "df = df.merge(train, on='building_id', how='left')\n",
    "df = df.merge(weather_train, on=['site_id', 'timestamp'], how='left')\n",
    "del building, train, weather_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c0a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(df.corr())\n",
    "plt.title(\"Pre-Feature Engineering Feature Correlations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b5d41",
   "metadata": {},
   "source": [
    "# Basic Feature Engineering / Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2212459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_square_feet'] = np.log1p(df['square_feet'])\n",
    "df['log_precip_depth_1_hr'] = np.log1p(df['precip_depth_1_hr'])\n",
    "df['log_meter_reading'] = np.log1p(df['meter_reading'])\n",
    "\n",
    "\n",
    "# Fill any infinity values with zero \n",
    "df['log_square_feet'].replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "df['log_precip_depth_1_hr'].replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "\n",
    "# Get time (granular down to the hour, and only one year)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['day'] = df['timestamp'].dt.day\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['weekday'] = df['timestamp'].dt.dayofweek\n",
    "\n",
    "# Track weather metrics means (to detect spikes) \n",
    "weather_features = ['cloud_coverage', 'dew_temperature', 'air_temperature', \n",
    "                    'sea_level_pressure', 'wind_direction', 'wind_speed', 'precip_depth_1_hr',]\n",
    "\n",
    "hourly_by_site = df.groupby(['hour', 'month', 'site_id'])[weather_features].mean().reset_index()\n",
    "\n",
    "df = df.merge(hourly_by_site, on=['hour', 'month', 'site_id'], how='left', suffixes=(None, '_hourly_by_site'))\n",
    "del hourly_by_site\n",
    "\n",
    "for feature in weather_features:\n",
    "    df[feature + \"_diff_hourly_from_mean\"] = df[feature] - df[feature + \"_hourly_by_site\"]\n",
    "    \n",
    "df = df.drop(columns = [feat + \"_hourly_by_site\" for feat in weather_features])\n",
    "\n",
    "# Map meter values to their true name \n",
    "# df['meter'] = df['meter'].replace({\n",
    "#     0: 'electricity',\n",
    "#     1: 'chilledwater',\n",
    "#     2: 'steam',\n",
    "#     3: 'hotwater'\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7767cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 7, figsize=(20, 10))\n",
    "\n",
    "# Generate a histogram for each feature \n",
    "i = 0\n",
    "for feat in df.columns:\n",
    "    try:\n",
    "        sub_axis = axes[i // 7][i % 7]\n",
    "        df[feat].plot.hist(ax=sub_axis)\n",
    "        sub_axis.set_yscale('log')\n",
    "        sub_axis.set_title(feat)\n",
    "        \n",
    "        i += 1 \n",
    "    except:\n",
    "        print(f\"Skipping {feat}\")\n",
    "       \n",
    "\n",
    "plt.suptitle(\"Distributions \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5d94d8",
   "metadata": {},
   "source": [
    "# Hypothesis Testing \n",
    "Given the non-Gaussian nature of the data, I conducted parametric tests to observe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics across building IDs \n",
    "# for feature in df.columns:\n",
    "#     _, pval = kruskal(\n",
    "#         *[df[df['building_id'] == sid][feature].dropna() for sid in df['building_id'].unique()]\n",
    "#     )\n",
    "#     print(feature, pval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a854a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data isn't necessarily linear, observe it with T-SNE\n",
    "# for meter in df['meter'].unique():\n",
    "#     data = df[df['meter'] == meter]\n",
    "#     tsne = TSNE(n_jobs=4)\n",
    "#     transformed_df = tsne.fit_transform(data)\n",
    "#     plt.scatter(transformed_df[:,0], transformed_df[:,1], c=data['building_id'], cmap='viridis')\n",
    "#     plt.title(f\"TSNE {meter}\")\n",
    "#     plt.colorbar()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d76b111",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "Intuition: climate different per month, should train on 75% of each month's data and then test on 25% of it. This is achieved using a stratified shuffle split, where the month is treated as the class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a337ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = StratifiedShuffleSplit(\n",
    "    n_splits=4, \n",
    ")\n",
    "\n",
    "n_trees = 50\n",
    "split = 1 \n",
    "for train_idx, test_idx in splitter.split(df, df['month']):\n",
    "    train, test = df.iloc[train_idx], df.iloc[test_idx]\n",
    "    \n",
    "    regressor = RandomForestRegressor(\n",
    "        n_estimators=n_trees, \n",
    "        random_state=0,\n",
    "        max_samples=0.1\n",
    "    )\n",
    "    \n",
    "    regressor.fit(train.drop(columns='meter_reading'), train['meter_reading'])\n",
    "    \n",
    "    y_hat = regressor.predict(test.drop(columns='meter_reading'))\n",
    "    \n",
    "    print(mean_squared_error(test['meter_reading'], y_hat))\n",
    "    split += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ec10eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
